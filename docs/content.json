{"meta":{"title":"DBKernel","subtitle":"","description":"专注于数据库技术分享","author":"DBKernel","url":"http://dbkernel.github.io","root":"/"},"pages":[{"title":"分类","date":"2021-07-10T09:34:18.000Z","updated":"2021-07-10T10:49:25.987Z","comments":false,"path":"categories/index.html","permalink":"http://dbkernel.github.io/categories/index.html","excerpt":"","text":""},{"title":"标签","date":"2017-05-27T05:47:40.000Z","updated":"2021-07-10T13:50:19.870Z","comments":false,"path":"tags/index.html","permalink":"http://dbkernel.github.io/tags/index.html","excerpt":"","text":"-"},{"title":"关于","date":"2021-07-10T05:47:55.000Z","updated":"2021-07-10T13:59:06.317Z","comments":false,"path":"about/index.html","permalink":"http://dbkernel.github.io/about/index.html","excerpt":"","text":"简介卢文双 xxx yyy"},{"title":"友情链接","date":"2021-07-11T13:25:13.262Z","updated":"2021-07-11T13:25:13.213Z","comments":true,"path":"links/index.html","permalink":"http://dbkernel.github.io/links/index.html","excerpt":"","text":"微信公众号：MySQL数据库技术"},{"title":"项目","date":"2021-07-11T13:27:01.021Z","updated":"2021-07-11T13:27:00.986Z","comments":true,"path":"repository/index.html","permalink":"http://dbkernel.github.io/repository/index.html","excerpt":"","text":""}],"posts":[{"title":"技术分享 | 如何为你的代码选择一个合适的开源协议？","slug":"how-to-choose-open-source-licence","date":"2021-08-18T16:37:15.000Z","updated":"2021-08-22T05:58:30.795Z","comments":true,"path":"2021/08/19/how-to-choose-open-source-licence/","link":"","permalink":"http://dbkernel.github.io/2021/08/19/how-to-choose-open-source-licence/","excerpt":"近期公司全面拥抱开源，在选择开源协议方面遇到了一些问题，查阅了很多资料，特此总结~~","text":"近期公司全面拥抱开源，在选择开源协议方面遇到了一些问题，查阅了很多资料，特此总结~~ 前言对于很多刚踏入开源软件这个行业的小伙伴来说，在编码过程中难免会用到其他人的成果，如果你足够细心，很容易注意到即使是一小段代码，优秀的作者都在文件开头附上一段关于版权的声明，比如 Licensed under the MIT license。同时，一些博客也会标明”此文章采用 CC BY 4.0 CN 协议“。 如果我们拷贝了别人的代码或文章却没注意版权问题，在国外法律意识特别强的环境下（国内版权意识也在逐步加强），那么我们的作品会因触犯别人的权益而违法。即使是最开放的开源协议，最低要求也是保留原作者对代码的声明，所以开源不等于免费，也不等于没有约束。 何为 LICENCE？ LICENCE 是软件的授权许可，详细说明了获得代码后拥有的权利，哪些操作是允许的，哪些操作是禁止的。软件的版权许可证可有很多方式，本文仅限于讨论开源软件协议 Open Source License。 对于大多数人来说，没必要花大把时间去写许可协议，选择一种比较流行的开源协议就足够了，省时省力，更便于自己作品的传播，于人于己都有利。 PS： 说句题外话，很多国外开发者在尊重他人劳动成果方面做得很好，如果A的作品是因为B的作品的启发而来，A甚至都没有使用B任何一句代码，但A会在他的作品里面指明是受到了B的启发：Inspired by XXX link: http://www.xxxx.com。 快速选择开源协议如果你不想了解太多，只是想要一个简直直接的答案，下面给出的建议或许适合你。本小节关于协议地址来自于 GitHub choosealicence 。 简单宽松的协议： 如果你只想要一个简单点的协议不想太麻烦的话。 MIT协议相对宽松，此协议允许别人以任何方式使用你的代码同时署名原作者，但原作者不承担代码使用后的风险，当然也没有技术支持的义务。 考虑有专利的情况： 如果你的作品中涉及到专利相关。 Apache协议也是个相对宽松的协议，与MIT类似，但它指明了作者对用户专利上的一些授权（我的理解是软件作品中含有专利，但它授权你可以免费使用）。 促进代码分享： 如果你在乎作品的传播和别人的修改，希望别人也以相同的协议分享出来。 GPL（V2或V3）协议要求代码分发者或者以此代码为基础开发出来的衍生作品需要以同样的协议来发布，也必须开源，因此，该协议具有”传染性“。 乌克兰程序员Paul Bagwell，画了一张分析图，说明应该怎么选择。只用两分钟，你就能搞清楚这六种开源协议之间的最大区别。 国内大神阮一峰的汉化版本： 主流开源许可协议（Open Source License）世界上的开源许可协议（Open Source License）大概有上百种，常用的开源软件协议大致有： GPL LGPL BSD MIT Mozilla Apache 由宽松到严紧排序，常用的开源协议有： MIT BSD Apache LGPL GPL 主要区别： MIT、BSD 开源协议都源自大学，体现了简单、开放和包容的特点。 MIT、BSD、Apache 三者都支持闭源的后续开发。 GPL、LGPL 传染性开源，编译的代码里用了这里的代码，都必须开源。 MIT来源于大学，MIT 开源协议是史上最为简洁、慷慨的开源协议之一。作者只想保留版权，而无任何其他了限制。也就是说，你必须在你的发行版里包含原许可协议的声明，无论你是以二进制发布的还是以源代码发布的。 特点： 用户可以拿你的代码做任何想做的事情。 用户在项目副本中要包含版权声明和许可声明。 你无需承担任何责任。 代表作品： jQuery Rails 等。 BSD BSD-2-Clause BSD-3-Clause BSD可证也来源于大学，与MIT差不多，也非常简单、慷慨。 BSD开源协议是一个给于使用者很大自由的协议。基本上使用者可以”为所欲为”,可以自由的使用、修改源代码，也可以将修改后的代码作为开源或者专有软件再发布。前提是当你发布使用了BSD协议的代码，或者以BSD协议代码为基础开发自己的产品时，需要满足三个条件： 如果再发布的产品中包含源代码，则在源代码中必须带有原代码中的BSD协议。 如果再发布的只是二进制类库/软件，则需要在类库/软件的文档和版权声明中包含原来代码中的BSD协议。 不可以用开源代码的作者/机构名字和原来产品的名字做市场推广。 BSD 开源协议鼓励代码共享，但需要尊重代码作者的著作权。BSD 开源协议允许使用者修改和重新发布代码，也允许使用或在BSD代码上开发商业软件发布、销售，是对商业集成很友好的协议。因此，很多公司在选用开源产品的时候都首选BSD协议。 Apache Licence Apache License, Version 2.0 Apache License, Version 1.1 Apache License, Version 1.0 来自 Apache，类似 MIT 开源协议，但它重视专利权。 Apache Licence 是著名的非盈利开源组织 Apache 采用的协议。该协议和BSD类似，同样鼓励代码共享和尊重原作者的著作权，同样允许修改代码、再发布（作为开源或商业软件）。需要满足的条件也和BSD类似： 需要为使用代码的用户提供一份 Apache Licence 。 如果你修改了代码，需要在被修改的文件中说明。 在延伸的代码中（修改和由源代码衍生的代码中）需要带有原来代码中的协议、商标、专利声明和其他原作者规定需要包含的说明。 如果再发布的产品中包含一个Notice文件，则在Notice文件中需要带有 Apache Licence 。你可以在Notice中增加自己的许可，但不可对 Apache Licence 构成更改。 Apache Licence 也是对商业应用友好的许可，使用者也可以在需要的时候修改代码来满足需要并作为开源或商业产品发布/销售。 代表作品： echarts superset dubbo spark LGPLLGPL（GNU LESSER GENERAL PUBLIC LICENSE）来自于自由软件联盟GNU，可以翻译为更宽松的GPL协议，也属于传染性开源协议。 LGPL是GPL的一个主要为类库使用设计的开源协议。和GPL要求任何使用/修改/衍生之GPL类库的的软件必须采用GPL协议不同，LGPL 允许商业软件通过类库引用(link)方式使用LGPL类库而不需要开源商业软件的代码。这使得采用LGPL协议的开源代码可以被商业软件作为类库引用并发布和销售。 但是如果修改LGPL协议的代码或者衍生，则所有修改的代码，涉及修改部分的额外代码和衍生的代码都必须采用LGPL协议，因此，LGPL协议的开源代码很适合作为第三方类库被商业软件引用，但不适合希望以LGPL协议代码为基础，通过修改和衍生的方式做二次开发的商业软件采用。 GPL/LGPL都保障原作者的知识产权，避免有人利用开源代码复制并开发类似的产品。 GPLGPL（GNU GENERAL PUBLIC LICENSE）来源于自由软件联盟GNU，GPL/LGPL侧重于代码及衍生代码的开源与免费使用。 GPL协议的主要内容是只要在一个软件中使用（”使用”指类库引用，修改后的代码或者衍生代码）GPL 协议的产品，则该软件产品必须也采用GPL协议，既必须也是开源和免费。这就是所谓的”传染性”。 由于GPL严格要求使用了GPL类库的软件产品必须使用GPL协议，对于使用GPL协议的开源代码，商业软件或者对代码有保密要求的部门就不适合集成/采用作为类库和二次开发的基础。 我们很熟悉的Linux就是采用了GPL。GPL协议和BSD, Apache Licence等鼓励代码重用的许可很不一样。GPL的出发点是代码的开源/免费使用/引用/修改和衍生代码的开源/免费使用，但不允许修改后和衍生的代码做为闭源的商业软件发布和销售。 其它细节和BSD/Apache等协议类似。 代表作品： Linux 更多开源协议对比下方表格中出现的用词的解释： 协议和版权信息(License and copyright notice)：在代码中保留作者提供的协议和版权信息。 声明变更(State Changes)：在代码中声明对原来代码的重大修改及变更。 公开源码(Disclose Source)：代码必需公开。 库引用(Library usage)：该库可以用于商业软件中。 责任承担(Hold Liable)：代码的作者承担代码使用后的风险及产生的后果。如果禁止，那么作者将不会承担责任，可以理解为免责条款。 商标使用(Use Trademark)：可以使用作者的姓名，作品的Logo，或商标。 附加协议(Sublicensing)：允许在软件分发传播过程中附加上原来没有的协议条款等。 协议 描述 要求 允许 禁止 Apache 一个比较宽松且简明地指出了专利授权的协议。 1. 协议和版权信息2. 声明变更 1. 商用2. 分发3. 修改4. 专利授权5. 私用6. 附加协议 1. 责任承担（作者免责）2. 商标使用 GPL 应用最广泛的开源协议，拥有较强的版权自由（copyleft）要求。衍生代码的分发需开源并且也要遵守此协议。此协议有许多变种，不同变种的要求略有不同。 1. 公开源码2. 协议和版权信息3. 声明变更 1. 商用2. 分发3. 修改4. 专利授权5. 私用 1. 责任承担2. 附加协议 MIT 此协议宽松简单。在适当标明来源及免责的情况下，它允许你对代码进行任何形式的使用。 1. 协议和版权信息 1. 商用2. 分发3. 修改4. 私用5. 附加协议 1. 责任承担 Artistic Perl社区最钟爱此协议。要求更改后的软件不能影响原软件的使用。 1. 协议和版权信息2. 声明变更 1. 商用2. 分发3. 修改4. 私用5. 附加协议 1. 责任承担2. 商标使用 BSD 较为宽松的协议，有两个变种BSD 2-Clause 和BSD 3-Clause，两者都与MIT协议只存在细微差异。 1. 协议和版权信息 1. 商用2. 分发3. 修改4. 私用5. 附加协议 1. 责任承担 Eclipse 对商用非常友好的协议，可以用于软件的商业授权。包含对专利的优雅授权，也可以对相关代码应用商业协议。 1. 公开源码2. 协议和版权信息 1. 商用2. 分发3. 修改4. 专利授权5. 私用6. 附加协议 1. 责任承担 LGPL 主要用于一些代码库。衍生代码可以以此协议发布（也可以用其他协议），但与此协议相关的代码必需遵循此协议。 1. 公开源码2. 库引用3. 协议和版权信息 1. 商用2. 分发3. 修改4. 专利授权5. 私用6. 附加协议 1. 责任承担 Mozilla Mozilla Public License(MPL 2.0)是由Mozilla基金创建维护的，旨在较为宽松的BSD协议和更加互惠的GPL协议中找一个折衷点。 1. 公开源码2. 协议和版权信息 1. 商用2. 分发3. 修改4. 专利授权5. 私用6. 附加协议 1. 责任承担2. 商标使用 No license 作者保留所有权利，不允许他人分发，复制或者创造衍生物。当你将代码发表在一些网站上时需要遵守该网站的协议，此协议可能包含了一些对你劳动成果的授权许可。比如将代码发布到GitHub，那么就必须同意别人查看和fork。 1. 协议和版权信息 1. 商用2. 私用 1. 分发2. 修改3. 附加协议 Public domain dedication 在许多国家，默认版权归作者自动拥有，所以Unlicense协议提供了一种通用的模板。此协议表明作者放弃版权，将劳动成果无私贡献出来，会丧失作品全部权利，包括在MIT/X11中定义的无担保权利。 1. N/A 1. 商用2. 分发3. 修改4. 私用 1. 责任承担 参考链接 https://github.com/github/choosealicense.com https://opensource.org/licenses https://www.cnblogs.com/Wayou/p/how_to_choose_a_license.html https://zhuanlan.zhihu.com/p/87855729 欢迎关注我的微信公众号【MySQL数据库技术】。 标题 网址 GitHub https://dbkernel.github.io 知乎 https://www.zhihu.com/people/dbkernel/posts 思否（SegmentFault） https://segmentfault.com/u/dbkernel 掘金 https://juejin.im/user/5e9d3ed251882538083fed1f/posts 开源中国（oschina） https://my.oschina.net/dbkernel 博客园（cnblogs） https://www.cnblogs.com/dbkernel","categories":[{"name":"开源","slug":"开源","permalink":"http://dbkernel.github.io/categories/%E5%BC%80%E6%BA%90/"}],"tags":[{"name":"开源协议","slug":"开源协议","permalink":"http://dbkernel.github.io/tags/%E5%BC%80%E6%BA%90%E5%8D%8F%E8%AE%AE/"},{"name":"开源许可证","slug":"开源许可证","permalink":"http://dbkernel.github.io/tags/%E5%BC%80%E6%BA%90%E8%AE%B8%E5%8F%AF%E8%AF%81/"},{"name":"LICENCE","slug":"LICENCE","permalink":"http://dbkernel.github.io/tags/LICENCE/"},{"name":"github","slug":"github","permalink":"http://dbkernel.github.io/tags/github/"}]},{"title":"源码分析 | ClickHouse和他的朋友们（3）MySQL Protocol和Write调用栈","slug":"clickhouse-and-friends-03-mysql-protocol-write-stack","date":"2020-06-08T11:57:10.000Z","updated":"2021-08-22T05:59:19.549Z","comments":true,"path":"2020/06/08/clickhouse-and-friends-03-mysql-protocol-write-stack/","link":"","permalink":"http://dbkernel.github.io/2020/06/08/clickhouse-and-friends-03-mysql-protocol-write-stack/","excerpt":"","text":"《ClickHouse和他的朋友们》系列文章转载自圈内好友 BohuTANG 的博客，原文链接：https://bohutang.me/2020/06/08/clickhouse-and-friends-mysql-protocol-write-stack/以下为正文。 上篇的MySQL Protocol和Read调用里介绍了 ClickHouse 一条查询语句的调用栈，本文继续介绍写的调用栈，开整。 Write请求 建表: 12mysql&gt; CREATE TABLE test(a UInt8, b UInt8, c UInt8) ENGINE=MergeTree() PARTITION BY (a, b) ORDER BY c;Query OK, 0 rows affected (0.03 sec) 写入数据： 1INSERT INTO test VALUES(1,1,1), (2,2,2); 调用栈分析1. 获取存储引擎 OutputStream1234567DB::StorageMergeTree::write(std::__1::shared_ptr&lt;DB::IAST&gt; const&amp;, DB::Context const&amp;) StorageMergeTree.cpp:174DB::PushingToViewsBlockOutputStream::PushingToViewsBlockOutputStream(std::__1::shared_ptr&lt;DB::IStorage&gt; const&amp;, DB::Context const&amp;, std::__1::shared_ptr&lt;DB::IAST&gt; const&amp;, bool) PushingToViewsBlockOutputStream.cpp:110DB::InterpreterInsertQuery::execute() InterpreterInsertQuery.cpp:229DB::executeQueryImpl(const char *, const char *, DB::Context &amp;, bool, DB::QueryProcessingStage::Enum, bool, DB::ReadBuffer *) executeQuery.cpp:364DB::executeQuery(DB::ReadBuffer&amp;, DB::WriteBuffer&amp;, bool, DB::Context&amp;, std::__1::function&lt;void (std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;)&gt;) executeQuery.cpp:696DB::MySQLHandler::comQuery(DB::ReadBuffer&amp;) MySQLHandler.cpp:311DB::MySQLHandler::run() MySQLHandler.cpp:141 2. 从 SQL 组装 InputStream(1,1,1), (2,2,2) 如何组装成 inputstream 结构呢？ 12345DB::InputStreamFromASTInsertQuery::InputStreamFromASTInsertQuery(std::__1::shared_ptr&lt;DB::IAST&gt; const&amp;, DB::ReadBuffer*,DB::InterpreterInsertQuery::execute() InterpreterInsertQuery.cpp:300DB::executeQueryImpl(char const*, char const*, DB::Context&amp;, bool, DB::QueryProcessingStage::Enum, bool, DB::ReadBuffer*) executeQuery.cpp:386DB::MySQLHandler::comQuery(DB::ReadBuffer&amp;) MySQLHandler.cpp:313DB::MySQLHandler::run() MySQLHandler.cpp:150 然后 12res.in = std::make_shared&lt;InputStreamFromASTInsertQuery&gt;(query_ptr, nullptr, query_sample_block, context, nullptr);res.in = std::make_shared&lt;NullAndDoCopyBlockInputStream&gt;(res.in, out_streams.at(0)); 通过 NullAndDoCopyBlockInputStream的 copyData 方法构造出 Block： 12345678910111213141516DB::ValuesBlockInputFormat::readRow(std::__1::vector&lt;COW&lt;DB::IColumn&gt;::mutable_ptr&lt;DB::IColumn&gt;, std::__1::allocator&lt;COW&lt;DB::IColumn&gt;::mutable_ptr&lt;DB::IColumn&gt; &gt; &gt;&amp;, unsigned long) ValuesBlockInputFormat.cpp:93DB::ValuesBlockInputFormat::generate() ValuesBlockInputFormat.cpp:55DB::ISource::work() ISource.cpp:48DB::InputStreamFromInputFormat::readImpl() InputStreamFromInputFormat.h:48DB::IBlockInputStream::read() IBlockInputStream.cpp:57DB::InputStreamFromASTInsertQuery::readImpl() InputStreamFromASTInsertQuery.h:31DB::IBlockInputStream::read() IBlockInputStream.cpp:57void DB::copyDataImpl&lt;DB::copyData(DB::IBlockInputStream&amp;, DB::IBlockOutputStream&amp;, std::__1::atomic&lt;bool&gt;*)::$_0&amp;, void (&amp;)(DB::Block const&amp;)&gt;(DB::IBlockInputStream&amp;, DB::IBlockOutputStream&amp;, DB::copyData(DB::IBlockInputStream&amp;, DB::IBlockOutputStream&amp;, std::__1::atomic&lt;bool&gt;*)::$_0&amp;, void (&amp;)(DB::Block const&amp;)) copyData.cpp:26DB::copyData(DB::IBlockInputStream&amp;, DB::IBlockOutputStream&amp;, std::__1::atomic&lt;bool&gt;*) copyData.cpp:62DB::NullAndDoCopyBlockInputStream::readImpl() NullAndDoCopyBlockInputStream.h:47DB::IBlockInputStream::read() IBlockInputStream.cpp:57void DB::copyDataImpl&lt;std::__1::function&lt;bool ()&gt; const&amp;, std::__1::function&lt;void (DB::Block const&amp;)&gt; const&amp;&gt;(DB::IBlockInputStream&amp;, DB::IBlockOutputStream&amp;, std::__1::function&lt;bool ()&gt; const&amp;, std::__1::function&lt;void (DB::Block const&amp;)&gt; const&amp;) copyData.cpp:26DB::copyData(DB::IBlockInputStream&amp;, DB::IBlockOutputStream&amp;, std::__1::function&lt;bool ()&gt; const&amp;, std::__1::function&lt;void (DB::Block const&amp;)&gt; const&amp;) copyData.cpp:73DB::executeQuery(DB::ReadBuffer&amp;, DB::WriteBuffer&amp;, bool, DB::Context&amp;, std::__1::function&lt;void (std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;)&gt;) executeQuery.cpp:785DB::MySQLHandler::comQuery(DB::ReadBuffer&amp;) MySQLHandler.cpp:313DB::MySQLHandler::run() MySQLHandler.cpp:150 3. 组装 OutputStream12345DB::InterpreterInsertQuery::execute() InterpreterInsertQuery.cpp:107DB::executeQueryImpl(const char *, const char *, DB::Context &amp;, bool, DB::QueryProcessingStage::Enum, bool, DB::ReadBuffer *) executeQuery.cpp:364DB::executeQuery(DB::ReadBuffer&amp;, DB::WriteBuffer&amp;, bool, DB::Context&amp;, std::__1::function&lt;void (std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;)&gt;) executeQuery.cpp:696DB::MySQLHandler::comQuery(DB::ReadBuffer&amp;) MySQLHandler.cpp:311DB::MySQLHandler::run() MySQLHandler.cpp:141 组装顺序: NullAndDoCopyBlockInputStream CountingBlockOutputStream AddingDefaultBlockOutputStream SquashingBlockOutputStream PushingToViewsBlockOutputStream MergeTreeBlockOutputStream 4. 写入OutputStream123456789101112131415DB::MergeTreeBlockOutputStream::write(DB::Block const&amp;) MergeTreeBlockOutputStream.cpp:17DB::PushingToViewsBlockOutputStream::write(DB::Block const&amp;) PushingToViewsBlockOutputStream.cpp:145DB::SquashingBlockOutputStream::finalize() SquashingBlockOutputStream.cpp:30DB::SquashingBlockOutputStream::writeSuffix() SquashingBlockOutputStream.cpp:50DB::AddingDefaultBlockOutputStream::writeSuffix() AddingDefaultBlockOutputStream.cpp:25DB::CountingBlockOutputStream::writeSuffix() CountingBlockOutputStream.h:37DB::copyDataImpl&lt;DB::copyData(DB::IBlockInputStream&amp;, DB::IBlockOutputStream&amp;, std::__1::atomic&lt;bool&gt;*)::&lt;lambda()&gt;&amp;, void (&amp;)(const DB::Block&amp;)&gt;(DB::IBlockInputStream &amp;, DB::IBlockOutputStream &amp;, &lt;lambda()&gt; &amp;, void (&amp;)(const DB::Block &amp;)) copyData.cpp:52DB::copyData(DB::IBlockInputStream&amp;, DB::IBlockOutputStream&amp;, std::__1::atomic&lt;bool&gt;*) copyData.cpp:138DB::NullAndDoCopyBlockInputStream::readImpl() NullAndDoCopyBlockInputStream.h:57DB::IBlockInputStream::read() IBlockInputStream.cpp:60void DB::copyDataImpl&lt;std::__1::function&lt;bool ()&gt; const&amp;, std::__1::function&lt;void (DB::Block const&amp;)&gt; const&amp;&gt;(DB::IBlockInputStream&amp;, DB::IBlockOutputStream&amp;, std::__1::function&lt;bool ()&gt; const&amp;, std::__1::function&lt;void (DB::Block const&amp;)&gt; const&amp;) copyData.cpp:29DB::copyData(DB::IBlockInputStream&amp;, DB::IBlockOutputStream&amp;, std::__1::function&lt;bool ()&gt; const&amp;, std::__1::function&lt;void (DB::Block const&amp;)&gt; const&amp;) copyData.cpp:154DB::executeQuery(DB::ReadBuffer&amp;, DB::WriteBuffer&amp;, bool, DB::Context&amp;, std::__1::function&lt;void (std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;)&gt;) executeQuery.cpp:748DB::MySQLHandler::comQuery(DB::ReadBuffer&amp;) MySQLHandler.cpp:311DB::MySQLHandler::run() MySQLHandler.cpp:141 通过 copyData 方法，让数据在 OutputStream 间层层透传，一直到 MergeTreeBlockOutputStream。 5. 返回 Client123456789DB::MySQLOutputFormat::finalize() MySQLOutputFormat.cpp:62DB::IOutputFormat::doWriteSuffix() IOutputFormat.h:78DB::OutputStreamToOutputFormat::writeSuffix() OutputStreamToOutputFormat.cpp:18DB::MaterializingBlockOutputStream::writeSuffix() MaterializingBlockOutputStream.h:22void DB::copyDataImpl&lt;std::__1::function&lt;bool ()&gt; const&amp;, std::__1::function&lt;void (DB::Block const&amp;)&gt; const&amp;&gt;(DB::IBlockInputStream&amp;, DB::IBlockOutputStream&amp;, std::__1::function&lt;bool ()&gt; const&amp;, std::__1::function&lt;void (DB::Block const&amp;)&gt; const&amp;) copyData.cpp:52DB::copyData(DB::IBlockInputStream&amp;, DB::IBlockOutputStream&amp;, std::__1::function&lt;bool ()&gt; const&amp;, std::__1::function&lt;void (DB::Block const&amp;)&gt; const&amp;) copyData.cpp:154DB::executeQuery(DB::ReadBuffer&amp;, DB::WriteBuffer&amp;, bool, DB::Context&amp;, std::__1::function&lt;void (std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;)&gt;) executeQuery.cpp:748DB::MySQLHandler::comQuery(DB::ReadBuffer&amp;) MySQLHandler.cpp:311DB::MySQLHandler::run() MySQLHandler.cpp:141 总结1INSERT INTO test VALUES(1,1,1), (2,2,2); 首先内核解析 SQL 语句生成 AST，根据 AST 获取 Interpreter：InterpreterInsertQuery。其次 Interpreter 依次添加相应的 OutputStream。然后从 InputStream 读取数据，写入到 OutputStream，stream 会层层渗透，一直写到底层的存储引擎。最后写入到 Socket Output，返回结果。 ClickHouse 的 OutputStream 编排还是比较复杂，缺少类似 Pipeline 的调度和编排，但是由于模式比较固化，目前看还算清晰。 欢迎关注我的微信公众号【MySQL数据库技术】。 标题 网址 GitHub https://dbkernel.github.io 知乎 https://www.zhihu.com/people/dbkernel/posts 思否（SegmentFault） https://segmentfault.com/u/dbkernel 掘金 https://juejin.im/user/5e9d3ed251882538083fed1f/posts 开源中国（oschina） https://my.oschina.net/dbkernel 博客园（cnblogs） https://www.cnblogs.com/dbkernel","categories":[{"name":"ClickHouse","slug":"ClickHouse","permalink":"http://dbkernel.github.io/categories/ClickHouse/"}],"tags":[{"name":"ClickHouse和他的朋友们","slug":"ClickHouse和他的朋友们","permalink":"http://dbkernel.github.io/tags/ClickHouse%E5%92%8C%E4%BB%96%E7%9A%84%E6%9C%8B%E5%8F%8B%E4%BB%AC/"},{"name":"ClickHouse","slug":"ClickHouse","permalink":"http://dbkernel.github.io/tags/ClickHouse/"},{"name":"源码分析","slug":"源码分析","permalink":"http://dbkernel.github.io/tags/%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"}]},{"title":"源码分析 | ClickHouse和他的朋友们（2）MySQL Protocol和Read调用栈","slug":"clickhouse-and-friends-02-mysql-protocol-read-stack","date":"2020-06-07T09:17:10.000Z","updated":"2021-08-22T06:00:12.009Z","comments":true,"path":"2020/06/07/clickhouse-and-friends-02-mysql-protocol-read-stack/","link":"","permalink":"http://dbkernel.github.io/2020/06/07/clickhouse-and-friends-02-mysql-protocol-read-stack/","excerpt":"","text":"《ClickHouse和他的朋友们》系列文章转载自圈内好友 BohuTANG 的博客，原文链接：https://bohutang.me/2020/06/07/clickhouse-and-friends-mysql-protocol-read-stack/以下为正文。 作为一个 OLAP 的 DBMS 来说，有2个端非常重要： 用户如何方便的链进来，这是入口端 ClickHouse 除了自己的 client 外，还提供了 MySQL/PG/GRPC/HTTP 等接入方式 数据如何方便的挂上去，这是数据源端 ClickHouse 除了自己的引擎外，还可以挂载 MySQL/Kafka 等外部数据源 这样内外互通，多条朋友多条路，以实现“数据”级的编排能力。 今天谈的是入口端的 MySQL 协议，也是本系列 ClickHouse 的第一个好朋友，用户可通过 MySQL 客户端或相关 Driver 直接链接到 ClickHouse，进行数据读写等操作。 本文通过 MySQL的 Query 请求，借用调用栈来了解下 ClickHouse 的数据读取全过程。 如何实现？入口文件在:MySQLHandler.cpp 握手协议 MySQLClient 发送 Greeting 数据报文到 MySQLHandler MySQLHandler 回复一个 Greeting-Response 报文 MySQLClient 发送认证报文 MySQLHandler 对认证报文进行鉴权，并返回鉴权结果 MySQL Protocol 实现在: Core/MySQLProtocol.h 最近的代码中调整为了 Core/MySQL/PacketsProtocolText.h Query请求当认证通过后，就可以进行正常的数据交互了。 当 MySQLClient 发送请求: 1mysql&gt; SELECT * FROM system.numbers LIMIT 5; MySQLHandler 的调用栈： 1-&gt;MySQLHandler::comQuery -&gt; executeQuery -&gt; pipeline-&gt;execute -&gt; MySQLOutputFormat::consume MySQLClient 接收到结果 在步骤2里，executeQuery(executeQuery.cpp)非常重要。它是所有前端 Server 和 ClickHouse 内核的接入口，第一个参数是 SQL 文本(‘select 1’)，第二个参数是结果集要发送到哪里去(socket net)。 调用栈分析1SELECT * FROM system.numbers LIMIT 5 1. 获取数据源StorageSystemNumbers 数据源： 123456789101112DB::StorageSystemNumbers::read(std::__1::vector&lt;std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt;, std::__1::allocator&lt;std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; &gt; &gt; const&amp;, std::__1::shared_ptr&lt;DB::StorageInMemoryMetadata const&gt; const&amp;, DB::SelectQueryInfo const&amp;, DB::Context const&amp;, DB::QueryProcessingStage::Enum, unsigned long, unsigned int) StorageSystemNumbers.cpp:135DB::ReadFromStorageStep::ReadFromStorageStep(std::__1::shared_ptr&lt;DB::RWLockImpl::LockHolderImpl&gt;, std::__1::shared_ptr&lt;DB::StorageInMemoryMetadata const&gt;&amp;, DB::SelectQueryOptions,DB::InterpreterSelectQuery::executeFetchColumns(DB::QueryProcessingStage::Enum, DB::QueryPlan&amp;, std::__1::shared_ptr&lt;DB::PrewhereInfo&gt; const&amp;, std::__1::vector&lt;std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt;, std::__1::allocator&lt;std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; &gt; &gt; const&amp;) memory:3028DB::InterpreterSelectQuery::executeFetchColumns(DB::QueryProcessingStage::Enum, DB::QueryPlan&amp;, std::__1::shared_ptr&lt;DB::PrewhereInfo&gt; const&amp;, std::__1::vector&lt;std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt;, std::__1::allocator&lt;std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; &gt; &gt; const&amp;) InterpreterSelectQuery.cpp:1361DB::InterpreterSelectQuery::executeImpl(DB::QueryPlan&amp;, std::__1::shared_ptr&lt;DB::IBlockInputStream&gt; const&amp;, std::__1::optional&lt;DB::Pipe&gt;) InterpreterSelectQuery.cpp:791DB::InterpreterSelectQuery::buildQueryPlan(DB::QueryPlan&amp;) InterpreterSelectQuery.cpp:472DB::InterpreterSelectWithUnionQuery::buildQueryPlan(DB::QueryPlan&amp;) InterpreterSelectWithUnionQuery.cpp:183DB::InterpreterSelectWithUnionQuery::execute() InterpreterSelectWithUnionQuery.cpp:198DB::executeQueryImpl(const char *, const char *, DB::Context &amp;, bool, DB::QueryProcessingStage::Enum, bool, DB::ReadBuffer *) executeQuery.cpp:385DB::executeQuery(DB::ReadBuffer&amp;, DB::WriteBuffer&amp;, bool, DB::Context&amp;, std::__1::function&lt;void (std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;,DB::MySQLHandler::comQuery(DB::ReadBuffer&amp;) MySQLHandler.cpp:307DB::MySQLHandler::run() MySQLHandler.cpp:141 这里最主要的是 ReadFromStorageStep 函数，从不同 storage 里获取数据源 pipe: 1Pipes pipes = storage-&gt;read(required_columns, metadata_snapshot, query_info, *context, processing_stage, max_block_size, max_streams); 2. Pipeline构造12345678910111213DB::LimitTransform::LimitTransform(DB::Block const&amp;, unsigned long, unsigned long, unsigned long, bool, bool, std::__1::vector&lt;DB::SortColumnDescription, std::__1::allocator&lt;DB::SortColumnDescription&gt; &gt;) LimitTransform.cpp:21DB::LimitStep::transformPipeline(DB::QueryPipeline&amp;) memory:2214DB::LimitStep::transformPipeline(DB::QueryPipeline&amp;) memory:2299DB::LimitStep::transformPipeline(DB::QueryPipeline&amp;) memory:3570DB::LimitStep::transformPipeline(DB::QueryPipeline&amp;) memory:4400DB::LimitStep::transformPipeline(DB::QueryPipeline&amp;) LimitStep.cpp:33DB::ITransformingStep::updatePipeline(std::__1::vector&lt;std::__1::unique_ptr&lt;DB::QueryPipeline, std::__1::default_delete&lt;DB::QueryPipeline&gt; &gt;, std::__1::allocator&lt;std::__1::unique_ptr&lt;DB::QueryPipeline, std::__1::default_delete&lt;DB::QueryPipeline&gt; &gt; &gt; &gt;) ITransformingStep.cpp:21DB::QueryPlan::buildQueryPipeline() QueryPlan.cpp:154DB::InterpreterSelectWithUnionQuery::execute() InterpreterSelectWithUnionQuery.cpp:200DB::executeQueryImpl(const char *, const char *, DB::Context &amp;, bool, DB::QueryProcessingStage::Enum, bool, DB::ReadBuffer *) executeQuery.cpp:385DB::executeQuery(DB::ReadBuffer&amp;, DB::WriteBuffer&amp;, bool, DB::Context&amp;, std::__1::function&lt;void (std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;)&gt;) executeQuery.cpp:722DB::MySQLHandler::comQuery(DB::ReadBuffer&amp;) MySQLHandler.cpp:307DB::MySQLHandler::run() MySQLHandler.cpp:141 3. Pipeline执行123456789101112131415161718DB::LimitTransform::prepare(std::__1::vector&lt;unsigned long, std::__1::allocator&lt;unsigned long&gt; &gt; const&amp;, std::__1::vector&lt;unsigned long, std::__1::allocator&lt;unsigned long&gt; &gt; const&amp;) LimitTransform.cpp:67DB::PipelineExecutor::prepareProcessor(unsigned long, unsigned long, std::__1::queue&lt;DB::PipelineExecutor::ExecutionState*, std::__1::deque&lt;DB::PipelineExecutor::ExecutionState*, std::__1::allocator&lt;DB::PipelineExecutor::ExecutionState*&gt; &gt; &gt;&amp;, std::__1::unique_lock&lt;std::__1::mutex&gt;) PipelineExecutor.cpp:291DB::PipelineExecutor::tryAddProcessorToStackIfUpdated(DB::PipelineExecutor::Edge&amp;, std::__1::queue&lt;DB::PipelineExecutor::ExecutionState*, std::__1::deque&lt;DB::PipelineExecutor::ExecutionState*, std::__1::allocator&lt;DB::PipelineExecutor::ExecutionState*&gt; &gt; &gt;&amp;, unsigned long) PipelineExecutor.cpp:264DB::PipelineExecutor::prepareProcessor(unsigned long, unsigned long, std::__1::queue&lt;DB::PipelineExecutor::ExecutionState*, std::__1::deque&lt;DB::PipelineExecutor::ExecutionState*, std::__1::allocator&lt;DB::PipelineExecutor::ExecutionState*&gt; &gt; &gt;&amp;, std::__1::unique_lock&lt;std::__1::mutex&gt;) PipelineExecutor.cpp:373DB::PipelineExecutor::tryAddProcessorToStackIfUpdated(DB::PipelineExecutor::Edge&amp;, std::__1::queue&lt;DB::PipelineExecutor::ExecutionState*, std::__1::deque&lt;DB::PipelineExecutor::ExecutionState*, std::__1::allocator&lt;DB::PipelineExecutor::ExecutionState*&gt; &gt; &gt;&amp;, unsigned long) PipelineExecutor.cpp:264DB::PipelineExecutor::prepareProcessor(unsigned long, unsigned long, std::__1::queue&lt;DB::PipelineExecutor::ExecutionState*, std::__1::deque&lt;DB::PipelineExecutor::ExecutionState*, std::__1::allocator&lt;DB::PipelineExecutor::ExecutionState*&gt; &gt; &gt;&amp;, std::__1::unique_lock&lt;std::__1::mutex&gt;) PipelineExecutor.cpp:373DB::PipelineExecutor::tryAddProcessorToStackIfUpdated(DB::PipelineExecutor::Edge&amp;, std::__1::queue&lt;DB::PipelineExecutor::ExecutionState*, std::__1::deque&lt;DB::PipelineExecutor::ExecutionState*, std::__1::allocator&lt;DB::PipelineExecutor::ExecutionState*&gt; &gt; &gt;&amp;, unsigned long) PipelineExecutor.cpp:264DB::PipelineExecutor::prepareProcessor(unsigned long, unsigned long, std::__1::queue&lt;DB::PipelineExecutor::ExecutionState*, std::__1::deque&lt;DB::PipelineExecutor::ExecutionState*, std::__1::allocator&lt;DB::PipelineExecutor::ExecutionState*&gt; &gt; &gt;&amp;, std::__1::unique_lock&lt;std::__1::mutex&gt;) PipelineExecutor.cpp:373DB::PipelineExecutor::tryAddProcessorToStackIfUpdated(DB::PipelineExecutor::Edge&amp;, std::__1::queue&lt;DB::PipelineExecutor::ExecutionState*, std::__1::deque&lt;DB::PipelineExecutor::ExecutionState*, std::__1::allocator&lt;DB::PipelineExecutor::ExecutionState*&gt; &gt; &gt;&amp;, unsigned long) PipelineExecutor.cpp:264DB::PipelineExecutor::prepareProcessor(unsigned long, unsigned long, std::__1::queue&lt;DB::PipelineExecutor::ExecutionState*, std::__1::deque&lt;DB::PipelineExecutor::ExecutionState*, std::__1::allocator&lt;DB::PipelineExecutor::ExecutionState*&gt; &gt; &gt;&amp;, std::__1::unique_lock&lt;std::__1::mutex&gt;) PipelineExecutor.cpp:373DB::PipelineExecutor::tryAddProcessorToStackIfUpdated(DB::PipelineExecutor::Edge&amp;, std::__1::queue&lt;DB::PipelineExecutor::ExecutionState*, std::__1::deque&lt;DB::PipelineExecutor::ExecutionState*, std::__1::allocator&lt;DB::PipelineExecutor::ExecutionState*&gt; &gt; &gt;&amp;, unsigned long) PipelineExecutor.cpp:264DB::PipelineExecutor::prepareProcessor(unsigned long, unsigned long, std::__1::queue&lt;DB::PipelineExecutor::ExecutionState*, std::__1::deque&lt;DB::PipelineExecutor::ExecutionState*, std::__1::allocator&lt;DB::PipelineExecutor::ExecutionState*&gt; &gt; &gt;&amp;, std::__1::unique_lock&lt;std::__1::mutex&gt;) PipelineExecutor.cpp:373DB::PipelineExecutor::initializeExecution(unsigned long) PipelineExecutor.cpp:747DB::PipelineExecutor::executeImpl(unsigned long) PipelineExecutor.cpp:764DB::PipelineExecutor::execute(unsigned long) PipelineExecutor.cpp:479DB::executeQuery(DB::ReadBuffer&amp;, DB::WriteBuffer&amp;, bool, DB::Context&amp;, std::__1::function&lt;void (std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;)&gt;) executeQuery.cpp:833DB::MySQLHandler::comQuery(DB::ReadBuffer&amp;) MySQLHandler.cpp:307DB::MySQLHandler::run() MySQLHandler.cpp:141 4. Output执行发送1234567891011DB::MySQLOutputFormat::consume(DB::Chunk) MySQLOutputFormat.cpp:53DB::IOutputFormat::work() IOutputFormat.cpp:62DB::executeJob(DB::IProcessor *) PipelineExecutor.cpp:155operator() PipelineExecutor.cpp:172DB::PipelineExecutor::executeStepImpl(unsigned long, unsigned long, std::__1::atomic&lt;bool&gt;*) PipelineExecutor.cpp:630DB::PipelineExecutor::executeSingleThread(unsigned long, unsigned long) PipelineExecutor.cpp:546DB::PipelineExecutor::executeImpl(unsigned long) PipelineExecutor.cpp:812DB::PipelineExecutor::execute(unsigned long) PipelineExecutor.cpp:479DB::executeQuery(DB::ReadBuffer&amp;, DB::WriteBuffer&amp;, bool, DB::Context&amp;, std::__1::function&lt;void (std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;)&gt;) executeQuery.cpp:800DB::MySQLHandler::comQuery(DB::ReadBuffer&amp;) MySQLHandler.cpp:311DB::MySQLHandler::run() MySQLHandler.cpp:141 总结ClickHouse 的模块化比较清晰，像乐高积木一样可以组合拼装，当我们执行: 1SELECT * FROM system.numbers LIMIT 5 首先内核解析 SQL 语句生成 AST，然后根据 AST 获取数据源 Source，pipeline.Add(Source)。其次根据 AST 信息生成 QueryPlan，根据 QueryPlan 再生成相应的 Transform，pipeline.Add(LimitTransform)。然后添加 Output Sink 作为数据发送对象，pipeline.Add(OutputSink)。执行 pipeline, 各个 Transformer 开始工作。 ClickHouse 的 Transformer 调度系统叫做 Processor，也是决定性能的重要模块，详情见 Pipeline 处理器和调度器。ClickHouse 是一辆手动挡的豪华跑车，免费拥有，海啸们！ 欢迎关注我的微信公众号【MySQL数据库技术】。 标题 网址 GitHub https://dbkernel.github.io 知乎 https://www.zhihu.com/people/dbkernel/posts 思否（SegmentFault） https://segmentfault.com/u/dbkernel 掘金 https://juejin.im/user/5e9d3ed251882538083fed1f/posts 开源中国（oschina） https://my.oschina.net/dbkernel 博客园（cnblogs） https://www.cnblogs.com/dbkernel","categories":[{"name":"ClickHouse","slug":"ClickHouse","permalink":"http://dbkernel.github.io/categories/ClickHouse/"}],"tags":[{"name":"ClickHouse和他的朋友们","slug":"ClickHouse和他的朋友们","permalink":"http://dbkernel.github.io/tags/ClickHouse%E5%92%8C%E4%BB%96%E7%9A%84%E6%9C%8B%E5%8F%8B%E4%BB%AC/"},{"name":"ClickHouse","slug":"ClickHouse","permalink":"http://dbkernel.github.io/tags/ClickHouse/"},{"name":"源码分析","slug":"源码分析","permalink":"http://dbkernel.github.io/tags/%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"}]},{"title":"源码分析 | ClickHouse和他的朋友们（1）编译、开发、测试","slug":"clickhouse-and-friends-01-development","date":"2020-06-05T11:37:10.000Z","updated":"2021-08-22T05:58:57.049Z","comments":true,"path":"2020/06/05/clickhouse-and-friends-01-development/","link":"","permalink":"http://dbkernel.github.io/2020/06/05/clickhouse-and-friends-01-development/","excerpt":"","text":"《ClickHouse和他的朋友们》系列文章转载自圈内好友 BohuTANG 的博客，原文链接：https://bohutang.me/2020/06/05/clickhouse-and-friends-development/以下为正文。 一次偶然的机会，和ClickHouse团队做了一次线下沟通，Alexey提到ClickHouse的设计哲学: The product must solve actual problem And do it better than others 用工程思维解决商业问题的典范啊！ 对用户来说，他们关心的不是什么天花乱坠、上天入地的高科技，只是需要一个能很好解决自己问题的方案，这在开源社区是非常难得的，靠实力“野蛮式”生长。 于是，我对这个散发着伏特加味道的利器充满了好奇，并参与到ClickHouse的社区中一探究竟，第一感觉是开放、友好、战斗力强(AK47 vs CK16, ClickHouse 2016年开源)。 本文先从编译和测试入手，再到如何为社区贡献Patch，希望对那些想参与CK社区的同学有所帮助。 如何本地编译和测试ClickHouse？源码获取1git clone --recursive https://github.com/ClickHouse/ClickHouse 编译准备1234567sudo apt install build-essentialsudo apt-get install software-properties-commonsudo apt-add-repository ppa:ubuntu-toolchain-r/testsudo apt-get updatesudo apt-get install gcc-9 g++-9 git python ninja-buildsudo snap install cmake 开始编译1234567cd ClickHousemkdir buildcd buildexport CC=gcc-9export CXX=g++-9cmake ..ninja 测试方法ClickHouse的测试在官方development/tests文档里有详细的介绍，这里列举3个常用的测试模式： 1. Functional Tests功能测试，主要用于ClickHouse内部功能测试，方式：输入一个sql文件，输出一个result，类似MySQL里的mtr，测试集合 12cd tests./clickhouse-test -c &quot;../build/programs/clickhouse-client&quot; 00001_select_1 2. Integration Tests集成测试，主要用于涉及第三方服务的测试，比如MySQL/Postgres/MongoDB等，以容器化方式编排调度(pytest)运行，测试集合 由于涉及模块较多，集成测试环境的搭建有一定的难度，建议使用官方的docker镜像。比如要跑test_mysql_protocol下的集成测试集： 123cd tests/integrationdocker pull yandex/clickhouse-integration-tests-runner./runner --binary /your/ClickHouse/build/programs/clickhouse --bridge-binary /your/ClickHouse/build/programs/clickhouse-odbc-bridge --configs-dir /your/ClickHouse/programs/server/ &#x27;test_mysql_protocol/test.py::test_java_client -ss -vv&#x27; 3. Unit Tests单元测试，主要用于代码模块的测试，测试集在各个模块的tests目录，比如: Core/tests 如果大家想了解某个模块是如何工作的，强烈建议去翻翻该模块的tests目录，比如想了解processor的工作机制，跟踪调试 Processors/tests/ 即可。 如何给ClickHouse社区提Patch？1. fork首先在自己的github上fork一份ClickHouse代码，比如 https://github.com/BohuTANG/ClickHouse 2. clone到本地12git clone --recursive https://github.com/BohuTANG/ClickHousegit checkout -B mysql_replica(branch名字) 3. 创建新的分支1git checkout -B mysql_replica(branch名字) 4. 功能开发开发者可以提交一个Draft Pull Request到官方，github会显示这个Pull Request处于Draft状态，官方是无法Merge的 5. can be testd标签等待Upstream打[can be tested]标签，一旦被标记CI狂魔们就强势开跑，跑一轮大概需要几十个小时。协助开发者发现一些代码Style、编译以及测试等错误，这样开发者就可以在自己的分支不停的迭代、修正。 如果只是修改typo，这个标签Upstream通常不会添加。 6. 开发完毕开发完成，测试OK，把Draft提升为正式Pull Request，等待Upstraem Review。 7. Merge到Master如果Upstream通过，你的代码会被Merge到Master，恭喜你成为ClickHouse贡献者 8. 注意事项ClickHouse Upstream迭代非常快，一定要多关注master分支进度，尽量保持自己的分支代码与master同步。否则Upstream Docker更新，自己的test可能就过不了。 建议把doc/development读一遍。 欢迎关注我的微信公众号【MySQL数据库技术】。 标题 网址 GitHub https://dbkernel.github.io 知乎 https://www.zhihu.com/people/dbkernel/posts 思否（SegmentFault） https://segmentfault.com/u/dbkernel 掘金 https://juejin.im/user/5e9d3ed251882538083fed1f/posts 开源中国（oschina） https://my.oschina.net/dbkernel 博客园（cnblogs） https://www.cnblogs.com/dbkernel","categories":[{"name":"ClickHouse","slug":"ClickHouse","permalink":"http://dbkernel.github.io/categories/ClickHouse/"}],"tags":[{"name":"ClickHouse和他的朋友们","slug":"ClickHouse和他的朋友们","permalink":"http://dbkernel.github.io/tags/ClickHouse%E5%92%8C%E4%BB%96%E7%9A%84%E6%9C%8B%E5%8F%8B%E4%BB%AC/"},{"name":"ClickHouse","slug":"ClickHouse","permalink":"http://dbkernel.github.io/tags/ClickHouse/"},{"name":"源码分析","slug":"源码分析","permalink":"http://dbkernel.github.io/tags/%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"}]},{"title":"引擎特性 | MySQL select count(*) 、count(1)、count(列) 详解（1）：概念及区别","slug":"mysql-select-count-functions-01-concepts-and-differences","date":"2020-05-06T07:55:15.000Z","updated":"2021-08-22T05:59:50.136Z","comments":true,"path":"2020/05/06/mysql-select-count-functions-01-concepts-and-differences/","link":"","permalink":"http://dbkernel.github.io/2020/05/06/mysql-select-count-functions-01-concepts-and-differences/","excerpt":"","text":"一、前言从接触MySQL开始断断续续的看过一些文章，对count()操作众说纷纭，其中分歧点主要在于count(1)和count(*)哪个效率高，有说count(1)比count(*)快的（这种说法更普遍），有说二者一样快的。个人理解这两种行为可能适用于的是不同的版本，我只关心较新的MySQL版本是什么行为，详见下文。 二、含义首先，先说明一下常见count()操作及含义： count(*)：计算包括NULL值在内的行数，SQL92定义的标准统计行数的语法。 count(1)：计算包括NULL值在内的行数，其中的1是恒真表达式。 count(列名)：计算指定列的行数，但不包含NULL值。 三、具体区别MySQL手册中相关描述如下： For transactional storage engines such as InnoDB, storing an exact row count is problematic. Multiple transactions may be occurring at the same time, each of which may affect the count. InnoDB does not keep an internal count of rows in a table because concurrent transactions might “see” different numbers of rows at the same time. Consequently, SELECT COUNT(*) statements only count rows visible to the current transaction. Prior to MySQL 5.7.18, InnoDB processes SELECT COUNT(*) statements by scanning the clustered index. As of MySQL 5.7.18, InnoDB processes SELECT COUNT(*) statements by traversing the smallest available secondary index unless an index or optimizer hint directs the optimizer to use a different index. If a secondary index is not present, the clustered index is scanned. Processing SELECT COUNT(*) statements takes some time if index records are not entirely in the buffer pool. For a faster count, create a counter table and let your application update it according to the inserts and deletes it does. However, this method may not scale well in situations where thousands of concurrent transactions are initiating updates to the same counter table. If an approximate row count is sufficient, use SHOW TABLE STATUS. InnoDB handles SELECT COUNT(*) and SELECT COUNT(1) operations in the same way. There is no performance difference. For MyISAM tables, COUNT(*) is optimized to return very quickly if the SELECT retrieves from one table, no other columns are retrieved, and there is no WHERE clause. For example: 1&gt;mysql&gt; SELECT COUNT(*) FROM student; This optimization only applies to MyISAM tables, because an exact row count is stored for this storage engine and can be accessed very quickly.COUNT(1) is only subject to the same optimization if the first column is defined as NOT NULL. 官方这段描述要点如下： InnoDB是事务引擎，支持MVCC，并发事务可能同时“看到”不同的行数，所以，InnoDB不保留表中的行数，SELECT COUNT(*)语句只计算当前事务可见的行数。 在MySQL 5.7.18之前，InnoDB通过扫描聚集索引处理SELECT COUNT(*)语句。从MySQL 5.7.18开始，InnoDB通过遍历最小的可用二级索引来处理SELECT COUNT(*)语句，除非索引或优化器明确指示使用不同的索引。如果不存在二级索引，则扫描聚集索引。这样的设计单从 IO 的角度就节省了很多开销。 InnoDB以同样的方式处理SELECT COUNT(*)和SELECT COUNT(1)操作，没有性能差异。 因此，建议使用符合SQL标准的count(*)。 对于MyISAM表，由于MyISAM引擎存储了精确的行数，因此，如果SELECT COUNT(*)语句不包含WHERE子句，则会很快返回。这个很好理解，如果带了where条件，就需要扫表了。 如果索引记录不完全在缓冲池中，则处理SELECT(*)语句需要一些时间。为了更快的计数，您可以创建一个计数器表，并让您的应用程序按插入和删除操作更新它。然而，这种方法在同一计数器表中启动成千上万个并发事务的情况下，可能无法很好地扩展。如果一个近似的行数足够，可以使用SHOW TABLE STATUS查询行数。 到这里我们明白了 count(*) 和 count(1) 本质上面其实是一样的，那么 count(column) 又是怎么回事呢？ count(column) 也是会遍历整张表，但是不同的是它会拿到 column 的值以后判断是否为空，然后再进行累加，那么如果针对主键需要解析内容，如果是二级索引需要再次根据主键获取内容，则要多一次 IO 操作，所以 count(column) 的性能肯定不如前两者，如果按照效率比较的话：*count()=count(1)&gt;count(primary key)&gt;count(非主键column)**。 四、建议基于以上描述，如果要查询innodb存储引擎的表的总行数，有如下建议： 若仅仅是想获取大概的行数，建议使用show table status或查询information_schema.tables：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667mysql&gt; use db6;Reading table information for completion of table and column namesYou can turn off this feature to get a quicker startup with -ADatabase changedmysql&gt; show tables;+---------------+| Tables_in_db6 |+---------------+| t1 |+---------------+1 row in set (0.01 sec)mysql&gt; select count(*) from t1;+----------+| count(*) |+----------+| 2 |+----------+1 row in set (0.00 sec)mysql&gt; show table status\\G*************************** 1. row *************************** Name: t1 Engine: InnoDB Version: 10 Row_format: Dynamic Rows: 2 Avg_row_length: 8192 Data_length: 16384Max_data_length: 0 Index_length: 0 Data_free: 0 Auto_increment: NULL Create_time: 2020-04-21 12:00:44 Update_time: NULL Check_time: NULL Collation: utf8mb4_general_ci Checksum: NULL Create_options: Comment:1 row in set (0.00 sec)mysql&gt; select * from information_schema.tables where table_name = &#x27;t1&#x27;\\G*************************** 1. row *************************** TABLE_CATALOG: def TABLE_SCHEMA: db6 TABLE_NAME: t1 TABLE_TYPE: BASE TABLE ENGINE: InnoDB VERSION: 10 ROW_FORMAT: Dynamic TABLE_ROWS: 2 AVG_ROW_LENGTH: 8192 DATA_LENGTH: 16384MAX_DATA_LENGTH: 0 INDEX_LENGTH: 0 DATA_FREE: 0 AUTO_INCREMENT: NULL CREATE_TIME: 2020-04-21 12:00:44 UPDATE_TIME: NULL CHECK_TIME: NULLTABLE_COLLATION: utf8mb4_general_ci CHECKSUM: NULL CREATE_OPTIONS: TABLE_COMMENT:1 row in set (0.00 sec) 反之，如果必须要获取准确的总行数，建议： 创建一个计数器表，并让您的应用程序按插入和删除操作更新它。 若业务插入和删除相对较少，也可以考虑缓存到 redis。 篇幅有限，深入验证、源码分析将在下一篇文章中介绍。 欢迎关注我的微信公众号【MySQL数据库技术】。 标题 网址 GitHub https://dbkernel.github.io 知乎 https://www.zhihu.com/people/dbkernel/posts 思否（SegmentFault） https://segmentfault.com/u/dbkernel 掘金 https://juejin.im/user/5e9d3ed251882538083fed1f/posts 开源中国（oschina） https://my.oschina.net/dbkernel 博客园（cnblogs） https://www.cnblogs.com/dbkernel","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://dbkernel.github.io/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://dbkernel.github.io/tags/MySQL/"},{"name":"Select","slug":"Select","permalink":"http://dbkernel.github.io/tags/Select/"},{"name":"Count","slug":"Count","permalink":"http://dbkernel.github.io/tags/Count/"}]},{"title":"引擎特性 | MySQL-自增列详解（1）：自增列概念及使用","slug":"mysql-auto_increment-details-01-concepts-and-usage","date":"2019-12-09T11:37:10.000Z","updated":"2021-08-22T05:59:32.101Z","comments":true,"path":"2019/12/09/mysql-auto_increment-details-01-concepts-and-usage/","link":"","permalink":"http://dbkernel.github.io/2019/12/09/mysql-auto_increment-details-01-concepts-and-usage/","excerpt":"一直想写一些关于自增列的文章，今天下班比较早，Let’s do this.","text":"一直想写一些关于自增列的文章，今天下班比较早，Let’s do this. 1. 概念自增列，即 AUTO_INCREMENT，可用于为新的记录生成唯一标识。 要求： AUTO_INCREMENT 是数据列的一种属性，只适用于整数类型数据列。 AUTO_INCREMENT 数据列必须具备 NOT NULL 属性。 2. 使用方法2.1. 创建含自增列的表1234567-- 不指定 AUTO_INCREMENT 的值，则从1开始mysql&gt; create table t1(a int auto_increment primary key,b int);Query OK, 0 rows affected (0.01 sec)-- 手动指定 AUTO_INCREMENT 的值mysql&gt; create table t2(a int auto_increment primary key,b int) AUTO_INCREMENT=100;Query OK, 0 rows affected (0.02 sec) 2.2. 插入数据12345678910111213141516-- 不指定自增列mysql&gt; insert into t1(b) values(1),(2);Query OK, 1 row affected (0.00 sec)mysql&gt; select * from t1;+---+------+| a | b |+---+------+| 1 | 1 || 2 | 2 |+---+------+3 rows in set (0.00 sec)-- 指定自增列mysql&gt; insert into t1(a,b) values(3,3);Query OK, 1 row affected (0.00 sec) 2.3. 如何查看表的 AUTO_INCREMENT 涨到了多少？1234567891011mysql&gt; show create table t1;+-------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+| Table | Create Table |+-------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+| t1 | CREATE TABLE `t1` ( `a` int(11) NOT NULL AUTO_INCREMENT, `b` int(11) DEFAULT NULL, PRIMARY KEY (`a`)) ENGINE=InnoDB AUTO_INCREMENT=3 DEFAULT CHARSET=utf8 |+-------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+1 row in set (0.00 sec) 2.4. 插入数据时能否有空洞？可以的，但要注意 AUTO_INCREMENT 的值一定比自增列当前最大的记录值大。 1234567891011121314151617181920212223242526-- 创造空洞mysql&gt; insert into t1(a,b) values(5,5);Query OK, 1 row affected (0.00 sec)mysql&gt; select * from t1;+---+------+| a | b |+---+------+| 1 | 1 || 2 | 2 || 3 | 3 || 5 | 5 |+---+------+5 rows in set (0.00 sec)mysql&gt; show create table t1;+-------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+| Table | Create Table |+-------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+| t1 | CREATE TABLE `t1` ( `a` int(11) NOT NULL AUTO_INCREMENT, `b` int(11) DEFAULT NULL, PRIMARY KEY (`a`)) ENGINE=InnoDB AUTO_INCREMENT=6 DEFAULT CHARSET=utf8 |+-------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+1 row in set (0.00 sec) 2.5. 能否插入重复记录既然自增列是唯一记录，那么肯定不能插入重复记录。 123-- 尝试插入重复记录mysql&gt; insert into t1(a,b) values(5,5);ERROR 1062 (23000): Duplicate entry &#x27;5&#x27; for key &#x27;PRIMARY&#x27; 2.6. 怎么修改 AUTO_INCREMENT 的值？注意：AUTO_INCREMENT 不能小于当前自增列记录的最大值。 12345678910111213141516171819202122232425262728293031323334-- 尝试将 AUTO_INCREMENT 设为10mysql&gt; alter table t1 AUTO_INCREMENT=10;Query OK, 0 rows affected (0.01 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; show create table t1;+-------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+| Table | Create Table |+-------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+| t1 | CREATE TABLE `t1` ( `a` int(11) NOT NULL AUTO_INCREMENT, `b` int(11) DEFAULT NULL, PRIMARY KEY (`a`)) ENGINE=InnoDB AUTO_INCREMENT=10 DEFAULT CHARSET=utf8 |+-------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+1 row in set (0.00 sec)-- 尝试将 AUTO_INCREMENT 设为4mysql&gt; alter table t1 AUTO_INCREMENT=4;Query OK, 0 rows affected (0.00 sec)Records: 0 Duplicates: 0 Warnings: 0-- 由于自增列最大记录值是5，那么 AUTO_INCREMENT 不能小于5，因此该值为6mysql&gt; show create table t1;+-------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+| Table | Create Table |+-------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+| t1 | CREATE TABLE `t1` ( `a` int(11) NOT NULL AUTO_INCREMENT, `b` int(11) DEFAULT NULL, PRIMARY KEY (`a`)) ENGINE=InnoDB AUTO_INCREMENT=6 DEFAULT CHARSET=utf8 |+-------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+1 row in set (0.00 sec) 3. 问题3.1. 自增列是否有上限？由上文可见，自增列会一直增加，那是否有上限呢？ 上文中表 t1 的自增列是 int 类型，由下表（MySQL 5.7）可见取值范围是 -2147483648 到 2147483647（ -231 ~ 231 - 1 ）。 Type Storage (Bytes) Minimum Value Signed Minimum Value Unsigned Maximum Value Signed Maximum Value Unsigned TINYINT 1 -128 0 127 255 SMALLINT 2 -32768 0 32767 65535 MEDIUMINT 3 -8388608 0 8388607 16777215 INT 4 -2147483648 0 2147483647 4294967295 BIGINT 8 -263 0 263-1 264-1 验证如下： 12345678910111213141516171819202122232425262728mysql&gt; show create table t1;+-------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| Table | Create Table |+-------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| t1 | CREATE TABLE `t1` ( `a` int(11) NOT NULL AUTO_INCREMENT, `b` int(11) DEFAULT NULL, PRIMARY KEY (`a`)) ENGINE=InnoDB AUTO_INCREMENT=2147483644 DEFAULT CHARSET=utf8 |+-------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------+1 row in set (0.01 sec)mysql&gt; insert into t1(b) values(0),(0),(0);Query OK, 1 row affected (0.00 sec)mysql&gt; insert into t1(b) values(0);ERROR 1062 (23000): Duplicate entry &#x27;2147483647&#x27; for key &#x27;PRIMARY&#x27;mysql&gt; show create table t1;+-------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| Table | Create Table |+-------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| t1 | CREATE TABLE `t1` ( `a` int(11) NOT NULL AUTO_INCREMENT, `b` int(11) DEFAULT NULL, PRIMARY KEY (`a`)) ENGINE=InnoDB AUTO_INCREMENT=2147483647 DEFAULT CHARSET=utf8 |+-------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------+1 row in set (0.00 sec) 这里需要补充说明下 int(11) 中的数字的含义： MySQL中整数数据类型后面的(N)指定显示宽度。显示宽度不影响查询出来的结果。显示宽度限制了小数点的位置(只要实际数字不超过显示宽度，这种情况下，数字显示为原样)。显示宽度也是一个有用的工具，可以让开发人员知道应该将值填充到哪个长度。 3.2. 如何避免自增列超过最大值？可以采用无符号的 BIGINT 类型（也可根据业务产生自增列的速度采用合适的类型），能极大提升自增列的范围。 1234567891011121314151617181920212223242526272829303132mysql&gt; create table t2(a bigint unsigned primary key auto_increment,b int);Query OK, 0 rows affected (0.00 sec)mysql&gt; alter table t2 auto_increment=18446744073709551613;Query OK, 0 rows affected (0.00 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; show create table t2;+-------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| Table | Create Table |+-------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| t2 | CREATE TABLE `t2` ( `a` bigint(20) unsigned NOT NULL AUTO_INCREMENT, `b` int(11) DEFAULT NULL, PRIMARY KEY (`a`)) ENGINE=InnoDB AUTO_INCREMENT=18446744073709551613 DEFAULT CHARSET=utf8 |+-------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+1 row in set (0.01 sec)mysql&gt; insert into t2(b) values(0);Query OK, 1 row affected (0.00 sec)mysql&gt; insert into t2(b) values(0);ERROR 1467 (HY000): Failed to read auto-increment value from storage enginemysql&gt;mysql&gt; select * from t2;+----------------------+------+| a | b |+----------------------+------+| 18446744073709551613 | 0 |+----------------------+------+1 row in set (0.00 sec) UNSIGNED BIGINT 类型的范围究竟有多大呢？ 假如每秒自增100万次，想要消耗完需要 18446744073709551613/1000000/3600/24/365=584942年。 有的朋友会问如果自增列不是采用BIGINT类型，那么达到最大值后该表就无法写入，此时该怎么办呢？ 一般达到最大值后再次插入数据会报错ERROR 1467 (HY000): Failed to read auto-increment value from storage engine，可以通过alter table 将自增列的类型设为数值范围更大的类型（比如BIGINT）。 4. 总结 AUTO_INCREMENT 列必定唯一，且仅用于整型类型。 AUTO_INCREMENT 列会持续增长，不会因 delete 自增列最大的记录而变小。 当 AUTO_INCREMENT 列达到当前类型的最大值后将无法插入数据，会报错ERROR 1467 (HY000): Failed to read auto-increment value from storage engine，此时将自增列改为 BIGINT 类型可解决问题。 为了避免自增列达到最大值，可将其设为BIGINT类型。 使用 alter table 修改 AUTO_INCREMENT 列时，其值会取自增列当前最大记录值+1与将要设置的值的最大值。 在MySQL 5.7 中，将列设置成 AUTO_INCREMENT 之后，必须将其设置成主键/或者是主键的一部分，否则会报错ERROR 1075 (42000): Incorrect table definition; there can be only one auto column and it must be defined as a key。 欢迎关注我的微信公众号【MySQL数据库技术】。 标题 网址 GitHub https://dbkernel.github.io 知乎 https://www.zhihu.com/people/dbkernel/posts 思否（SegmentFault） https://segmentfault.com/u/dbkernel 掘金 https://juejin.im/user/5e9d3ed251882538083fed1f/posts 开源中国（oschina） https://my.oschina.net/dbkernel 博客园（cnblogs） https://www.cnblogs.com/dbkernel","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://dbkernel.github.io/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://dbkernel.github.io/tags/MySQL/"},{"name":"auto_increment","slug":"auto-increment","permalink":"http://dbkernel.github.io/tags/auto-increment/"}]},{"title":"实用工具 | Linux定时任务crontab命令详解","slug":"description-of-the-crontab-command","date":"2016-11-23T02:24:45.000Z","updated":"2021-09-04T15:04:50.473Z","comments":true,"path":"2016/11/23/description-of-the-crontab-command/","link":"","permalink":"http://dbkernel.github.io/2016/11/23/description-of-the-crontab-command/","excerpt":"","text":"概述Linux 下的任务调度分为两类：系统任务调度和用户任务调度。Linux 系统任务是由 cron (crond) 这个系统服务来控制的，这个系统服务是默认启动的。用户自己设置的计划任务则使用 crontab 命令。 cron 配置文件在 Ubuntu/Debian 中，配置文件路径为 /etc/crontab（CentOS也类似），其内容为： 12345678910111213141516171819202122# /etc/crontab: system-wide crontab# Unlike any other crontab you don&#x27;t have to run the `crontab&#x27;# command to install the new version when you edit this file# and files in /etc/cron.d. These files also have username fields,# that none of the other crontabs do.SHELL=/bin/shPATH=/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin# Example of job definition:# .---------------- minute (0 - 59)# | .------------- hour (0 - 23)# | | .---------- day of month (1 - 31)# | | | .------- month (1 - 12) OR jan,feb,mar,apr ...# | | | | .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat# | | | | |# * * * * * user-name command to be executed17 * * * * root cd / &amp;&amp; run-parts --report /etc/cron.hourly25 6 * * * root test -x /usr/sbin/anacron || ( cd / &amp;&amp; run-parts --report /etc/cron.daily )47 6 * * 7 root test -x /usr/sbin/anacron || ( cd / &amp;&amp; run-parts --report /etc/cron.weekly )52 6 1 * * root test -x /usr/sbin/anacron || ( cd / &amp;&amp; run-parts --report /etc/cron.monthly )# SHELL 环境变量用于指定系统要使用的shell，此处为/bin/sh。 PATH 环境变量指定了系统执行命令的路径。 也可以添加MAILTO变量，如果指定，则表示 crond 的任务执行信息将通过电子邮件发送给指定的用户。 其他部分在后文详细讲述。 用户定期要执行的工作，比如用户数据备份、定时邮件提醒等，都可以使用 crontab 工具来定制自己的计划任务。所有非root用户定义的 crontab 文件都被保存在 /var/spool/cron 目录中，其文件名与用户名一致。 1ls /var/spool/cron/crontabs/admin 除此之外，还有两个文件/etc/cron.deny和/etc/cron.allow，前者中可列出不允许哪些用户使用 crontab 命令，后者中可列出允许哪些用户使用 crontab 命令。 crontab 文件含义用户所建立的crontab文件中，每一行都代表一项任务，每行的每个字段代表一项设置，它的格式共分为六个字段，前五段是时间设定段，第六段是要执行的命令段，格式如下： 1minute hour day month week command 各字段含义如下： minute：表示分钟，可以是从0到59之间的任何整数。 hour：表示小时，可以是从0到23之间的任何整数。 day：表示日期，可以是从1到31之间的任何整数。 month：表示月份，可以是从1到12之间的任何整数。 week：表示星期几，可以是从0到7之间的任何整数，这里的0或7代表星期日。 command：要执行的命令，可以是系统命令，也可以是自己编写的脚本文件。 在以上各个字段中，还可以使用以下特殊字符： 星号(*)：代表所有可能的值，例如 month 字段如果是星号，则表示在满足其它字段的制约条件后每月都执行该命令操作。 逗号(,)：可以用逗号隔开的值指定一个列表范围，例如：1,2,5,7,8,9 。 中杠(-)：可以用整数之间的中杠表示一个整数范围，例如：2-6 表示2,3,4,5,6 。 正斜线(/)：可以用正斜线指定时间的间隔频率，例如：0-23/2表示每两小时执行一次。同时正斜线可以和星号一起使用，例如：*/10，如果用在minute字段，表示每十分钟执行一次。 crontab命令详解命令格式： 1234567usage: crontab [-u user] file crontab [ -u user ] [ -i ] &#123; -e | -l | -r &#125; (default operation is replace, per 1003.2) -e (edit user&#x27;s crontab) -l (list user&#x27;s crontab) -r (delete user&#x27;s crontab) -i (prompt before deleting user&#x27;s crontab) -u user：用于设定某个用户的crontab服务。 file: file 为命令文件名，表示将 file 作为 crontab 的任务列表文件并载入 crontab ；如果在命令行中没有指定这个文件，crontab 命令将接受标准输入（键盘）上键入的命令，并将它们载入crontab 。 -e：编辑某个用户的 crontab 文件内容，如不指定用户则表示当前用户。 -l：显示某个用户的 crontab 文件内容，如不指定用户则表示当前用户。 -r：从 /var/spool/cron 目录中删除某个用户的crontab文件，如不指定用户，则默认删除当前用户 crontab 文件。 -i：在删除用户的 crontab 文件时给确认提示。 crontab 注意事项 crontab有2种编辑方式：直接编辑/etc/crontab文件与crontab –e，其中/etc/crontab里的计划任务是系统的计划任务，而用户的计划任务需要通过crontab –e来编辑。 每次编辑完某个用户的 cron 设置后，cron 自动在 /var/spool/cron 下生成一个与此用户同名的文件，此用户的 cron 信息都记录在这个文件中，这个文件是不可以直接编辑的，只可以用 crontab -e 来编辑。 crontab 中的 command 尽量使用绝对路径，否则会经常因为路径错误导致任务无法执行。 新创建的 cron job 不会马上执行，至少要等2分钟才能执行，可重启 cron 来立即执行。 % 在crontab文件中表示换行，因此假如脚本或命令含有%，需要使用\\%来进行转义。 crontab -e的默认编辑器是 nano ，如需使用 vim，可在/etc/profile或~/.bashrc中添加 export EDITOR=vi 来解决。 crontab 配置示例 每分钟执行1次 command（因cron默认每1分钟扫描一次，因此全为*即可）： 1* * * * * command 每小时的第3和第15分钟执行 command ： 13,15 * * * * command 每天上午8-11点的第3和15分钟执行 command ： 13,15 8-11 * * * command 每隔2天的上午8-11点的第3和15分钟执行 command ： 13,15 8-11 */2 * * command 每个星期一的上午8点到11点的第3和第15分钟执行 command ： 13,15 8-11 * * 1 command 每晚的21:30分重启 smb ： 130 21 * * * /etc/init.d/smb restart 每月1、10、22日的 4:45 重启 smb ： 145 4 1,10,22 * * /etc/init.d/smb restart 每周六、周日的 1:10 重启 smb ： 110 1 * * 6,0 /etc/init.d/smb restart 每天 18:00 至 23:00 之间每隔30分钟重启 smb ： 10,30 18-23 * * * /etc/init.d/smb restart 每隔1小时重启 smb ： 1* */1 * * * /etc/init.d/smb restart 晚上23点到早上7点之间，每隔1小时重启 smb ： 1* 23-7/1 * * * /etc/init.d/smb restart 每月的4号与每周一到周三的11点重启 smb ： 10 11 4 * mon-wed /etc/init.d/smb restart 每小时执行/etc/cron.hourly目录内的脚本： 10 1 * * * root run-parts /etc/cron.hourly 欢迎关注我的微信公众号【MySQL数据库技术】。 标题 网址 GitHub https://dbkernel.github.io 知乎 https://www.zhihu.com/people/dbkernel/posts 思否（SegmentFault） https://segmentfault.com/u/dbkernel 掘金 https://juejin.im/user/5e9d3ed251882538083fed1f/posts 开源中国（oschina） https://my.oschina.net/dbkernel 博客园（cnblogs） https://www.cnblogs.com/dbkernel","categories":[{"name":"实用工具","slug":"实用工具","permalink":"http://dbkernel.github.io/categories/%E5%AE%9E%E7%94%A8%E5%B7%A5%E5%85%B7/"},{"name":"Linux","slug":"实用工具/Linux","permalink":"http://dbkernel.github.io/categories/%E5%AE%9E%E7%94%A8%E5%B7%A5%E5%85%B7/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://dbkernel.github.io/tags/Linux/"},{"name":"crontab","slug":"crontab","permalink":"http://dbkernel.github.io/tags/crontab/"}]},{"title":"系统运维 | Ubuntu下安装配置samba服务的详细过程","slug":"how-to-install-configure-samba-service-in-ubuntu","date":"2014-08-05T02:14:48.000Z","updated":"2021-09-07T04:02:22.231Z","comments":true,"path":"2014/08/05/how-to-install-configure-samba-service-in-ubuntu/","link":"","permalink":"http://dbkernel.github.io/2014/08/05/how-to-install-configure-samba-service-in-ubuntu/","excerpt":"","text":"1. Samba作用Samba的主要任务就是实现Linux系统和Windows系统之间的资源共享。我们现在是要在Linux下配置Samba，让Windows的用户可以访问你的PC。 当然，也可用于VMWare虚拟机与宿主机之间的资源共享。 2. 安装我是在ubuntu上实现的，所以我只需在配置好ubuntu的更新源之后，在终端中使用一下两句命令，就可以安装Samba的软件包 12sudo apt-get install smabasudo apt-get install smbfs 3. Samba服务的构成Samba的核心是两个守护进程smbd和nmbd 。它们的配置信息都保存在/etc/samba/smb.conf里面。 其中smbd处理Samba软件与Linux协商，nmbd使其他主机能浏览Linux服务器。 4. Samba配置文件配置文件为/etc/samba/smb.conf，如果担心改了之后有问题，可以先备份一下： 1sudo cp /etc/samba/smb.conf /etc/samba/smb_conf_backup 一个完整的Samba配置文件包含两部分： Samba Global Settings 全局参数设置 该部分由[global]段来完成配置，主要是设置整体的规则。其中参数workgroup比较特殊，用于提供NT域名或者工作组名，需要根据实际情况修改： 1workgroup=mygroup Share Definitions 共享定义 有很多段，都用[]标志开始的，需要根据实际情况修改。 语法说明： 每个部分有消息头和参数构成，消息头用[]表示，如[global]就是一个消息头。 参数的结构形式是parameter=value。 注释用 # 表示，这个和shell脚本有点像。 有一些配置前面有 ; ，这个表示这一行的配置可以更改，如需修改，则要去掉;，配置才可能生效。 5. 示例5.1. 设置共享目录假定共享目录为/home/share/samba： 12sudo mkdir -p /home/share/sambasudo chmod 777 /home/share/samba 5.2. 修改配置文件修改 global 段： 12345[global] workgroup = WORKGROUP display charset = UTF-8 unix charset = UTF-8 dos charset = cp936 添加Share段： 123456789101112[Share] comment = Shared Folder with username and password path = /home/share/samba public = yes writable = no valid users = user create mask = 0300 directory mask = 0300 force user = nobody force group = nogroup available = yes browseable = yes 搜索到 security 配置项，修改为： 12security = userusername map = /etc/samba/smbusers 保存并关闭配置文件。 5.3. 添加Samba用户12sudo useradd user #增加了一个叫做user的用户sudo smbpasswd user #修改user的对samba服务的密码，系统会提示输入密码 5.4. 重启服务1sudo /etc/init.d/samba restart 5.5. 使用 在windows系统下使用 方法一：在IE地址栏中输入：\\\\你的IP，然后回车，可能要求你输入用户名和密码（第5.3小节设定的）。 方法二：在网上邻居中新建邻居，在路径中输入: \\\\你的IP\\Share，然后点击下一步完成（可能会要求输入用户名和密码）。 在Linux下访问：在终端中挂载文件系统 1sudo mount -t smbfs -o username=user,password=123456 //218.*.*.*/Share /mnt 其中，-t参数指示了文件系统的类型，username是用户名，password是密码，218.*.*.*是你的IP，Share是在配置文件中已经指明的段名，/mnt是要挂载到的文件夹。 欢迎关注我的微信公众号【MySQL数据库技术】。 标题 网址 GitHub https://dbkernel.github.io 知乎 https://www.zhihu.com/people/dbkernel/posts 思否（SegmentFault） https://segmentfault.com/u/dbkernel 掘金 https://juejin.im/user/5e9d3ed251882538083fed1f/posts 开源中国（oschina） https://my.oschina.net/dbkernel 博客园（cnblogs） https://www.cnblogs.com/dbkernel","categories":[{"name":"Linux","slug":"Linux","permalink":"http://dbkernel.github.io/categories/Linux/"},{"name":"系统运维","slug":"Linux/系统运维","permalink":"http://dbkernel.github.io/categories/Linux/%E7%B3%BB%E7%BB%9F%E8%BF%90%E7%BB%B4/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://dbkernel.github.io/tags/Linux/"},{"name":"系统运维","slug":"系统运维","permalink":"http://dbkernel.github.io/tags/%E7%B3%BB%E7%BB%9F%E8%BF%90%E7%BB%B4/"}]},{"title":"程序人生 | 我的《C陷阱与缺陷》读书笔记","slug":"c-traps-and-pitfalls-reading-notes","date":"2014-08-04T09:56:55.000Z","updated":"2021-09-06T15:47:46.651Z","comments":true,"path":"2014/08/04/c-traps-and-pitfalls-reading-notes/","link":"","permalink":"http://dbkernel.github.io/2014/08/04/c-traps-and-pitfalls-reading-notes/","excerpt":"","text":"第一章 词法“陷阱”1. =不同于==12if(x = y) break; 实际上是将y赋给x，再检查x是否为0。 如果真的是这样预期，那么应该改为： 12if((x = y) != 0) break; 2. &amp;和| 不同于 &amp;&amp; 和 ||3. 词法分析中的“贪心法”编译器将程序分解成符号的方法是：从左到有一个一个字符的读入，如果该字符可能组成一个符号，那么再读入下一个字符，判断已经读入的两个字符组成的字符床是否可能是一个符号的组成部分；如果可能，继续读入下一个字符，重复上述判断，直到读入的字符组成的字符串已不再可能组成一个有意义的符号。例如： 1y = x/*p; 会被解析为：/* 注释符号 4. 整型常量010(八进制数) 不同于 10（十进制）。 5. 字符与字符串首先是单引号与双引号的区别： 用单引号括起来的一个字符表示一个整数（ASCII码），而双引号括起来表示一个指针。 第二章 语法“陷阱”1. 理解函数声明弄懂(*(void(*)())0)(); //首地址为0的函数。 float (*h)(): h是一个指向返回值为浮点型的函数的指针 所以，(float (*)()) 表示一个“指向返回值为浮点型的函数的指针”的类型转换符。 fp(): 是(*fp)( )的简写。 *fp(): 是 *( (*fp) ( ) )的简写。 1( *0 )( ); 虽然上式编译器不认，但可以把0转换为指向“返回值为void的”函数的指针，所以0可变为： ( void(*) ( ) ) 0 ，代入(*0)()，得到： 1(*( void(*) ( ) ) 0) ( ) 该式子用等价于： 12typedef void ( *func ) ( );( *( func ) 0 ) ( ); 类似的，signal.h中对signal函数的声明： 12typedef void (*sighandler_t)(int);sighandler_t signal(int signum, sighandler_t handler); 2. 运算符优先级的问题 优先级 运算符 名称或含义 使用形式 结合方向 说明 1 [] 数组下标 数组名[常量表达式] 左到右 1 () 圆括号 (表达式) 函数名(形参表) 左到右 1 . 成员选择（对象） 对象.成员名 左到右 1 -&gt; 成员选择（指针） 对象指针-&gt;成员名 左到右 2 - 负号运算符 -表达式 右到左 单目运算符 2 (类型) 强制类型转换 (数据类型)表达式 右到左 2 ++ 自增运算符 ++变量名 变量名++ 右到左 单目运算符 2 – 自减运算符 –变量名 变量名– 右到左 单目运算符 2 * 取值运算符 *指针变量 右到左 单目运算符 2 &amp; 取地址运算符 &amp;变量名 右到左 单目运算符 2 ! 逻辑非运算符 !表达式 右到左 单目运算符 2 ~ 按位取反运算符 ~表达式 右到左 单目运算符 2 sizeof 长度运算符 sizeof(表达式) 右到左 3 / 除 表达式 / 表达式 左到右 双目运算符 3 * 乘 表达式*表达式 左到右 双目运算符 3 % 余数（取模） 整型表达式%整型表达式 左到右 双目运算符 4 + 加 表达式+表达式 左到右 双目运算符 4 - 减 表达式-表达式 左到右 双目运算符 5 &lt;&lt; 左移 变量&lt;&lt;表达式 左到右 双目运算符 5 &gt;&gt; 右移 变量&gt;&gt;表达式 左到右 双目运算符 6 &gt; 大于 表达式&gt;表达式 左到右 双目运算符 6 &gt;= 大于等于 表达式&gt;=表达式 左到右 双目运算符 6 &lt; 小于 表达式&lt;表达式 左到右 双目运算符 6 &lt;= 小于等于 表达式&lt;=表达式 左到右 双目运算符 7 == 等于 表达式==表达式 左到右 双目运算符 7 != 不等于 表达式!= 表达式 左到右 双目运算符 8 &amp; 按位与 表达式&amp;表达式 左到右 双目运算符 9 ^ 按位异或 表达式^表达式 左到右 双目运算符 10 | 按位或 表达式|表达式 左到右 双目运算符 11 &amp;&amp; 逻辑与 表达式&amp;&amp;表达式 左到右 双目运算符 12 || 逻辑或 表达式||表达式 左到右 双目运算符 13 ?: 条件运算符 表达式1? 表达式2: 表达式3 右到左 三目运算符 14 = 赋值运算符 变量=表达式 右到左 14 /= 除后赋值 变量/=表达式 右到左 14 *= 乘后赋值 变量*=表达式 右到左 14 %= 取模后赋值 变量%=表达式 右到左 14 += 加后赋值 变量+=表达式 右到左 14 -= 减后赋值 变量-=表达式 右到左 14 &lt;&lt;= 左移后赋值 变量&lt;&lt;=表达式 右到左 14 &gt;&gt;= 右移后赋值 变量&gt;&gt;=表达式 右到左 14 &amp;= 按位与后赋值 变量&amp;=表达式 右到左 14 ^= 按位异或后赋值 变量^=表达式 右到左 14 |= 按位或后赋值 变量|=表达式 右到左 15 , 逗号运算符 表达式,表达式,… 左到右 3. 其他主要是别多写分号，switch别忘了break，别写空else分支。 第三章 语义“陷阱”1. 指针与数组123456789101112131415161718192021222324struct &#123; Int p[4]; Double x;&#125;b[17];int calendar[12][31];int (*p)[31];sizeof(calendar):12*31=372calendar[0] // 指向该一维数组，对应*pcalendar[0][0]......calendar[0][30]calendar[1] // 指向该一维数组，对应*(p+1)calendar[1][0]......calendar[1][30]..................calendar[11] // 指向该一维数组，对应*(p+11)calendar[11][0]......calendar[11][30] 2. 内存分配1free(r); 用malloc显式分配的空间，不会再退出本函数后自动释放掉，而是会等程序员显式释放后才消失。 注意检查，malloc分配的内存可能失败。 C语言中会自动地将作为函数参数的数组声明转换为对应的指针声明，如： 123int strlen(char s[ ])&#123; &#125;等价于int strlen(char *s)&#123; &#125;但在其他情形下不会自动转换，也就是说不等价，如：extern char hello[ ];和extern char *hello;完全不同。 边界计算自己实现一个memcpy函数： 12345void memcpy(char *dest, const char *source, int k)&#123; while( --k &gt;= 0 ) *dest++ = *source++;&#125; 重点是：操作时一定要知道操作数据的长度。 整数溢出 两个有符号整数相加会发生溢出。 两个无符号整数相加不会发生溢出。 一个有符号和一个无符号整数相加，因为有符号被自动转换成无符号，所以也不会溢出。 第四章 连接编译器一般每次只处理一个文件。编译器的责任是把C源程序翻译成对连接器有意义的形式。 许多系统中的连接器是独立于C语言实现的，因此如果链接时候错误原因是与C语言相关的，连接器无法判断错误原因。但连接器能够理解机器语言和内存布局。 典型的连接器把由汇编器或编译器生成的若干个目标模块，整合成一个被称为载入模块或可执行文件的实体。 连接器通常把目标模块看成是由一组外部对象组成的。每个外部对象代表着机器内存中的某个部分，并通过一个外部名称来识别。因此，程序中的每个函数和每个外部变量，如果没有被声明为static，就都是一个外部对象。static的不会与其它源程序文件中的同名函数或同名变量发生冲突。对于非satatic的函数或变量的名称冲突的解决办法将在后面讨论。 除了外部对象外，目标模块中还可能包括了对其他模块中的外部对象的引用，当连接器读入一个目标模块时，它必须解析出这些引用，并作出标记说明这些外部对象不再是未定义的。 连接器的输入是一组目标模块文件和库文件。输出是一个载入模块。 避免外部变量的函数的冲突和不一致等问题的办法： 每个外部对象只在一个头文件里声明，需要用到该外部对象的所有模块都应该包括这个头文件。 定义该外部对象的模块也应该包括这个头文件。 第五章 库函数没什么好说的，就是apue的一些函数而已。 第六章 预处理器宏定义：主要是理解宏不是函数，而是直接替换。 不能忽视宏定义中的空格：1#define f (x) ( (x)-1 )：因为f后面多了一个空格，所以f(x)代表(x) ( (x)-1 ) 宏并不是函数，所以注意那些括号：12#define abs(x) ( ( (x) &gt;= 0)?(x):-(x) )#define max(a,b) ( (a)&gt;(b)?(a):(b) ) 宏并不是语句：1#define assert(e) if (!e) assert_error(__FILE__, __LINE__) 宏不是类型定义 错误用法：12#define int_8_ int* int_8 a,b; //则a是指针，b是int型 正确用法：应该用typedef1typedef int * int_8_; 第七章 可移植性缺陷主要是： 应对C语言标准的变更； 标识符名称的限制； 整数的大小； 字符是有符号整数还是无符号整数； 移位运算符； 在向右移位时，空出的位是由0填充还是1，还是由符号位的副本填充？如果被移位对象是无符号数，那么由0填充；如果是有符号数，那么是0或符号位的副本。 移位操作的位数允许的取值范围是什么？如果被移位对象的长度是n位，那么移位计数必须大于或等于0，而严格小于n。 移植性需考虑的地方： 机器的字符表不同。 有的机器是one’s complement，有的机器是two’s complement的。基于2的补码的计算机，所允许表示的附属取值范围要大于正数取值范围，所以有时取负值的运算会导致溢出。 各机器对取模运算的定义不同。 第八章 惯用与答案将惯用的c == &#39;\\t&#39;写作&#39;\\t&#39; == c。 一旦写错成=号，编译器就能检查出来。 欢迎关注我的微信公众号【MySQL数据库技术】。 标题 网址 GitHub https://dbkernel.github.io 知乎 https://www.zhihu.com/people/dbkernel/posts 思否（SegmentFault） https://segmentfault.com/u/dbkernel 掘金 https://juejin.im/user/5e9d3ed251882538083fed1f/posts 开源中国（oschina） https://my.oschina.net/dbkernel 博客园（cnblogs） https://www.cnblogs.com/dbkernel","categories":[{"name":"程序人生","slug":"程序人生","permalink":"http://dbkernel.github.io/categories/%E7%A8%8B%E5%BA%8F%E4%BA%BA%E7%94%9F/"},{"name":"C语言","slug":"程序人生/C语言","permalink":"http://dbkernel.github.io/categories/%E7%A8%8B%E5%BA%8F%E4%BA%BA%E7%94%9F/C%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"C语言","slug":"C语言","permalink":"http://dbkernel.github.io/tags/C%E8%AF%AD%E8%A8%80/"}]},{"title":"程序人生 | C语言字节对齐问题详解 - 对齐/字节序/位序/网络序等（下）","slug":"c-language-byte-alignment-problem-in-detail-part-2","date":"2014-07-21T07:35:30.000Z","updated":"2021-09-06T15:46:02.227Z","comments":true,"path":"2014/07/21/c-language-byte-alignment-problem-in-detail-part-2/","link":"","permalink":"http://dbkernel.github.io/2014/07/21/c-language-byte-alignment-problem-in-detail-part-2/","excerpt":"","text":"6. 附录6.1. 字节序与网络序6.1.1. 字节序字节序，顾名思义就是字节的高低位存放顺序。 对于单字节，大部分处理器以相同的顺序处理比特位，因此单字节的存放和传输方式一般相同。 对于多字节数据，如整型（32位机中一般占4字节），在不同的处理器的存放方式主要有两种（以内存中 0x0A0B0C0D 的存放方式为例）。 6.1.1.1. 大字节序（Big-Endian，又称大端序或大尾序）在计算机中，存储介质以下面方式存储整数 0x0A0B0C0D，则称为大字节序： 数据以8bit为单位：低地址方向 -&gt; 0x0A 0x0B 0x0C 0x0D -&gt; 高地址方向 数据以16bit为单位：低地址方向 -&gt; 0x0A0B 0x0C0D -&gt; 高地址方向 其中，最高有效位(MSB，Most Significant Byte)0x0A存储在最低的内存地址处。下个字节0x0B存在后面的地址处。同时，最高的16bit单元0x0A0B存储在低位。 简而言之，大字节序就是高字节存入低地址，低字节存入高地址。 这里讲个词源典故：“endian”一词来源于乔纳森·斯威夫特的小说《格列佛游记》。小说中，小人国为水煮蛋该从大的一端(Big-End)剥开还是小的一端(Little-End)剥开而争论，争论的双方分别被称为 Big-endians 和 Little-endians 。 1980年，Danny Cohen在其著名的论文”On Holy Wars and a Plea for Peace“中为平息一场关于字节该以什么样的顺序传送的争论而引用了该词。 借用上面的典故，想象一下要把熟鸡蛋旋转着稳立起来，大头（高字节）肯定在下面（低地址）^_^ 6.1.1.2. 小字节序（Little-Endian，又称小端序或小尾序）在计算机中，存储介质以下面方式存储整数 0x0A0B0C0D 则称为小字节序： 数据以8bit为单位：高地址方向 -&gt; 0x0A 0x0B 0x0C 0x0D -&gt; 低地址方向 数据以16bit为单位：高地址方向 -&gt; 0x0A0B 0x0C0D -&gt; 低地址方向 其中，最低有效位(LSB，Least Significant Byte)0x0D存储在最低的内存地址处。后面字节依次存在后面的地址处。同时，最低的16bit单元0x0A0B存储在低位。 可见，小字节序就高字节存入高地址，低字节存入低地址。 C语言中的位域结构也要遵循比特序(类似字节序) 。例如： 1234struct bitfield&#123; unsigned char a: 2; unsigned char b: 6;&#125; 该位域结构占1个字节，假设赋值a=0x01和b=0x02，则大字节机器上该字节为(01)(000010)，小字节机器上该字节为(000010)(01) 。因此在编写可移植代码时，需要加条件编译。 注意，在包含位域的C结构中，若位域A在位域B之前定义，则位域A所占用的内存空间地址低于位域B所占用的内存空间。 另见以下联合体，在小字节机器上若low=0x01，high=0x02，则hex=0x21： 12345678910111213int main(void)&#123; union&#123; unsigned char hex; struct&#123; unsigned char low : 4; unsigned char high : 4; &#125;; &#125;convert; convert.low = 0x01; convert.high = 0x02; printf(&quot;hex = 0x%0x\\n&quot;, convert.hex); return 0;&#125; 6.1.1.3. 注意事项无论是大字节序，还是小字节序，变量的地址都等于变量所占字节中的低地址。例如，下述程序中，小字节序输出 0x0D，大字节序输出 0x0A 。 12int32_t a = 0x0A0B0C0D;printf(&quot;0x%0x\\n&quot;, *((int8_t*)&amp;dwData)); 6.1.2. 网络序网络传输一般采用大字节序，也称为网络字节序或网络序。IP协议中定义大字节序为网络字节序。 对于可移植的代码来说，将接收的网络数据转换成主机的字节序是必须的，一般会有成对的函数用于把网络数据转换成相应的主机字节序或反之（若主机字节序与网络字节序相同，通常将函数定义为空宏）。 伯克利socket API定义了一组转换函数，用于16和32位整数在网络序和主机字节序之间的转换。htonl、htons用于主机序转换到网络序；ntohl、ntohs用于网络序转换到本机序。 注意：在大小字节序转换时，必须考虑待转换数据的长度(如5.1.1节的数据单元)。另外对于单字符或小于单字符的几个bit数据，是不必转换的，因为在机器存储和网络发送的一个字符内的bit位存储顺序是一致的。 6.1.3. 位序用于描述串行设备的传输顺序。一般硬件传输采用小字节序（先传低位），但I2C协议采用大字节序。网络协议中只有数据链路层的底端会涉及到。 6.1.4. 处理器字节序不同处理器体系的字节序如下所示： X86、MOS Technology 6502、Z80、VAX、PDP-11 等处理器为 Little endian； Motorola 6800、Motorola 68000、PowerPC 970、System/370、SPARC(除V9外) 等处理器为 Big endian； ARM、PowerPC (除PowerPC 970外)、DEC Alpha，SPARC V9，MIPS，PA-RISC and IA64 等的字节序是可配置的。 6.1.5. 字节序编程请看下面的语句： 1printf(&quot;%c\\n&quot;, *((short*)&quot;AB&quot;) &gt;&gt; 8); 在大字节序下输出为’A’，小字节序下输出为’B’。 下面的代码可用来判断本地机器字节序： 123456789101112131415161718192021222324252627282930//字节序枚举类型typedef enum&#123; ENDIAN_LITTLE = (INT8U)0X00, ENDIAN_BIG = (INT8U)0X01&#125;E_ENDIAN_TYPE;E_ENDIAN_TYPE GetEndianType(VOID)&#123; INT32U dwData = 0x12345678; // 取数都从低地址开始访问 if(0x78 == *((INT8U*)&amp;dwData)) return ENDIAN_LITTLE; else return ENDIAN_BIG;&#125;//Start of GetEndianTypeTest//#include &lt;endian.h&gt;VOID GetEndianTypeTest(VOID)&#123;#if _BYTE_ORDER == _LITTLE_ENDIAN printf(&quot;[%s]&lt;Test Case&gt; Result: %s, EndianType = %s!\\n&quot;, __FUNCTION__, (ENDIAN_LITTLE != GetEndianType()) ? &quot;ERROR&quot; : &quot;OK&quot;, &quot;Little&quot;);#elif _BYTE_ORDER == _BIG_ENDIAN printf(&quot;[%s]&lt;Test Case&gt; Result: %s, EndianType = %s!\\n&quot;, __FUNCTION__, (ENDIAN_BIG != GetEndianType()) ? &quot;ERROR&quot; : &quot;OK&quot;, &quot;Big&quot;);#endif&#125;//End of GetEndianTypeTest// 在字节序不同的平台间的交换数据时，必须进行转换。比如对于int类型，大字节序写入文件： 12int i = 100;write(fd, &amp;i, sizeof(int)); 小字节序读出后： 1234567891011int i;read(fd, &amp;i, sizeof(int));char buf[sizeof(int)];memcpy(buf, &amp;i, sizeof(int));for(i = 0; i &lt; sizeof(int); i++)&#123; int v = buf[sizeof(int) - i - 1]; buf[sizeof(int) - 1] = buf[i]; buf[i] = v;&#125;memcpy(&amp;i, buf, sizeof(int)); 上面仅仅是个例子。在不同平台间即使不存在字节序的问题，也尽量不要直接传递二进制数据。作为可选的方式就是使用文本来交换数据，这样至少可以避免字节序的问题。 很多的加密算法为了追求速度，都会采取字符串和数字之间的转换，在计算完毕后，必须注意字节序的问题，在某些实现中可以见到使用预编译的方式来完成，这样很不方便，如果使用前面的语句来判断，就可以自动适应。 字节序问题不仅影响异种平台间传递数据，还影响诸如读写一些特殊格式文件之类程序的可移植性。此时使用预编译的方式来完成也是一个好办法。 6.2. 对齐时的填充字节代码如下： 123456789101112struct A&#123; char c; int i; short s;&#125;;int main(void)&#123; struct A a; a.c = 1; a.i = 2; a.s = 3; printf(&quot;sizeof(A)=%d\\n&quot;, sizeof(struct A)); return 0;&#125; 执行后输出为sizeof(A)=12。 6.3. pragma pack语法说明123#pragma pack(n)#pragma pack(push, 1)#pragma pack(pop) 1）#pragma pack(n) 该指令指定结构和联合成员的紧凑对齐。而一个完整的转换单元的结构和联合的紧凑对齐由/Zp选项设置。紧凑对齐用pack编译指示在数据说明层设置。该编译指示在其出现后的第一个结构或者联合声明处生效。该编译指示对定义无效。 当使用#pragma pack (n) 时，n 为1、2、4、8或16。第一个结构成员后的每个结构成员都被存储在更小的成员类型或n字节界限内。如果使用无参量的#pragma pack，结构成员被紧凑为以/Zp指定的值。该缺省/Zp紧凑值为/Zp 8。 2）编译器也支持以下增强型语法： 1#pragma pack( [ [ &#123; push | pop &#125; , ] [identifier, ] ] [ n] ) 若不同的组件使用 pack编译指示 指定不同的紧凑对齐, 这个语法允许你把程序组件组合为一个单独的转换单元。 带push参量的 pack编译指示 的每次出现将当前的紧凑对齐存储到一个内部编译器堆栈中。编译指示的参量表从左到右读取。如果使用push，则当前紧凑值被存储起来；如果给出一个n值，该值将成为新的紧凑值。若指定一个标识符，即选定一个名称，则该标识符将和这个新的的紧凑值联系起来。 带一个pop参量的 pack编译指示 的每次出现都会检索内部编译器堆栈顶的值，并使该值为新的紧凑对齐值。如果使用pop参量且内部编译器堆栈是空的，则紧凑值为命令行给定的值，并将产生一个警告信息。若使用pop且指定一个n值，该值将成为新的紧凑值。 若使用pop且指定一个标识符，所有存储在堆栈中的值将从栈中删除，直到找到一个匹配的标识符。这个与标识符相关的紧凑值也从栈中移出，并且这个仅在标识符入栈之前存在的紧凑值成为新的紧凑值。如果未找到匹配的标识符, 将使用命令行设置的紧凑值，并且将产生一个一级警告。缺省紧凑对齐为8。 pack编译指示 的新的增强功能让你在编写头文件时，确保在遇到该头文件的前后的紧凑值是一样的。 6.4. Intel关于内存对齐的说明以下内容节选自《Intel Architecture 32 Manual》。 字、双字和四字在自然边界上不需要在内存中对齐。（对于字、双字和四字来说，自然边界分别是偶数地址，可以被4整除的地址，和可以被8整除的地址。） 无论如何，为了提高程序的性能，数据结构(尤其是栈)应该尽可能地在自然边界上对齐。原因在于，为了访问未对齐的内存，处理器需要作两次内存访问；然而，对齐的内存访问仅需要一次访问。 一个字或双字操作数跨越了4字节边界，或者一个四字操作数跨越了8字节边界，被认为是未对齐的，从而需要两次总线周期来访问内存。一个字起始地址是奇数但却没有跨越字边界被认为是对齐的，能够在一个总线周期中被访问。 某些操作双四字的指令需要内存操作数在自然边界上对齐。如果操作数没有对齐，这些指令将会产生一个通用保护异常(#GP)。双四字的自然边界是能够被16整除的地址。其他操作双四字的指令允许未对齐的访问(不会产生通用保护异常)，然而，需要额外的内存总线周期来访问内存中未对齐的数据。 6.5. 不同架构处理器的对齐要求RISC指令集处理器（MIPS/ARM）：这种处理器的设计以效率为先，要求所访问的多字节数据（short/int/long）的地址必须是此数据大小的倍数，如short数据地址应为2的倍数，long数据地址应为4的倍数，也就是说是对齐的。 CISC指令集处理器(X86) ：没有上述限制。 对齐处理策略 访问非对齐多字节数据时(pack数据)，编译器会将指令拆成多条(因为非对齐多字节数据可能跨越地址对齐边界)，保证每条指令都从正确的起始地址上获取数据，但也因此效率比较低。 访问对齐数据时则只用一条指令获取数据，因此对齐数据必须确保其起始地址是在对齐边界上。如果不是在对齐的边界，对X86 CPU是安全的，但对MIPS/ARM这种RISC CPU会出现总线访问异常。 为什么X86是安全的呢？ X86 CPU是如何进行数据对齐的？ X86 CPU的EFLAGS寄存器中包含一个特殊的位标志，称为AC(对齐检查的英文缩写)标志。 按照默认设置，当CPU首次加电时，该标志被设置为0。 当该标志是0时，CPU能够自动执行它应该执行的操作，以便成功地访问未对齐的数据值。 然而，如果该标志被设置为1，每当系统试图访问未对齐的数据时，CPU就会发出一个INT 17H中断。 X86的Windows 2000和Windows 98版本从来不改变这个CPU标志位。因此，当应用程序在X86处理器上运行时，你根本看不到应用程序中出现数据未对齐的异常条件。 为什么MIPS/ARM不安全呢？ 因为MIPS/ARM CPU不能自动处理对未对齐数据的访问。当未对齐的数据访问发生时，CPU就会将这一情况通知操作系统。这时，操作系统将会确定它是否应该引发一个数据未对齐异常条件，对vxworks是会触发这个异常的。 6.6. ARM下的对齐处理有部分摘自ARM编译器文档对齐部分。 对齐的使用： __align(num) 用于修改最高级别对象的字节边界。 在汇编中使用LDRD或STRD时就要用到此命令__align(8)进行修饰限制。来保证数据对象是相应对齐。 这个修饰对象的命令最大是8个字节限制，可以让2字节的对象进行4字节对齐，但不能让4字节的对象2字节对齐。 __align是存储类修改，只修饰最高级类型对象，不能用于结构或者函数对象。 __packed 进行一字节对齐。需注意： 不能对packed的对象进行对齐； 所有对象的读写访问都进行非对齐访问； float及包含float的结构联合及未用__packed的对象将不能字节对齐； __packed对局部整型变量无影响。 强制由unpacked对象向packed对象转化时未定义。整型指针可以合法定义为packed，如__packed int* p(__packed int 则没有意义) 对齐或非对齐读写访问可能存在的问题： 12345678910111213141516171819202122232425262728293031323334353637//定义如下结构，b的起始地址不对齐。在栈中访问b可能有问题，因为栈上数据对齐访问__packed struct STRUCT_TEST&#123; char a; int b; char c;&#125;;//将下面的变量定义成全局静态(不在栈上)static char *p;static struct STRUCT_TEST a;void main()&#123; __packed int *q; //定义成__packed来修饰当前q指向为非对齐的数据地址下面的访问则可以 p = (char*)&amp;a; q = (int*)(p + 1); *q = 0x87654321; /* 得到赋值的汇编指令很清楚 ldr r5,0x20001590 ; = #0x12345678 [0xe1a00005] mov r0,r5 [0xeb0000b0] bl __rt_uwrite4 //在此处调用一个写4字节的操作函数 [0xe5c10000] strb r0,[r1,#0] //函数进行4次strb操作然后返回，正确访问数据 [0xe1a02420] mov r2,r0,lsr #8 [0xe5c12001] strb r2,[r1,#1] [0xe1a02820] mov r2,r0,lsr #16 [0xe5c12002] strb r2,[r1,#2] [0xe1a02c20] mov r2,r0,lsr #24 [0xe5c12003] strb r2,[r1,#3] [0xe1a0f00e] mov pc,r14 若q未加__packed修饰则汇编出来指令如下(会导致奇地址处访问失败)： [0xe59f2018] ldr r2,0x20001594 ; = #0x87654321 [0xe5812000] str r2,[r1,#0] */ //这样很清楚地看到非对齐访问如何产生错误，以及如何消除非对齐访问带来的问题 //也可看到非对齐访问和对齐访问的指令差异会导致效率问题&#125; 6.7. 《The C Book》之位域篇While we’re on the subject of structures, we might as well look at bitfields. They can only be declared inside a structure or a union, and allow you to specify some very small objects of a given number of bits in length. Their usefulness is limited and they aren’t seen in many programs, but we’ll deal with them anyway. This example should help to make things clear: 1234567struct&#123; unsigned field1 :4; //field 4 bits wide unsigned :3; //unnamed 3 bit field(allow for padding) signed field2 :1; //one-bit field(can only be 0 or -1 in two&#x27;s complement) unsigned :0; //align next field on a storage unit unsigned field3 :6;&#125;full_of_fields; Each field is accessed and manipulated as if it were an ordinary member of a structure. The keywords signed and unsigned mean what you would expect, except that it is interesting to note that a 1-bit signed field on a two’s complement machine can only take the values 0 or -1. The declarations are permitted to include the const and volatile qualifiers. The main use of bitfields is either to allow tight packing of data or to be able to specify the fields within some externally produced data files. C gives no guarantee of the ordering of fields within machine words, so if you do use them for the latter reason, you program will not only be non-portable, it will be compiler-dependent too. The Standard says that fields are packed into ‘storage units’, which are typically machine words. The packing order, and whether or not a bitfield may cross a storage unit boundary, are implementation defined. To force alignment to a storage unit boundary, a zero width field is used before the one that you want to have aligned. Be careful using them. It can require a surprising amount of run-time code to manipulate these things and you can end up using more space than they save. Bit fields do not have addresses—you can’t have pointers to them or arrays of them. 6.8. C语言字节相关面试题6.8.1. Intel/微软C语言面试题请看下面的问题： 1234567891011#pragma pack(8)struct s1&#123; short a; // 按 min(1,8) 对齐 long b; // 按 min(4,8) 对齐&#125;;struct s2&#123; char c; s1 d; long long e; //VC6.0下可能要用__int64代替双long&#125;;#pragma pack() 问题： sizeof(s2) = ？ s2的s1中的a后面空了几个字节接着是b？ 分析： 成员对齐有一个重要的条件，即每个成员分别按自己的方式对齐。 也就是说上面虽然指定了按8字节对齐，但并不是所有的成员都是以8字节对齐。其对齐的规则是：每个成员按 其类型的对齐参数（通常是这个类型的大小） 和 指定对齐参数（这里是8字节） 中较小的一个对齐，并且结构的长度必须为所用过的所有对齐参数的整数倍，不够就补空字节。 s1中成员a是1字节，默认按1字节对齐，而指定对齐参数为8，两值中取1，即a按1字节对齐；成员b是4个字节，默认按4字节对齐，这时就按4字节对齐，所以sizeof(s1)应该为8； s2中c和s1中a一样，按1字节对齐。而d是个8字节结构体，其默认对齐方式就是所有成员使用的对齐参数中最大的一个，s1的就是4。所以，成员d按4字节对齐。成员e是8个字节，默认按8字节对齐，和指定的一样，所以它对到8字节的边界上。这时，已经使用了12个字节，所以又添加4个字节的空，从第16个字节开始放置成员e。此时长度为24，并可被8（成员e按8字节对齐）整除。这样，一共使用了24个字节。 各个变量在内存中的布局为： 123c***aa**bbbb****dddddddd ——这种“矩阵写法”很方便看出结构体实际大小！ 因此，sizeof(S2)结果为24，a后面空了2个字节接着是b。 这里有三点很重要： 每个成员分别按自己的方式对齐，并能最小化长度； 复杂类型(如结构)的默认对齐方式是其最长的成员的对齐方式，这样在成员是复杂类型时可以最小化长度； 对齐后的长度必须是成员中最大对齐参数的整数倍，这样在处理数组时可保证每一项都边界对齐。 还要注意，“空结构体”(不含数据成员)的大小为1，而不是0。试想如果不占空间的话，一个空结构体变量如何取地址、两个不同的空结构体变量又如何得以区分呢？ 6.8.2 上海网宿科技面试题假设硬件平台是intel x86(little endian)，以下程序输出什么： 12345678910111213141516//假设硬件平台是intel x86(little endian)typedef unsigned int uint32_t;void inet_ntoa(uint32_t in)&#123; char b[18]; register char *p; p = (char *)∈#define UC(b) (((int)b)&amp;0xff) //byte转换为无符号int型 sprintf(b, &quot;%d.%d.%d.%d\\n&quot;, UC(p[0]), UC(p[1]), UC(p[2]), UC(p[3])); printf(b);&#125;int main(void)&#123; inet_ntoa(0x12345678); inet_ntoa(0x87654321); return 0;&#125; 先看如下程序： 12345678int main(void)&#123; int a = 0x12345678; char *p = (char *)&amp;a; char str[20]; sprintf(str,&quot;%d.%d.%d.%d\\n&quot;, p[0], p[1], p[2], p[3]); printf(str); return 0;&#125; 按照小字节序的规则，变量a在计算机中存储方式为： 高地址方向 ————–&gt; 低地址方向0x12 0x34 0x56 0x78p[3] p[2] p[1] p[0] 注意：p并不是指向0x12345678的开头0x12，而是指向0x78。p[0]到p[1]的操作是&amp;p[0]+1，因此p[1]地址比p[0]地址大。输出结果为120.86.52.18。 反过来的话，令int a = 0x87654321，则输出结果为33.67.101.-121。 为什么有负值呢？ 因为系统默认的char是有符号的，本来是0x87也就是135，大于127因此就减去256得到-121。 想要得到正值的话只需将char *p = (char *)&amp;a改为unsigned char *p = (unsigned char *)&amp;a即可。 综上不难得出，网宿面试题的答案为120.86.52.18和33.67.101.135。 说明：本文转载自 https://www.cnblogs.com/clover-toeic/p/3853132.html 欢迎关注我的微信公众号【MySQL数据库技术】。 标题 网址 GitHub https://dbkernel.github.io 知乎 https://www.zhihu.com/people/dbkernel/posts 思否（SegmentFault） https://segmentfault.com/u/dbkernel 掘金 https://juejin.im/user/5e9d3ed251882538083fed1f/posts 开源中国（oschina） https://my.oschina.net/dbkernel 博客园（cnblogs） https://www.cnblogs.com/dbkernel","categories":[{"name":"程序人生","slug":"程序人生","permalink":"http://dbkernel.github.io/categories/%E7%A8%8B%E5%BA%8F%E4%BA%BA%E7%94%9F/"},{"name":"C语言","slug":"程序人生/C语言","permalink":"http://dbkernel.github.io/categories/%E7%A8%8B%E5%BA%8F%E4%BA%BA%E7%94%9F/C%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"C语言","slug":"C语言","permalink":"http://dbkernel.github.io/tags/C%E8%AF%AD%E8%A8%80/"},{"name":"字节对齐","slug":"字节对齐","permalink":"http://dbkernel.github.io/tags/%E5%AD%97%E8%8A%82%E5%AF%B9%E9%BD%90/"},{"name":"字节序","slug":"字节序","permalink":"http://dbkernel.github.io/tags/%E5%AD%97%E8%8A%82%E5%BA%8F/"},{"name":"网络序","slug":"网络序","permalink":"http://dbkernel.github.io/tags/%E7%BD%91%E7%BB%9C%E5%BA%8F/"}]},{"title":"程序人生 | C语言字节对齐问题详解 - 对齐/字节序/位序/网络序等（上）","slug":"c-language-byte-alignment-problem-in-detail-part-1","date":"2014-07-21T07:32:28.000Z","updated":"2021-09-06T03:36:20.927Z","comments":true,"path":"2014/07/21/c-language-byte-alignment-problem-in-detail-part-1/","link":"","permalink":"http://dbkernel.github.io/2014/07/21/c-language-byte-alignment-problem-in-detail-part-1/","excerpt":"","text":"1. 引言考虑下面的结构体定义： 123456typedef struct&#123; char c1; short s; char c2; int i;&#125;T_FOO; 假设这个结构体的成员在内存中是紧凑排列的，且c1的起始地址是0，则s的地址就是1，c2的地址是3，i的地址是4。 现在，我们编写一个简单的程序： 123456789int main(void)&#123; T_FOO a; printf(&quot;c1 -&gt; %d, s -&gt; %d, c2 -&gt; %d, i -&gt; %d\\n&quot;, (unsigned int)(void*)&amp;a.c1 - (unsigned int)(void*)&amp;a, (unsigned int)(void*)&amp;a.s - (unsigned int)(void*)&amp;a, (unsigned int)(void*)&amp;a.c2 - (unsigned int)(void*)&amp;a, (unsigned int)(void*)&amp;a.i - (unsigned int)(void*)&amp;a); return 0;&#125; 运行后输出： 1c1 -&gt; 0, s -&gt; 2, c2 -&gt; 4, i -&gt; 8 为什么会这样？这就是字节对齐导致的问题。 本文在参考诸多资料的基础上，详细介绍常见的字节对齐问题。因成文较早，资料来源大多已不可考，敬请谅解。 2. 什么是字节对齐现代计算机中，内存空间按照字节划分，理论上可以从任何起始地址访问任意类型的变量，但实际上在访问特定类型变量时经常在特定的内存地址访问，这就需要各种类型数据按照一定的规则在空间上排列，而不是一个接一个地顺序存放，这就是对齐。 3. 对齐的原因和作用 不同硬件平台对存储空间的处理上存在很大的不同。某些平台对特定类型的数据只能从特定地址开始存取，而不允许其在内存中任意存放。例如 Motorola 68000 处理器不允许16位的字存放在奇地址，否则会触发异常，因此在这种架构下编程必须保证字节对齐。 如果不按照平台要求对数据存放进行对齐，会带来存取效率上的损失。比如32位的 Intel 处理器通过总线访问(包括读和写)内存数据。每个总线周期从偶地址开始访问32位内存数据，内存数据以字节为单位存放。如果一个32位的数据没有存放在4字节整除的内存地址处，那么处理器就需要2个总线周期对其进行访问，显然访问效率下降很多。因此，通过合理的内存对齐可以提高访问效率。 为使CPU能够对数据进行快速访问，数据的起始地址应具有“对齐”特性。比如4字节数据的起始地址应位于4字节边界上，即起始地址能够被4整除。 合理利用字节对齐还可以有效地节省存储空间。但要注意，在32位机中使用1字节或2字节对齐，反而会降低变量访问速度，因此，需要考虑处理器类型。同时，还应考虑编译器的类型，在VC/C++和GNU GCC中都是默认是4字节对齐。 4. 对齐的分类和准则本小节主要基于 Intel X86 架构介绍结构体对齐和栈内存对齐，位域本质上为结构体类型。 对于 Intel X86 平台，每次分配内存应该是从4的整数倍地址开始分配，无论是对结构体变量还是简单类型的变量。 4.1. 结构体对齐在C语言中，结构体是种复合数据类型，其构成元素既可以是基本数据类型（int、long、float等）的变量，也可以是一些复合数据类型（数组、结构体、联合等)的数据单元。编译器为结构体的每个成员按照其自然边界（alignment）分配空间。各成员按照它们被声明的顺序在内存中顺序存储，第一个成员的地址和整个结构的地址相同。 字节对齐的问题主要就是针对结构体。 4.1.1. 简单示例先看个简单的例子（32位，X86处理器，GCC编译器）： 【例1】假设结构体定义如下： 1234567891011struct A&#123; int a; char b; short c;&#125;;struct B&#123; char b; int a; short c;&#125;; 已知32位机器上各数据类型的长度为：char为1字节、short为2字节、int为4字节、long为4字节、float为4字节、double为8字节。那么上面两个结构体大小如何呢？ 结果是：sizeof(strcut A)值为8；sizeof(struct B)的值却是12。 结构体A和B中字段一样，包含一个4字节的int数据，一个1字节char数据和一个2字节short数据，只是顺序不同。按理说A和B大小应该都是7字节，之所以出现上述结果，就是因为编译器要对数据成员在空间上进行对齐。 4.1.2. 对齐准则先来看四个重要的基本概念： 数据类型自身的对齐值：char型数据自身对齐值为1字节，short型数据为2字节，int/float型为4字节，double型为8字节。 结构体或类的自身对齐值：其成员中自身对齐值最大的那个值。 指定对齐值：#pragma pack (value) 指定对齐值 value。 数据成员、结构体和类的有效对齐值：自身对齐值和指定对齐值中较小者，即有效对齐值=min&#123;自身对齐值，当前指定的pack值&#125;。 基于上面这些原则，就可以方便地讨论具体数据结构的成员和其自身的对齐方式。 其中，有效对齐值 N 是最终用来决定数据存放地址方式的值。有效对齐值 N 表示“对齐在N上”，即该数据的存放起始地址 % N = 0。而数据结构中的数据变量都是按定义的先后顺序存放。第一个数据变量的起始地址就是数据结构的起始地址。结构体的成员变量要对齐存放，结构体本身也要根据自身的有效对齐值圆整（即结构体成员变量占用总长度为结构体有效对齐值的整数倍）。 以此分析3.1.1节中的结构体B： 假设B从地址空间0x0000开始存放，且指定对齐值默认为4(4字节对齐)。成员变量b的自身对齐值是1，比默认指定对齐值4小，所以其有效对齐值为1，其存放地址0x0000符合0x0000%1=0。 成员变量a自身对齐值为4，所以有效对齐值也为4，只能存放在起始地址为0x0004~0x0007四个连续的字节空间中，符合0x0004%4=0且紧靠第一个变量。 变量c自身对齐值为2，所以有效对齐值也是2，可存放在0x0008~0x0009两个字节空间中，符合0x0008%2=0。 所以从0x0000~0x0009存放的都是B内容。 再看数据结构B的自身对齐值为其变量中最大对齐值（这里是b），也就是4，所以结构体的有效对齐值也是4。根据结构体圆整的要求，0x0000~0x0009=10字节，(10＋2)％4＝0。 所以0x0000A~0x000B也为结构体B所占用。故B从0x0000到0x000B，共有12个字节，sizeof(struct B)=12。 之所以编译器在后面补充2个字节，是为了实现结构数组的存取效率。试想如果定义一个结构B的数组，那么第一个结构起始地址是0没有问题，但是第二个结构呢？ 按照数组的定义，数组中所有元素都紧挨着。如果我们不把结构体大小补充为4的整数倍，那么下一个结构的起始地址将是0x0000A，这显然不能满足结构的地址对齐。因此要把结构体补充成有效对齐大小的整数倍。 其实对于char/short/int/float/double等已有类型的自身对齐值也是基于数组考虑的，只是因为这些类型的长度已知，所以他们的自身对齐值也就已知。 上面的概念非常便于理解，不过个人还是更喜欢下面的对齐准则。 结构体字节对齐的细节和具体编译器实现相关，但一般而言满足三个准则： 结构体变量的首地址能够被其最宽基本类型成员的大小所整除； 结构体每个成员相对结构体首地址的偏移量(offset)都是成员大小的整数倍，如有需要编译器会在成员之间加上填充字节(internal adding)； 结构体的总大小为结构体最宽基本类型成员大小的整数倍，如有需要编译器会在最末一个成员之后加上填充字节{trailing padding}。 对于以上规则的说明如下： 第一条：编译器在给结构体开辟空间时，首先找到结构体中最宽的基本数据类型，然后寻找内存地址能被该基本数据类型所整除的位置，作为结构体的首地址。将这个最宽的基本数据类型的大小作为上面介绍的对齐模数。 第二条：为结构体的一个成员开辟空间之前，编译器首先检查预开辟空间的首地址相对于结构体首地址的偏移是否是本成员大小的整数倍，若是，则存放本成员，反之，则在本成员和上一个成员之间填充一定的字节，以达到整数倍的要求，也就是将预开辟空间的首地址后移几个字节。 第三条：结构体总大小是包括填充字节，最后一个成员满足上面两条以外，还必须满足第三条，否则就必须在最后填充几个字节以达到本条要求。 【例2】假设4字节对齐，以下程序的输出结果是多少？ 1234567891011121314151617/* OFFSET宏定义可取得指定结构体某成员在结构体内部的偏移 */#define OFFSET(st, field) (size_t)&amp;(((st*)0)-&gt;field)typedef struct&#123; char a; short b; char c; int d; char e[3];&#125;T_Test;int main(void)&#123; printf(&quot;Size = %d\\n a-%d, b-%d, c-%d, d-%d\\n e[0]-%d, e[1]-%d, e[2]-%d\\n&quot;, sizeof(T_Test), OFFSET(T_Test, a), OFFSET(T_Test, b), OFFSET(T_Test, c), OFFSET(T_Test, d), OFFSET(T_Test, e[0]), OFFSET(T_Test, e[1]),OFFSET(T_Test, e[2])); return 0;&#125; 执行后输出如下： 123Size = 16a-0, b-2, c-4, d-8e[0]-12, e[1]-13, e[2]-14 下面来具体分析： 首先char a占用1个字节，没问题。 short b本身占用2个字节，根据上面准则2，需要在b和a之间填充1个字节。 char c占用1个字节，没问题。 int d本身占用4个字节，根据准则2，需要在d和c之间填充3个字节。 char e[3]；本身占用3个字节，根据原则3，需要在其后补充1个字节。 因此，sizeof(T_Test) = 1 + 1 + 2 + 1 + 3 + 4 + 3 + 1 = 16字节。 4.1.3. 对齐的隐患4.1.3.1. 数据类型转换代码中关于对齐的隐患，很多是隐式的。例如，在强制类型转换的时候： 12345678int main(void)&#123; unsigned int i = 0x12345678; unsigned char *p = (unsigned char *)&amp;i; *p = 0x00; unsigned short *p1 = (unsigned short *)(p+1); *p1 = 0x0000; return 0;&#125; 最后两句代码，从奇数边界去访问 unsigned short 型变量，显然不符合对齐的规定。在X86上，类似的操作只会影响效率；但在MIPS或者SPARC上可能导致error，因为它们要求必须字节对齐。 又如对于3.1.1节的结构体 struct B，定义如下函数： 123void Func(struct B *p)&#123; //Code&#125; 在函数体内如果直接访问 p-&gt;a，则很可能会异常。因为MIPS认为a是int，其地址应该是4的倍数，但p-&gt;a的地址很可能不是4的倍数。 如果p的地址不在对齐边界上就可能出问题，比如p来自一个跨CPU的数据包(多种数据类型的数据被按顺序放置在一个数据包中传输)，或p是经过指针移位算出来的。因此要特别注意跨CPU数据的接口函数对接口输入数据的处理，以及指针移位再强制转换为结构指针进行访问时的安全性。 解决方式如下： 定义一个此结构的局部变量，用memmove方式将数据拷贝进来。12345void Func(struct B *p)&#123; struct B tData; memmove(&amp;tData, p, sizeof(struct B)); //此后可安全访问tData.a，因为编译器已将tData分配在正确的起始地址上&#125; 注意：如果能确定p的起始地址没问题，则不需要这么处理；如果不能确定（比如跨CPU输入数据、或指针移位运算出来的数据），则需要这样处理。 用#pragma pack (1)将 STRUCT_T 定义为1字节对齐方式。 4.1.3.2. 处理器间数据通信处理器间通过消息（对于C/C++而言就是结构体）进行通信时，需要注意字节对齐以及字节序的问题。 大多数编译器提供一些内存选项供用户使用。这样用户可以根据处理器的情况选择不同的字节对齐方式。例如：C/C++编译器提供的#pragma pack(n) n=1，2，4等，让编译器在生成目标文件时，使内存数据按照指定的方式排布在1，2，4等字节整除的内存地址处。 然而在不同编译平台或处理器上，字节对齐会造成消息结构长度的变化。编译器为了使字节对齐可能会对消息结构体进行填充，不同编译平台可能填充为不同的形式，大大增加处理器间数据通信的风险。 下面以32位处理器为例，提出一种内存对齐方法以解决上述问题。 对于本地使用的数据结构，为提高内存访问效率，采用4字节对齐方式；同时为了减少内存的开销，合理安排结构体成员的位置，减少4字节对齐导致的成员之间的空隙，降低内存开销。 对于处理器之间的数据结构，需要保证消息长度不会因不同编译平台或处理器而导致消息结构体长度发生变化，使用1字节对齐方式对消息结构进行紧缩；为保证处理器之间的消息数据结构的内存访问效率，采用字节填充的方式自己对消息中成员进行4字节对齐。 数据结构的成员位置要兼顾成员之间的关系、数据访问效率和空间利用率。顺序安排原则是：4字节的放在最前面，2字节的紧接最后一个4字节成员，1字节紧接最后一个2字节成员，填充字节放在最后。 举例如下： 1234567typedef struct tag_T_MSG&#123; long ParaA; long ParaB; short ParaC； char ParaD; char Pad; //填充字节&#125;T_MSG; 4.1.3.3. 排查对齐问题如果出现对齐或者赋值问题，可查看： 编译器的字节序大小端设置； 处理器架构本身是否支持非对齐访问； 如果支持，则看是否设置对齐； 如果没有，则看访问时是否需要加某些特殊的修饰来标志其特殊访问操作。 4.1.4. 更改对齐方式主要是更改C编译器的缺省字节对齐方式。 在缺省情况下，C编译器为每一个变量或是数据单元按其自然对界条件分配空间。一般地，可以通过下面的方法来改变缺省的对界条件： 使用伪指令#pragma pack(n)：C编译器将按照n个字节对齐； 使用伪指令#pragma pack()：取消自定义字节对齐方式。 另外，还有如下的一种方式（GCC特有语法）： __attribute__((aligned (n)))：让所作用的结构成员对齐在n字节自然边界上。如果结构体中有成员的长度大于n，则按照最大成员的长度来对齐。 __attribute__((packed))：取消结构在编译过程中的优化对齐，按照实际占用字节数进行对齐。 注意： __attribute__机制是GCC的一大特色，可以设置函数属性(Function Attribute)、变量属性(Variable Attribute)和类型属性(Type Attribute)。 在编码时，可用#pragma pack动态修改对齐值。具体语法说明见附录5.3节。 自定义对齐值后要用#pragma pack()来还原，否则会对后面的结构造成影响。 【例3】分析如下结构体C： 1234567#pragma pack(2) //指定按2字节对齐struct C&#123; char b; int a; short c;&#125;;#pragma pack() //取消指定对齐，恢复缺省对齐 变量b自身对齐值为1，指定对齐值为2，所以有效对齐值为1，假设C从0x0000开始，则b存放在0x0000，符合0x0000%1=0； 变量a自身对齐值为4，指定对齐值为2，所以有效对齐值为2，顺序存放在0x0002~0x0005四个连续字节中，符合0x0002%2=0。 变量c的自身对齐值为2，所以有效对齐值为2，顺序存放在0x0006~0x0007中，符合0x0006%2=0。 所以从0x0000到0x00007共8字节存放的是C的变量。 C的自身对齐值为4，所以其有效对齐值为2。又8%2=0，C只占用0x0000~0x0007的八个字节。所以sizeof(struct C)=8。 注意：结构体对齐到的字节数并非完全取决于当前指定的pack值，例如： 1234567#pragma pack(8)struct D&#123; char b; short a; char c;&#125;;#pragma pack() 虽然#pragma pack(8)，但依然按照2字节对齐，所以 sizeof(struct D) 的值为6。所以，对齐到的字节数=min｛当前指定的pack值，最大成员大小｝。 另外，GNU GCC编译器中按1字节对齐可写为以下形式： 123456#define GNUC_PACKED __attribute__((packed))struct C&#123; char b; int a; short c;&#125;GNUC_PACKED; 此时 sizeof(struct C) 的值为7。 4.2. 栈内存对齐在VC/C++中，栈的对齐方式不受结构体成员对齐选项的影响，总是保持对齐在4字节边界上。 【例4】分析栈内存对齐方式： 1234567891011121314151617181920212223#pragma pack(push, 1) //后面可改为1, 2, 4, 8struct StrtE&#123; char m1; long m2;&#125;;#pragma pack(pop)int main(void)&#123; char a; short b; int c; double d[2]; struct StrtE s; printf(&quot;a address: %p\\n&quot;, &amp;a); printf(&quot;b address: %p\\n&quot;, &amp;b); printf(&quot;c address: %p\\n&quot;, &amp;c); printf(&quot;d[0] address: %p\\n&quot;, &amp;(d[0])); printf(&quot;d[1] address: %p\\n&quot;, &amp;(d[1])); printf(&quot;s address: %p\\n&quot;, &amp;s); printf(&quot;s.m2 address: %p\\n&quot;, &amp;(s.m2)); return 0;&#125; 结果如下： 1234567a address: 0xbfc4cfffb address: 0xbfc4cffcc address: 0xbfc4cff8d[0] address: 0xbfc4cfe8d[1] address: 0xbfc4cff0s address: 0xbfc4cfe3s.m2 address: 0xbfc4cfe4 可以看出都是对齐到4字节，并且前面的char和short并没有被凑在一起（成4字节），这和结构体内的处理是不同的。 至于为什么输出的地址值是变小的，这是因为该平台下的栈是倒着“生长”的。 4.3. 位域对齐4.3.1. 位域定义有些信息在存储时，并不需要占用一个完整的字节，而只需占几个或一个二进制位。例如在存放一个开关量时，只有0和1两种状态，用一位二进位即可。为了节省存储空间和处理简便，C语言提供了一种数据结构，称为位域或位段。 位域是一种特殊的结构成员或联合成员（即只能用在结构或联合中），用于指定该成员在内存存储时所占用的位数，从而在机器内更紧凑地表示数据。每个位域有一个域名，允许在程序中按域名操作对应的位，这样就可用一个字节的二进制位域来表示几个不同的对象。 位域定义与结构定义类似，其形式为： 12struct 位域结构名 &#123; 位域列表 &#125;; 其中位域列表的形式为： 1类型说明符位域名：位域长度 位域的使用和结构成员的使用相同，其一般形式为： 1位域变量名.位域名 位域允许用各种格式输出。 位域在本质上就是一种结构类型，不过其成员是按二进位分配的。位域变量的说明与结构变量说明的方式相同，可先定义后说明、同时定义说明或直接说明。 位域的使用主要为下面两种情况： 当机器可用内存空间较少而使用位域可大量节省内存时。例如：把结构作为大数组的元素时。 当需要把一结构体或联合映射成某预定的组织结构时。例如：需要访问字节内的特定位时。 4.3.2. 对齐准则位域成员不能单独被取sizeof值。下面主要讨论含有位域的结构体的sizeof。 C99规定 int、unsigned int 和 bool 可以作为位域类型，但编译器几乎都对此作了扩展，允许其它类型的存在。位域作为嵌入式系统中非常常见的一种编程工具，优点在于压缩程序的存储空间。 其对齐规则大致为： 如果相邻位域字段的类型相同，且其位宽之和小于类型的sizeof大小，则后面的字段将紧邻前一个字段存储，直到不能容纳为止； 如果相邻位域字段的类型相同，但其位宽之和大于类型的sizeof大小，则后面的字段将从新的存储单元开始，其偏移量为其类型大小的整数倍； 如果相邻的位域字段的类型不同，则各编译器的具体实现有差异，VC6采取不压缩方式，Dev-C++和GCC采取压缩方式； 如果位域字段之间穿插着非位域字段，则不进行压缩； 整个结构体的总大小为最宽基本类型成员大小的整数倍，而位域则按照其最宽类型字节数对齐。 【例5】 12345struct BitField&#123; char element1 : 1; char element2 : 4; char element3 : 5;&#125;; 位域类型为char，第1个字节仅能容纳下element1和element2，所以element1和element2被压缩到第1个字节中，而element3只能从下一个字节开始。因此 sizeof(BitField) 的结果为2。 【例6】 12345struct BitField1&#123; char element1 : 1; short element2 : 5; char element3 : 7;&#125;; 由于相邻位域类型不同，在VC6中其sizeof为6，在Dev-C++中为2。 【例7】 12345struct BitField2&#123; char element1 : 3; char element2 ; char element3 : 5;&#125;; 非位域字段穿插在其中，不会产生压缩，在VC6和Dev-C++中得到的大小均为3。 【例8】 12345678struct StructBitField&#123; int element1 : 1; int element2 : 5; int element3 : 29; int element4 : 6; char element5 :2; char stelement; //在含位域的结构或联合中也可同时说明普通成员&#125;; 位域中最宽类型int的字节数为4，因此结构体按4字节对齐，在VC6中其sizeof为16。 4.3.3. 注意事项关于位域操作有几点需要注意： 1）位域的地址不能访问，因此不允许将&amp;运算符用于位域。不能使用指向位域的指针也不能使用位域的数组（数组是种特殊指针）。例如，scanf函数无法直接向位域中存储数据： 12345int main(void)&#123; struct BitField1 tBit; scanf(&quot;%d&quot;, &amp;tBit.element2); //error: cannot take address of bit-field &#x27;element2&#x27; return 0;&#125; 可用scanf函数将输入读入到一个普通的整型变量中，然后再赋值给tBit.element2。 2）位域不能作为函数返回的结果。3）位域以定义的类型为单位，且位域的长度不能够超过所定义类型的长度。例如：定义 int a:33 是不允许的。4）位域可以不指定位域名，但不能访问无名的位域。 位域可以无位域名，只用作填充或调整位置，占位大小取决于该类型。例如，char :0 表示整个位域向后推一个字节，即该无名位域后的下一个位域从下一个字节开始存放，同理 short :0 和 int :0 分别表示整个位域向后推两个和四个字节。 当空位域的长度为具体数值N时(如 int :2)，该变量仅用来占位N位。 【例9】 12345struct BitField3&#123; char element1 : 3; char :6; char element3 : 5;&#125;; 结构体大小为3。因为element1占3位，后面要保留6位而char为8位，所以保留的6位只能放到第2个字节。同样element3只能放到第3字节。 12345struct BitField4&#123; char element1 : 3; char :0; char element3 : 5;&#125;; 长度为0的位域告诉编译器将下一个位域放在一个存储单元的起始位置。如上，编译器会给成员element1分配3位，接着跳过余下的4位到下一个存储单元，然后给成员element3分配5位。所以，上面的结构体大小为2 。 5）位域的表示范围： 位域的赋值不能超过其可以表示的范围。 位域的类型决定该编码能表示的值的结果。 对于第二点，若位域为unsigned类型，则直接转化为正数；若非unsigned类型，则先判断最高位是否为1，若为1，则表示补码，则对其除符号位外的所有位取反再加一得到最后的结果数据（原码）。例如： 12unsigned int p:3 = 111; //p表示7int p:3 = 111; //p 表示-1，对除符号位之外的所有位取反再加一 6）带位域的结构在内存中各个位域的存储方式取决于编译器，既可从左到右也可从右到左存储。 【例10】在VC6下执行下面的代码： 1234567891011121314int main(void)&#123; union&#123; int i; struct&#123; char a : 1; char b : 1; char c : 2; &#125;bits; &#125;num; printf(&quot;Input an integer for i(0~15): &quot;); scanf(&quot;%d&quot;, &amp;num.i); printf(&quot;i = %d, cba = %d %d %d\\n&quot;, num.i, num.bits.c, num.bits.b, num.bits.a); return 0; 输入i值为11，则输出为i = 11, cba = -2 -1 -1。 Intel x86 处理器按小字节序存储数据，所以bits中的位域在内存中放置顺序为ccba。当num.i置为11时，bits的最低有效位(即位域a)的值为1，a、b、c按低地址到高地址分别存储为10、1、1(二进制)。 但为什么最后的打印结果是a=-1而不是1？ 因为位域a定义的类型signed char是有符号数，所以尽管a只有1位，仍要进行符号扩展。1做为补码存在，对应原码-1。 如果将a、b、c的类型定义为unsigned char，即可得到cba = 2 1 1。1011即为11的二进制数。 注：C语言中，不同的成员使用共同的存储区域的数据构造类型称为联合(或共用体)。联合占用空间的大小取决于类型长度最大的成员。联合在定义、说明和使用形式上与结构体相似。 7）位域的实现会因编译器的不同而不同，使用位域会影响程序可移植性。因此如无必要，最好不要使用位域。 8）尽管使用位域可以节省内存空间，但却增加了处理时间。当访问各个位域成员时，需要把位域从它所在的字中分解出来或反过来把一值压缩存到位域所在的字位中。 5. 总结让我们回到引言部分的问题。 缺省情况下，C/C++编译器默认将结构、栈中的成员数据进行内存对齐。因此，引言程序输出就变成”c1 -&gt; 0, s -&gt; 2, c2 -&gt; 4, i -&gt; 8”。 编译器将未对齐的成员向后移，将每一个都成员对齐到自然边界上，从而也导致整个结构的尺寸变大。尽管会牺牲一点空间(成员之间有空洞)，但提高了性能。 也正是这个原因，引言例子中sizeof(T_ FOO)为12，而不是8。 总结说来，就是：在结构体中，综合考虑变量本身和指定的对齐值；在栈上，不考虑变量本身的大小，统一对齐到4字节。 说明： 本文转载自 https://www.cnblogs.com/clover-toeic/p/3853132.html 欢迎关注我的微信公众号【MySQL数据库技术】。 标题 网址 GitHub https://dbkernel.github.io 知乎 https://www.zhihu.com/people/dbkernel/posts 思否（SegmentFault） https://segmentfault.com/u/dbkernel 掘金 https://juejin.im/user/5e9d3ed251882538083fed1f/posts 开源中国（oschina） https://my.oschina.net/dbkernel 博客园（cnblogs） https://www.cnblogs.com/dbkernel","categories":[{"name":"程序人生","slug":"程序人生","permalink":"http://dbkernel.github.io/categories/%E7%A8%8B%E5%BA%8F%E4%BA%BA%E7%94%9F/"},{"name":"C语言","slug":"程序人生/C语言","permalink":"http://dbkernel.github.io/categories/%E7%A8%8B%E5%BA%8F%E4%BA%BA%E7%94%9F/C%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"C语言","slug":"C语言","permalink":"http://dbkernel.github.io/tags/C%E8%AF%AD%E8%A8%80/"},{"name":"字节对齐","slug":"字节对齐","permalink":"http://dbkernel.github.io/tags/%E5%AD%97%E8%8A%82%E5%AF%B9%E9%BD%90/"},{"name":"字节序","slug":"字节序","permalink":"http://dbkernel.github.io/tags/%E5%AD%97%E8%8A%82%E5%BA%8F/"},{"name":"网络序","slug":"网络序","permalink":"http://dbkernel.github.io/tags/%E7%BD%91%E7%BB%9C%E5%BA%8F/"}]},{"title":"程序人生 | Makefile常用模板 - 静态链接库/动态链接库/可执行文件","slug":"makefile-common-templates","date":"2014-07-10T03:51:10.000Z","updated":"2021-09-04T15:21:56.375Z","comments":true,"path":"2014/07/10/makefile-common-templates/","link":"","permalink":"http://dbkernel.github.io/2014/07/10/makefile-common-templates/","excerpt":"","text":"前言本文把 makefile 分成了三份：生成可执行文件的 makefile，生成静态链接库的 makefile，生成动态链接库的 makefile。 这些 makefile 都很简单，一般都是一看就会用，用法也很容易，只需要把它们拷贝到你的代码的同一目录下，然后就可以用 make 来生成目标文件了。 下面是三个makefile的源代码： 生成可执行文件的 makefile1234567891011121314151617181920212223242526272829303132333435363738394041424344##############################################################################source file#源文件，自动找所有.c和.cpp文件，并将目标定义为同名.o文件SOURCE := $(wildcard *.c) $(wildcard *.cpp)OBJS := $(patsubst %.c,%.o,$(patsubst %.cpp,%.o,$(SOURCE)))#target you can change test to what you want#目标文件名，输入任意你想要的执行文件名TARGET := test#compile and lib parameter#编译参数CC := gccLIBS :=LDFLAGS :=DEFINES :=INCLUDE := -I.CFLAGS := -g -Wall -O3 $(DEFINES) $(INCLUDE)CXXFLAGS:= $(CFLAGS) -DHAVE_CONFIG_H#i think you should do anything here#下面的基本上不需要做任何改动了.PHONY : everything objs clean veryclean rebuildeverything : $(TARGET)all : $(TARGET)objs : $(OBJS)rebuild: veryclean everythingclean : rm -fr *.so rm -fr *.overyclean : clean rm -fr $(TARGET)$(TARGET) : $(OBJS) $(CC) $(CXXFLAGS) -o $@ $(OBJS) $(LDFLAGS) $(LIBS) 生成静态链接库的 makefile123456789101112131415161718192021222324252627282930313233343536373839404142434445464748###############################################################################target you can change test to what you want#共享库文件名，lib*.aTARGET := libtest.a#compile and lib parameter#编译参数CC := gccAR = arRANLIB = ranlibLIBS :=LDFLAGS :=DEFINES :=INCLUDE := -I.CFLAGS := -g -Wall -O3 $(DEFINES) $(INCLUDE)CXXFLAGS:= $(CFLAGS) -DHAVE_CONFIG_H#i think you should do anything here#下面的基本上不需要做任何改动了#source file#源文件，自动找所有.c和.cpp文件，并将目标定义为同名.o文件SOURCE := $(wildcard *.c) $(wildcard *.cpp)OBJS := $(patsubst %.c,%.o,$(patsubst %.cpp,%.o,$(SOURCE))).PHONY : everything objs clean veryclean rebuildeverything : $(TARGET)all : $(TARGET)objs : $(OBJS)rebuild: veryclean everythingclean : rm -fr *.overyclean : clean rm -fr $(TARGET)$(TARGET) : $(OBJS) $(AR) cru $(TARGET) $(OBJS) $(RANLIB) $(TARGET) 生成动态链接库的 makefile12345678910111213141516171819202122232425262728293031323334353637383940414243444546###############################################################################target you can change test to what you want#共享库文件名，lib*.soTARGET := libtest.so#compile and lib parameter#编译参数CC := gccLIBS :=LDFLAGS :=DEFINES :=INCLUDE := -I.CFLAGS := -g -Wall -O3 $(DEFINES) $(INCLUDE)CXXFLAGS:= $(CFLAGS) -DHAVE_CONFIG_HSHARE := -fPIC -shared -o#i think you should do anything here#下面的基本上不需要做任何改动了#source file#源文件，自动找所有.c和.cpp文件，并将目标定义为同名.o文件SOURCE := $(wildcard *.c) $(wildcard *.cpp)OBJS := $(patsubst %.c,%.o,$(patsubst %.cpp,%.o,$(SOURCE))).PHONY : everything objs clean veryclean rebuildeverything : $(TARGET)all : $(TARGET)objs : $(OBJS)rebuild: veryclean everythingclean : rm -fr *.overyclean : clean rm -fr $(TARGET)$(TARGET) : $(OBJS) $(CC) $(CXXFLAGS) $(SHARE) $@ $(OBJS) $(LDFLAGS) $(LIBS) 欢迎关注我的微信公众号【MySQL数据库技术】。 标题 网址 GitHub https://dbkernel.github.io 知乎 https://www.zhihu.com/people/dbkernel/posts 思否（SegmentFault） https://segmentfault.com/u/dbkernel 掘金 https://juejin.im/user/5e9d3ed251882538083fed1f/posts 开源中国（oschina） https://my.oschina.net/dbkernel 博客园（cnblogs） https://www.cnblogs.com/dbkernel","categories":[{"name":"程序人生","slug":"程序人生","permalink":"http://dbkernel.github.io/categories/%E7%A8%8B%E5%BA%8F%E4%BA%BA%E7%94%9F/"},{"name":"Makefile","slug":"程序人生/Makefile","permalink":"http://dbkernel.github.io/categories/%E7%A8%8B%E5%BA%8F%E4%BA%BA%E7%94%9F/Makefile/"}],"tags":[{"name":"Makefile","slug":"Makefile","permalink":"http://dbkernel.github.io/tags/Makefile/"}]},{"title":"程序人生 | UNIX环境高级编程技巧之 du 指令实现","slug":"advanced-programming-in-the-unix-environment-du","date":"2014-07-10T02:00:41.000Z","updated":"2021-08-31T15:31:32.169Z","comments":true,"path":"2014/07/10/advanced-programming-in-the-unix-environment-du/","link":"","permalink":"http://dbkernel.github.io/2014/07/10/advanced-programming-in-the-unix-environment-du/","excerpt":"","text":"代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;glob.h&gt;#include &lt;string.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/stat.h&gt;#include &lt;unistd.h&gt;#define PATHSIZE 1024static int path_noloop(const char *path)&#123; char *pos; pos = strrchr(path,&#x27;/&#x27;);//定位最右边的&#x27;/&#x27;的位置 if(strcmp(pos+1,&quot;.&quot;) == 0 || (strcmp(pos+1,&quot;..&quot;) == 0)) return 0; return 1;&#125;static int64_t mydu(const char *path)&#123; int i; glob_t globres; int64_t sum; static struct stat statres; static char nextpath[PATHSIZE]; if(lstat(path, &amp;statres) &lt; 0) &#123; perror(&quot;lstat()&quot;); return 0;//exit(1); &#125; if(!S_ISDIR(statres.st_mode)) return statres.st_blocks; strncpy(nextpath, path,PATHSIZE); strncat(nextpath, &quot;/*&quot; , PATHSIZE); glob(nextpath,GLOB_NOSORT, NULL, &amp;globres); strncpy(nextpath, path,PATHSIZE); strncat(nextpath, &quot;/.*&quot; , PATHSIZE); glob(nextpath,GLOB_NOSORT|GLOB_APPEND, NULL, &amp;globres); sum = statres.st_blocks; for(i = 0 ;i &lt; globres.gl_pathc ; i++) &#123; if(path_noloop(globres.gl_pathv[i])) sum += mydu(globres.gl_pathv[i]); &#125; return sum;&#125;int main(int argc,char **argv)&#123; if(argc &lt; 2) &#123; fprintf(stderr,&quot;Usage...\\n&quot;); exit(1); &#125; printf(&quot;%lld 512B blocks\\n&quot;, (long long int)mydu(argv[1])); return 0;&#125; 编译1$ gcc -g -Wall testdu.c -o testdu 运行 testdf执行效果：12$ ./testdu /usr/bin1766184 512B blocks 原生df执行效果：12$ du -sh /usr/bin859M /usr/bin 欢迎关注我的微信公众号【MySQL数据库技术】。 标题 网址 GitHub https://dbkernel.github.io 知乎 https://www.zhihu.com/people/dbkernel/posts 思否（SegmentFault） https://segmentfault.com/u/dbkernel 掘金 https://juejin.im/user/5e9d3ed251882538083fed1f/posts 开源中国（oschina） https://my.oschina.net/dbkernel 博客园（cnblogs） https://www.cnblogs.com/dbkernel","categories":[{"name":"程序人生","slug":"程序人生","permalink":"http://dbkernel.github.io/categories/%E7%A8%8B%E5%BA%8F%E4%BA%BA%E7%94%9F/"},{"name":"APUE","slug":"程序人生/APUE","permalink":"http://dbkernel.github.io/categories/%E7%A8%8B%E5%BA%8F%E4%BA%BA%E7%94%9F/APUE/"}],"tags":[{"name":"APUE","slug":"APUE","permalink":"http://dbkernel.github.io/tags/APUE/"},{"name":"UNIX","slug":"UNIX","permalink":"http://dbkernel.github.io/tags/UNIX/"},{"name":"du","slug":"du","permalink":"http://dbkernel.github.io/tags/du/"}]},{"title":"程序人生 | UNIX环境高级编程技巧之 df 指令实现","slug":"advanced-programming-in-the-unix-environment-df","date":"2014-07-10T01:48:48.000Z","updated":"2021-08-31T15:17:33.202Z","comments":true,"path":"2014/07/10/advanced-programming-in-the-unix-environment-df/","link":"","permalink":"http://dbkernel.github.io/2014/07/10/advanced-programming-in-the-unix-environment-df/","excerpt":"","text":"代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106#include &lt;stdio.h&gt;#include &lt;mntent.h&gt;#include &lt;string.h&gt;#include &lt;sys/vfs.h&gt;static const unsigned long long G = 1024*1024*1024ull;static const unsigned long long M = 1024*1024;static const unsigned long long K = 1024;static char str[20];char* kscale(unsigned long b, unsigned long bs)&#123; unsigned long long size = b * (unsigned long long)bs; if (size &gt; G) &#123; sprintf(str, &quot;%0.2f GB&quot;, size/(G*1.0)); return str; &#125; else if (size &gt; M) &#123; sprintf(str, &quot;%0.2f MB&quot;, size/(1.0*M)); return str; &#125; else if (size &gt; K) &#123; sprintf(str, &quot;%0.2f K&quot;, size/(1.0*K)); return str; &#125; else &#123; sprintf(str, &quot;%0.2f B&quot;, size*1.0); return str; &#125;&#125;int main(int argc, char *argv[])&#123; FILE* mount_table; struct mntent *mount_entry; struct statfs s; unsigned long blocks_used; unsigned blocks_percent_used; const char *disp_units_hdr = NULL; mount_table = NULL; mount_table = setmntent(&quot;/etc/mtab&quot;, &quot;r&quot;); if (!mount_table) &#123; fprintf(stderr, &quot;set mount entry error\\n&quot;); return -1; &#125; disp_units_hdr = &quot; Size&quot;; printf(&quot;Filesystem %-15sUsed Available %s Mounted on\\n&quot;, disp_units_hdr, &quot;Use%&quot;); while (1) &#123; const char *device; const char *mount_point; if (mount_table) &#123; mount_entry = getmntent(mount_table); if (!mount_entry) &#123; endmntent(mount_table); break; &#125; &#125; else continue; device = mount_entry-&gt;mnt_fsname; mount_point = mount_entry-&gt;mnt_dir; //fprintf(stderr, &quot;mount info: device=%s mountpoint=%s\\n&quot;, device, mount_point); if (statfs(mount_point, &amp;s) != 0) &#123; fprintf(stderr, &quot;statfs failed!\\n&quot;); continue; &#125; if ((s.f_blocks &gt; 0) || !mount_table ) &#123; blocks_used = s.f_blocks - s.f_bfree; blocks_percent_used = 0; if (blocks_used + s.f_bavail) &#123; blocks_percent_used = (blocks_used * 100ULL + (blocks_used + s.f_bavail)/2 ) / (blocks_used + s.f_bavail); &#125; /* GNU coreutils 6.10 skips certain mounts, try to be compatible. */ if (strcmp(device, &quot;rootfs&quot;) == 0) continue; if (printf(&quot;\\n%-20s&quot; + 1, device) &gt; 20) printf(&quot;\\n%-20s&quot;, &quot;&quot;); char s1[20]; char s2[20]; char s3[20]; strcpy(s1, kscale(s.f_blocks, s.f_bsize)); strcpy(s2, kscale(s.f_blocks - s.f_bfree, s.f_bsize)); strcpy(s3, kscale(s.f_bavail, s.f_bsize)); printf(&quot; %9s %9s %9s %3u%% %s\\n&quot;, s1, s2, s3, blocks_percent_used, mount_point); &#125; &#125; return 0;&#125; 编译1$ gcc -g -Wall testdf.c -o testdf 运行 testdf执行效果：1234567891011121314151617$ ./testdfFilesystem Size Used Available Use% Mounted onudev 3.87 GB 0.00 B 3.87 GB 0% /devtmpfs 796.17 MB 980.00 K 795.21 MB 0% /run/dev/vda1 96.75 GB 40.54 GB 56.19 GB 42% /tmpfs 3.89 GB 0.00 B 3.89 GB 0% /dev/shmtmpfs 5.00 MB 0.00 B 5.00 MB 0% /run/locktmpfs 3.89 GB 0.00 B 3.89 GB 0% /sys/fs/cgroup/dev/vda15 104.35 MB 3.86 MB 100.50 MB 4% /boot/efi/dev/loop1 55.50 MB 55.50 MB 0.00 B 100% /snap/core18/2074/dev/loop2 70.62 MB 70.62 MB 0.00 B 100% /snap/lxd/16922/dev/loop4 70.38 MB 70.38 MB 0.00 B 100% /snap/lxd/21029/dev/loop5 32.38 MB 32.38 MB 0.00 B 100% /snap/snapd/12704tmpfs 796.17 MB 980.00 K 795.21 MB 0% /run/snapd/nstmpfs 796.17 MB 0.00 B 796.17 MB 0% /run/user/1000/dev/loop6 55.50 MB 55.50 MB 0.00 B 100% /snap/core18/2128/dev/loop0 32.38 MB 32.38 MB 0.00 B 100% /snap/snapd/12883 原生df执行效果：12345678910111213141516$ df -hFilesystem Size Used Avail Use% Mounted onudev 3.9G 0 3.9G 0% /devtmpfs 797M 980K 796M 1% /run/dev/vda1 97G 41G 57G 42% /tmpfs 3.9G 0 3.9G 0% /dev/shmtmpfs 5.0M 0 5.0M 0% /run/locktmpfs 3.9G 0 3.9G 0% /sys/fs/cgroup/dev/vda15 105M 3.9M 101M 4% /boot/efi/dev/loop1 56M 56M 0 100% /snap/core18/2074/dev/loop2 71M 71M 0 100% /snap/lxd/16922/dev/loop4 71M 71M 0 100% /snap/lxd/21029/dev/loop5 33M 33M 0 100% /snap/snapd/12704tmpfs 797M 0 797M 0% /run/user/1000/dev/loop6 56M 56M 0 100% /snap/core18/2128/dev/loop0 33M 33M 0 100% /snap/snapd/12883 欢迎关注我的微信公众号【MySQL数据库技术】。 标题 网址 GitHub https://dbkernel.github.io 知乎 https://www.zhihu.com/people/dbkernel/posts 思否（SegmentFault） https://segmentfault.com/u/dbkernel 掘金 https://juejin.im/user/5e9d3ed251882538083fed1f/posts 开源中国（oschina） https://my.oschina.net/dbkernel 博客园（cnblogs） https://www.cnblogs.com/dbkernel","categories":[{"name":"程序人生","slug":"程序人生","permalink":"http://dbkernel.github.io/categories/%E7%A8%8B%E5%BA%8F%E4%BA%BA%E7%94%9F/"},{"name":"APUE","slug":"程序人生/APUE","permalink":"http://dbkernel.github.io/categories/%E7%A8%8B%E5%BA%8F%E4%BA%BA%E7%94%9F/APUE/"}],"tags":[{"name":"APUE","slug":"APUE","permalink":"http://dbkernel.github.io/tags/APUE/"},{"name":"UNIX","slug":"UNIX","permalink":"http://dbkernel.github.io/tags/UNIX/"},{"name":"df","slug":"df","permalink":"http://dbkernel.github.io/tags/df/"}]}],"categories":[{"name":"开源","slug":"开源","permalink":"http://dbkernel.github.io/categories/%E5%BC%80%E6%BA%90/"},{"name":"ClickHouse","slug":"ClickHouse","permalink":"http://dbkernel.github.io/categories/ClickHouse/"},{"name":"MySQL","slug":"MySQL","permalink":"http://dbkernel.github.io/categories/MySQL/"},{"name":"实用工具","slug":"实用工具","permalink":"http://dbkernel.github.io/categories/%E5%AE%9E%E7%94%A8%E5%B7%A5%E5%85%B7/"},{"name":"Linux","slug":"实用工具/Linux","permalink":"http://dbkernel.github.io/categories/%E5%AE%9E%E7%94%A8%E5%B7%A5%E5%85%B7/Linux/"},{"name":"Linux","slug":"Linux","permalink":"http://dbkernel.github.io/categories/Linux/"},{"name":"系统运维","slug":"Linux/系统运维","permalink":"http://dbkernel.github.io/categories/Linux/%E7%B3%BB%E7%BB%9F%E8%BF%90%E7%BB%B4/"},{"name":"程序人生","slug":"程序人生","permalink":"http://dbkernel.github.io/categories/%E7%A8%8B%E5%BA%8F%E4%BA%BA%E7%94%9F/"},{"name":"C语言","slug":"程序人生/C语言","permalink":"http://dbkernel.github.io/categories/%E7%A8%8B%E5%BA%8F%E4%BA%BA%E7%94%9F/C%E8%AF%AD%E8%A8%80/"},{"name":"Makefile","slug":"程序人生/Makefile","permalink":"http://dbkernel.github.io/categories/%E7%A8%8B%E5%BA%8F%E4%BA%BA%E7%94%9F/Makefile/"},{"name":"APUE","slug":"程序人生/APUE","permalink":"http://dbkernel.github.io/categories/%E7%A8%8B%E5%BA%8F%E4%BA%BA%E7%94%9F/APUE/"}],"tags":[{"name":"开源协议","slug":"开源协议","permalink":"http://dbkernel.github.io/tags/%E5%BC%80%E6%BA%90%E5%8D%8F%E8%AE%AE/"},{"name":"开源许可证","slug":"开源许可证","permalink":"http://dbkernel.github.io/tags/%E5%BC%80%E6%BA%90%E8%AE%B8%E5%8F%AF%E8%AF%81/"},{"name":"LICENCE","slug":"LICENCE","permalink":"http://dbkernel.github.io/tags/LICENCE/"},{"name":"github","slug":"github","permalink":"http://dbkernel.github.io/tags/github/"},{"name":"ClickHouse和他的朋友们","slug":"ClickHouse和他的朋友们","permalink":"http://dbkernel.github.io/tags/ClickHouse%E5%92%8C%E4%BB%96%E7%9A%84%E6%9C%8B%E5%8F%8B%E4%BB%AC/"},{"name":"ClickHouse","slug":"ClickHouse","permalink":"http://dbkernel.github.io/tags/ClickHouse/"},{"name":"源码分析","slug":"源码分析","permalink":"http://dbkernel.github.io/tags/%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"name":"MySQL","slug":"MySQL","permalink":"http://dbkernel.github.io/tags/MySQL/"},{"name":"Select","slug":"Select","permalink":"http://dbkernel.github.io/tags/Select/"},{"name":"Count","slug":"Count","permalink":"http://dbkernel.github.io/tags/Count/"},{"name":"auto_increment","slug":"auto-increment","permalink":"http://dbkernel.github.io/tags/auto-increment/"},{"name":"Linux","slug":"Linux","permalink":"http://dbkernel.github.io/tags/Linux/"},{"name":"crontab","slug":"crontab","permalink":"http://dbkernel.github.io/tags/crontab/"},{"name":"系统运维","slug":"系统运维","permalink":"http://dbkernel.github.io/tags/%E7%B3%BB%E7%BB%9F%E8%BF%90%E7%BB%B4/"},{"name":"C语言","slug":"C语言","permalink":"http://dbkernel.github.io/tags/C%E8%AF%AD%E8%A8%80/"},{"name":"字节对齐","slug":"字节对齐","permalink":"http://dbkernel.github.io/tags/%E5%AD%97%E8%8A%82%E5%AF%B9%E9%BD%90/"},{"name":"字节序","slug":"字节序","permalink":"http://dbkernel.github.io/tags/%E5%AD%97%E8%8A%82%E5%BA%8F/"},{"name":"网络序","slug":"网络序","permalink":"http://dbkernel.github.io/tags/%E7%BD%91%E7%BB%9C%E5%BA%8F/"},{"name":"Makefile","slug":"Makefile","permalink":"http://dbkernel.github.io/tags/Makefile/"},{"name":"APUE","slug":"APUE","permalink":"http://dbkernel.github.io/tags/APUE/"},{"name":"UNIX","slug":"UNIX","permalink":"http://dbkernel.github.io/tags/UNIX/"},{"name":"du","slug":"du","permalink":"http://dbkernel.github.io/tags/du/"},{"name":"df","slug":"df","permalink":"http://dbkernel.github.io/tags/df/"}]}