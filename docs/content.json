{"meta":{"title":"DBKernel","subtitle":"","description":"专注于数据库技术分享","author":"DBKernel","url":"http://dbkernel.github.io","root":"/"},"pages":[{"title":"分类","date":"2021-07-10T09:34:18.000Z","updated":"2021-07-10T10:49:25.987Z","comments":false,"path":"categories/index.html","permalink":"http://dbkernel.github.io/categories/index.html","excerpt":"","text":""},{"title":"标签","date":"2017-05-27T05:47:40.000Z","updated":"2021-07-10T13:50:19.870Z","comments":false,"path":"tags/index.html","permalink":"http://dbkernel.github.io/tags/index.html","excerpt":"","text":"-"},{"title":"关于","date":"2021-07-10T05:47:55.000Z","updated":"2021-07-10T13:59:06.317Z","comments":false,"path":"about/index.html","permalink":"http://dbkernel.github.io/about/index.html","excerpt":"","text":"简介卢文双 xxx yyy"},{"title":"友情链接","date":"2021-07-11T13:25:13.262Z","updated":"2021-07-11T13:25:13.213Z","comments":true,"path":"links/index.html","permalink":"http://dbkernel.github.io/links/index.html","excerpt":"","text":"微信公众号：MySQL数据库技术"},{"title":"项目","date":"2021-07-11T13:27:01.021Z","updated":"2021-07-11T13:27:00.986Z","comments":true,"path":"repository/index.html","permalink":"http://dbkernel.github.io/repository/index.html","excerpt":"","text":""}],"posts":[{"title":"ClickHouse和他的朋友们（3）MySQL Protocol和Write调用栈","slug":"clickhouse-and-friends-03-mysql-protocol-write-stack","date":"2020-06-08T11:57:10.000Z","updated":"2021-07-21T15:28:28.257Z","comments":true,"path":"2020/06/08/clickhouse-and-friends-03-mysql-protocol-write-stack/","link":"","permalink":"http://dbkernel.github.io/2020/06/08/clickhouse-and-friends-03-mysql-protocol-write-stack/","excerpt":"","text":"《ClickHouse和他的朋友们》系列文章转载自圈内好友 BohuTANG 的博客，原文链接：https://bohutang.me/2020/06/08/clickhouse-and-friends-mysql-protocol-write-stack/以下为正文。 上篇的MySQL Protocol和Read调用里介绍了 ClickHouse 一条查询语句的调用栈，本文继续介绍写的调用栈，开整。 Write请求 建表: 12mysql&gt; CREATE TABLE test(a UInt8, b UInt8, c UInt8) ENGINE=MergeTree() PARTITION BY (a, b) ORDER BY c;Query OK, 0 rows affected (0.03 sec) 写入数据： 1INSERT INTO test VALUES(1,1,1), (2,2,2); 调用栈分析1. 获取存储引擎 OutputStream1234567DB::StorageMergeTree::write(std::__1::shared_ptr&lt;DB::IAST&gt; const&amp;, DB::Context const&amp;) StorageMergeTree.cpp:174DB::PushingToViewsBlockOutputStream::PushingToViewsBlockOutputStream(std::__1::shared_ptr&lt;DB::IStorage&gt; const&amp;, DB::Context const&amp;, std::__1::shared_ptr&lt;DB::IAST&gt; const&amp;, bool) PushingToViewsBlockOutputStream.cpp:110DB::InterpreterInsertQuery::execute() InterpreterInsertQuery.cpp:229DB::executeQueryImpl(const char *, const char *, DB::Context &amp;, bool, DB::QueryProcessingStage::Enum, bool, DB::ReadBuffer *) executeQuery.cpp:364DB::executeQuery(DB::ReadBuffer&amp;, DB::WriteBuffer&amp;, bool, DB::Context&amp;, std::__1::function&lt;void (std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;)&gt;) executeQuery.cpp:696DB::MySQLHandler::comQuery(DB::ReadBuffer&amp;) MySQLHandler.cpp:311DB::MySQLHandler::run() MySQLHandler.cpp:141 2. 从 SQL 组装 InputStream(1,1,1), (2,2,2) 如何组装成 inputstream 结构呢？ 12345DB::InputStreamFromASTInsertQuery::InputStreamFromASTInsertQuery(std::__1::shared_ptr&lt;DB::IAST&gt; const&amp;, DB::ReadBuffer*,DB::InterpreterInsertQuery::execute() InterpreterInsertQuery.cpp:300DB::executeQueryImpl(char const*, char const*, DB::Context&amp;, bool, DB::QueryProcessingStage::Enum, bool, DB::ReadBuffer*) executeQuery.cpp:386DB::MySQLHandler::comQuery(DB::ReadBuffer&amp;) MySQLHandler.cpp:313DB::MySQLHandler::run() MySQLHandler.cpp:150 然后 12res.in = std::make_shared&lt;InputStreamFromASTInsertQuery&gt;(query_ptr, nullptr, query_sample_block, context, nullptr);res.in = std::make_shared&lt;NullAndDoCopyBlockInputStream&gt;(res.in, out_streams.at(0)); 通过 NullAndDoCopyBlockInputStream的 copyData 方法构造出 Block： 12345678910111213141516DB::ValuesBlockInputFormat::readRow(std::__1::vector&lt;COW&lt;DB::IColumn&gt;::mutable_ptr&lt;DB::IColumn&gt;, std::__1::allocator&lt;COW&lt;DB::IColumn&gt;::mutable_ptr&lt;DB::IColumn&gt; &gt; &gt;&amp;, unsigned long) ValuesBlockInputFormat.cpp:93DB::ValuesBlockInputFormat::generate() ValuesBlockInputFormat.cpp:55DB::ISource::work() ISource.cpp:48DB::InputStreamFromInputFormat::readImpl() InputStreamFromInputFormat.h:48DB::IBlockInputStream::read() IBlockInputStream.cpp:57DB::InputStreamFromASTInsertQuery::readImpl() InputStreamFromASTInsertQuery.h:31DB::IBlockInputStream::read() IBlockInputStream.cpp:57void DB::copyDataImpl&lt;DB::copyData(DB::IBlockInputStream&amp;, DB::IBlockOutputStream&amp;, std::__1::atomic&lt;bool&gt;*)::$_0&amp;, void (&amp;)(DB::Block const&amp;)&gt;(DB::IBlockInputStream&amp;, DB::IBlockOutputStream&amp;, DB::copyData(DB::IBlockInputStream&amp;, DB::IBlockOutputStream&amp;, std::__1::atomic&lt;bool&gt;*)::$_0&amp;, void (&amp;)(DB::Block const&amp;)) copyData.cpp:26DB::copyData(DB::IBlockInputStream&amp;, DB::IBlockOutputStream&amp;, std::__1::atomic&lt;bool&gt;*) copyData.cpp:62DB::NullAndDoCopyBlockInputStream::readImpl() NullAndDoCopyBlockInputStream.h:47DB::IBlockInputStream::read() IBlockInputStream.cpp:57void DB::copyDataImpl&lt;std::__1::function&lt;bool ()&gt; const&amp;, std::__1::function&lt;void (DB::Block const&amp;)&gt; const&amp;&gt;(DB::IBlockInputStream&amp;, DB::IBlockOutputStream&amp;, std::__1::function&lt;bool ()&gt; const&amp;, std::__1::function&lt;void (DB::Block const&amp;)&gt; const&amp;) copyData.cpp:26DB::copyData(DB::IBlockInputStream&amp;, DB::IBlockOutputStream&amp;, std::__1::function&lt;bool ()&gt; const&amp;, std::__1::function&lt;void (DB::Block const&amp;)&gt; const&amp;) copyData.cpp:73DB::executeQuery(DB::ReadBuffer&amp;, DB::WriteBuffer&amp;, bool, DB::Context&amp;, std::__1::function&lt;void (std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;)&gt;) executeQuery.cpp:785DB::MySQLHandler::comQuery(DB::ReadBuffer&amp;) MySQLHandler.cpp:313DB::MySQLHandler::run() MySQLHandler.cpp:150 3. 组装 OutputStream12345DB::InterpreterInsertQuery::execute() InterpreterInsertQuery.cpp:107DB::executeQueryImpl(const char *, const char *, DB::Context &amp;, bool, DB::QueryProcessingStage::Enum, bool, DB::ReadBuffer *) executeQuery.cpp:364DB::executeQuery(DB::ReadBuffer&amp;, DB::WriteBuffer&amp;, bool, DB::Context&amp;, std::__1::function&lt;void (std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;)&gt;) executeQuery.cpp:696DB::MySQLHandler::comQuery(DB::ReadBuffer&amp;) MySQLHandler.cpp:311DB::MySQLHandler::run() MySQLHandler.cpp:141 组装顺序: NullAndDoCopyBlockInputStream CountingBlockOutputStream AddingDefaultBlockOutputStream SquashingBlockOutputStream PushingToViewsBlockOutputStream MergeTreeBlockOutputStream 4. 写入OutputStream123456789101112131415DB::MergeTreeBlockOutputStream::write(DB::Block const&amp;) MergeTreeBlockOutputStream.cpp:17DB::PushingToViewsBlockOutputStream::write(DB::Block const&amp;) PushingToViewsBlockOutputStream.cpp:145DB::SquashingBlockOutputStream::finalize() SquashingBlockOutputStream.cpp:30DB::SquashingBlockOutputStream::writeSuffix() SquashingBlockOutputStream.cpp:50DB::AddingDefaultBlockOutputStream::writeSuffix() AddingDefaultBlockOutputStream.cpp:25DB::CountingBlockOutputStream::writeSuffix() CountingBlockOutputStream.h:37DB::copyDataImpl&lt;DB::copyData(DB::IBlockInputStream&amp;, DB::IBlockOutputStream&amp;, std::__1::atomic&lt;bool&gt;*)::&lt;lambda()&gt;&amp;, void (&amp;)(const DB::Block&amp;)&gt;(DB::IBlockInputStream &amp;, DB::IBlockOutputStream &amp;, &lt;lambda()&gt; &amp;, void (&amp;)(const DB::Block &amp;)) copyData.cpp:52DB::copyData(DB::IBlockInputStream&amp;, DB::IBlockOutputStream&amp;, std::__1::atomic&lt;bool&gt;*) copyData.cpp:138DB::NullAndDoCopyBlockInputStream::readImpl() NullAndDoCopyBlockInputStream.h:57DB::IBlockInputStream::read() IBlockInputStream.cpp:60void DB::copyDataImpl&lt;std::__1::function&lt;bool ()&gt; const&amp;, std::__1::function&lt;void (DB::Block const&amp;)&gt; const&amp;&gt;(DB::IBlockInputStream&amp;, DB::IBlockOutputStream&amp;, std::__1::function&lt;bool ()&gt; const&amp;, std::__1::function&lt;void (DB::Block const&amp;)&gt; const&amp;) copyData.cpp:29DB::copyData(DB::IBlockInputStream&amp;, DB::IBlockOutputStream&amp;, std::__1::function&lt;bool ()&gt; const&amp;, std::__1::function&lt;void (DB::Block const&amp;)&gt; const&amp;) copyData.cpp:154DB::executeQuery(DB::ReadBuffer&amp;, DB::WriteBuffer&amp;, bool, DB::Context&amp;, std::__1::function&lt;void (std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;)&gt;) executeQuery.cpp:748DB::MySQLHandler::comQuery(DB::ReadBuffer&amp;) MySQLHandler.cpp:311DB::MySQLHandler::run() MySQLHandler.cpp:141 通过 copyData 方法，让数据在 OutputStream 间层层透传，一直到 MergeTreeBlockOutputStream。 5. 返回 Client123456789DB::MySQLOutputFormat::finalize() MySQLOutputFormat.cpp:62DB::IOutputFormat::doWriteSuffix() IOutputFormat.h:78DB::OutputStreamToOutputFormat::writeSuffix() OutputStreamToOutputFormat.cpp:18DB::MaterializingBlockOutputStream::writeSuffix() MaterializingBlockOutputStream.h:22void DB::copyDataImpl&lt;std::__1::function&lt;bool ()&gt; const&amp;, std::__1::function&lt;void (DB::Block const&amp;)&gt; const&amp;&gt;(DB::IBlockInputStream&amp;, DB::IBlockOutputStream&amp;, std::__1::function&lt;bool ()&gt; const&amp;, std::__1::function&lt;void (DB::Block const&amp;)&gt; const&amp;) copyData.cpp:52DB::copyData(DB::IBlockInputStream&amp;, DB::IBlockOutputStream&amp;, std::__1::function&lt;bool ()&gt; const&amp;, std::__1::function&lt;void (DB::Block const&amp;)&gt; const&amp;) copyData.cpp:154DB::executeQuery(DB::ReadBuffer&amp;, DB::WriteBuffer&amp;, bool, DB::Context&amp;, std::__1::function&lt;void (std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;)&gt;) executeQuery.cpp:748DB::MySQLHandler::comQuery(DB::ReadBuffer&amp;) MySQLHandler.cpp:311DB::MySQLHandler::run() MySQLHandler.cpp:141 总结1INSERT INTO test VALUES(1,1,1), (2,2,2); 首先内核解析 SQL 语句生成 AST，根据 AST 获取 Interpreter：InterpreterInsertQuery。其次 Interpreter 依次添加相应的 OutputStream。然后从 InputStream 读取数据，写入到 OutputStream，stream 会层层渗透，一直写到底层的存储引擎。最后写入到 Socket Output，返回结果。 ClickHouse 的 OutputStream 编排还是比较复杂，缺少类似 Pipeline 的调度和编排，但是由于模式比较固化，目前看还算清晰。","categories":[{"name":"ClickHouse","slug":"ClickHouse","permalink":"http://dbkernel.github.io/categories/ClickHouse/"}],"tags":[{"name":"ClickHouse和他的朋友们","slug":"ClickHouse和他的朋友们","permalink":"http://dbkernel.github.io/tags/ClickHouse%E5%92%8C%E4%BB%96%E7%9A%84%E6%9C%8B%E5%8F%8B%E4%BB%AC/"},{"name":"ClickHouse","slug":"ClickHouse","permalink":"http://dbkernel.github.io/tags/ClickHouse/"}]},{"title":"ClickHouse和他的朋友们（2）MySQL Protocol和Read调用栈","slug":"clickhouse-and-friends-02-mysql-protocol-read-stack","date":"2020-06-07T09:17:10.000Z","updated":"2021-07-21T09:30:56.053Z","comments":true,"path":"2020/06/07/clickhouse-and-friends-02-mysql-protocol-read-stack/","link":"","permalink":"http://dbkernel.github.io/2020/06/07/clickhouse-and-friends-02-mysql-protocol-read-stack/","excerpt":"","text":"《ClickHouse和他的朋友们》系列文章转载自圈内好友 BohuTANG 的博客，原文链接：https://bohutang.me/2020/06/07/clickhouse-and-friends-mysql-protocol-read-stack/以下为正文。 作为一个 OLAP 的 DBMS 来说，有2个端非常重要： 用户如何方便的链进来，这是入口端 ClickHouse 除了自己的 client 外，还提供了 MySQL/PG/GRPC/HTTP 等接入方式 数据如何方便的挂上去，这是数据源端 ClickHouse 除了自己的引擎外，还可以挂载 MySQL/Kafka 等外部数据源 这样内外互通，多条朋友多条路，以实现“数据”级的编排能力。 今天谈的是入口端的 MySQL 协议，也是本系列 ClickHouse 的第一个好朋友，用户可通过 MySQL 客户端或相关 Driver 直接链接到 ClickHouse，进行数据读写等操作。 本文通过 MySQL的 Query 请求，借用调用栈来了解下 ClickHouse 的数据读取全过程。 如何实现？入口文件在:MySQLHandler.cpp 握手协议 MySQLClient 发送 Greeting 数据报文到 MySQLHandler MySQLHandler 回复一个 Greeting-Response 报文 MySQLClient 发送认证报文 MySQLHandler 对认证报文进行鉴权，并返回鉴权结果 MySQL Protocol 实现在: Core/MySQLProtocol.h 最近的代码中调整为了 Core/MySQL/PacketsProtocolText.h Query请求当认证通过后，就可以进行正常的数据交互了。 当 MySQLClient 发送请求: 1mysql&gt; SELECT * FROM system.numbers LIMIT 5; MySQLHandler 的调用栈： 1-&gt;MySQLHandler::comQuery -&gt; executeQuery -&gt; pipeline-&gt;execute -&gt; MySQLOutputFormat::consume MySQLClient 接收到结果 在步骤2里，executeQuery(executeQuery.cpp)非常重要。它是所有前端 Server 和 ClickHouse 内核的接入口，第一个参数是 SQL 文本(‘select 1’)，第二个参数是结果集要发送到哪里去(socket net)。 调用栈分析1SELECT * FROM system.numbers LIMIT 5 1. 获取数据源StorageSystemNumbers 数据源： 123456789101112DB::StorageSystemNumbers::read(std::__1::vector&lt;std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt;, std::__1::allocator&lt;std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; &gt; &gt; const&amp;, std::__1::shared_ptr&lt;DB::StorageInMemoryMetadata const&gt; const&amp;, DB::SelectQueryInfo const&amp;, DB::Context const&amp;, DB::QueryProcessingStage::Enum, unsigned long, unsigned int) StorageSystemNumbers.cpp:135DB::ReadFromStorageStep::ReadFromStorageStep(std::__1::shared_ptr&lt;DB::RWLockImpl::LockHolderImpl&gt;, std::__1::shared_ptr&lt;DB::StorageInMemoryMetadata const&gt;&amp;, DB::SelectQueryOptions,DB::InterpreterSelectQuery::executeFetchColumns(DB::QueryProcessingStage::Enum, DB::QueryPlan&amp;, std::__1::shared_ptr&lt;DB::PrewhereInfo&gt; const&amp;, std::__1::vector&lt;std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt;, std::__1::allocator&lt;std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; &gt; &gt; const&amp;) memory:3028DB::InterpreterSelectQuery::executeFetchColumns(DB::QueryProcessingStage::Enum, DB::QueryPlan&amp;, std::__1::shared_ptr&lt;DB::PrewhereInfo&gt; const&amp;, std::__1::vector&lt;std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt;, std::__1::allocator&lt;std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; &gt; &gt; const&amp;) InterpreterSelectQuery.cpp:1361DB::InterpreterSelectQuery::executeImpl(DB::QueryPlan&amp;, std::__1::shared_ptr&lt;DB::IBlockInputStream&gt; const&amp;, std::__1::optional&lt;DB::Pipe&gt;) InterpreterSelectQuery.cpp:791DB::InterpreterSelectQuery::buildQueryPlan(DB::QueryPlan&amp;) InterpreterSelectQuery.cpp:472DB::InterpreterSelectWithUnionQuery::buildQueryPlan(DB::QueryPlan&amp;) InterpreterSelectWithUnionQuery.cpp:183DB::InterpreterSelectWithUnionQuery::execute() InterpreterSelectWithUnionQuery.cpp:198DB::executeQueryImpl(const char *, const char *, DB::Context &amp;, bool, DB::QueryProcessingStage::Enum, bool, DB::ReadBuffer *) executeQuery.cpp:385DB::executeQuery(DB::ReadBuffer&amp;, DB::WriteBuffer&amp;, bool, DB::Context&amp;, std::__1::function&lt;void (std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;,DB::MySQLHandler::comQuery(DB::ReadBuffer&amp;) MySQLHandler.cpp:307DB::MySQLHandler::run() MySQLHandler.cpp:141 这里最主要的是 ReadFromStorageStep 函数，从不同 storage 里获取数据源 pipe: 1Pipes pipes = storage-&gt;read(required_columns, metadata_snapshot, query_info, *context, processing_stage, max_block_size, max_streams); 2. Pipeline构造12345678910111213DB::LimitTransform::LimitTransform(DB::Block const&amp;, unsigned long, unsigned long, unsigned long, bool, bool, std::__1::vector&lt;DB::SortColumnDescription, std::__1::allocator&lt;DB::SortColumnDescription&gt; &gt;) LimitTransform.cpp:21DB::LimitStep::transformPipeline(DB::QueryPipeline&amp;) memory:2214DB::LimitStep::transformPipeline(DB::QueryPipeline&amp;) memory:2299DB::LimitStep::transformPipeline(DB::QueryPipeline&amp;) memory:3570DB::LimitStep::transformPipeline(DB::QueryPipeline&amp;) memory:4400DB::LimitStep::transformPipeline(DB::QueryPipeline&amp;) LimitStep.cpp:33DB::ITransformingStep::updatePipeline(std::__1::vector&lt;std::__1::unique_ptr&lt;DB::QueryPipeline, std::__1::default_delete&lt;DB::QueryPipeline&gt; &gt;, std::__1::allocator&lt;std::__1::unique_ptr&lt;DB::QueryPipeline, std::__1::default_delete&lt;DB::QueryPipeline&gt; &gt; &gt; &gt;) ITransformingStep.cpp:21DB::QueryPlan::buildQueryPipeline() QueryPlan.cpp:154DB::InterpreterSelectWithUnionQuery::execute() InterpreterSelectWithUnionQuery.cpp:200DB::executeQueryImpl(const char *, const char *, DB::Context &amp;, bool, DB::QueryProcessingStage::Enum, bool, DB::ReadBuffer *) executeQuery.cpp:385DB::executeQuery(DB::ReadBuffer&amp;, DB::WriteBuffer&amp;, bool, DB::Context&amp;, std::__1::function&lt;void (std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;)&gt;) executeQuery.cpp:722DB::MySQLHandler::comQuery(DB::ReadBuffer&amp;) MySQLHandler.cpp:307DB::MySQLHandler::run() MySQLHandler.cpp:141 3. Pipeline执行123456789101112131415161718DB::LimitTransform::prepare(std::__1::vector&lt;unsigned long, std::__1::allocator&lt;unsigned long&gt; &gt; const&amp;, std::__1::vector&lt;unsigned long, std::__1::allocator&lt;unsigned long&gt; &gt; const&amp;) LimitTransform.cpp:67DB::PipelineExecutor::prepareProcessor(unsigned long, unsigned long, std::__1::queue&lt;DB::PipelineExecutor::ExecutionState*, std::__1::deque&lt;DB::PipelineExecutor::ExecutionState*, std::__1::allocator&lt;DB::PipelineExecutor::ExecutionState*&gt; &gt; &gt;&amp;, std::__1::unique_lock&lt;std::__1::mutex&gt;) PipelineExecutor.cpp:291DB::PipelineExecutor::tryAddProcessorToStackIfUpdated(DB::PipelineExecutor::Edge&amp;, std::__1::queue&lt;DB::PipelineExecutor::ExecutionState*, std::__1::deque&lt;DB::PipelineExecutor::ExecutionState*, std::__1::allocator&lt;DB::PipelineExecutor::ExecutionState*&gt; &gt; &gt;&amp;, unsigned long) PipelineExecutor.cpp:264DB::PipelineExecutor::prepareProcessor(unsigned long, unsigned long, std::__1::queue&lt;DB::PipelineExecutor::ExecutionState*, std::__1::deque&lt;DB::PipelineExecutor::ExecutionState*, std::__1::allocator&lt;DB::PipelineExecutor::ExecutionState*&gt; &gt; &gt;&amp;, std::__1::unique_lock&lt;std::__1::mutex&gt;) PipelineExecutor.cpp:373DB::PipelineExecutor::tryAddProcessorToStackIfUpdated(DB::PipelineExecutor::Edge&amp;, std::__1::queue&lt;DB::PipelineExecutor::ExecutionState*, std::__1::deque&lt;DB::PipelineExecutor::ExecutionState*, std::__1::allocator&lt;DB::PipelineExecutor::ExecutionState*&gt; &gt; &gt;&amp;, unsigned long) PipelineExecutor.cpp:264DB::PipelineExecutor::prepareProcessor(unsigned long, unsigned long, std::__1::queue&lt;DB::PipelineExecutor::ExecutionState*, std::__1::deque&lt;DB::PipelineExecutor::ExecutionState*, std::__1::allocator&lt;DB::PipelineExecutor::ExecutionState*&gt; &gt; &gt;&amp;, std::__1::unique_lock&lt;std::__1::mutex&gt;) PipelineExecutor.cpp:373DB::PipelineExecutor::tryAddProcessorToStackIfUpdated(DB::PipelineExecutor::Edge&amp;, std::__1::queue&lt;DB::PipelineExecutor::ExecutionState*, std::__1::deque&lt;DB::PipelineExecutor::ExecutionState*, std::__1::allocator&lt;DB::PipelineExecutor::ExecutionState*&gt; &gt; &gt;&amp;, unsigned long) PipelineExecutor.cpp:264DB::PipelineExecutor::prepareProcessor(unsigned long, unsigned long, std::__1::queue&lt;DB::PipelineExecutor::ExecutionState*, std::__1::deque&lt;DB::PipelineExecutor::ExecutionState*, std::__1::allocator&lt;DB::PipelineExecutor::ExecutionState*&gt; &gt; &gt;&amp;, std::__1::unique_lock&lt;std::__1::mutex&gt;) PipelineExecutor.cpp:373DB::PipelineExecutor::tryAddProcessorToStackIfUpdated(DB::PipelineExecutor::Edge&amp;, std::__1::queue&lt;DB::PipelineExecutor::ExecutionState*, std::__1::deque&lt;DB::PipelineExecutor::ExecutionState*, std::__1::allocator&lt;DB::PipelineExecutor::ExecutionState*&gt; &gt; &gt;&amp;, unsigned long) PipelineExecutor.cpp:264DB::PipelineExecutor::prepareProcessor(unsigned long, unsigned long, std::__1::queue&lt;DB::PipelineExecutor::ExecutionState*, std::__1::deque&lt;DB::PipelineExecutor::ExecutionState*, std::__1::allocator&lt;DB::PipelineExecutor::ExecutionState*&gt; &gt; &gt;&amp;, std::__1::unique_lock&lt;std::__1::mutex&gt;) PipelineExecutor.cpp:373DB::PipelineExecutor::tryAddProcessorToStackIfUpdated(DB::PipelineExecutor::Edge&amp;, std::__1::queue&lt;DB::PipelineExecutor::ExecutionState*, std::__1::deque&lt;DB::PipelineExecutor::ExecutionState*, std::__1::allocator&lt;DB::PipelineExecutor::ExecutionState*&gt; &gt; &gt;&amp;, unsigned long) PipelineExecutor.cpp:264DB::PipelineExecutor::prepareProcessor(unsigned long, unsigned long, std::__1::queue&lt;DB::PipelineExecutor::ExecutionState*, std::__1::deque&lt;DB::PipelineExecutor::ExecutionState*, std::__1::allocator&lt;DB::PipelineExecutor::ExecutionState*&gt; &gt; &gt;&amp;, std::__1::unique_lock&lt;std::__1::mutex&gt;) PipelineExecutor.cpp:373DB::PipelineExecutor::initializeExecution(unsigned long) PipelineExecutor.cpp:747DB::PipelineExecutor::executeImpl(unsigned long) PipelineExecutor.cpp:764DB::PipelineExecutor::execute(unsigned long) PipelineExecutor.cpp:479DB::executeQuery(DB::ReadBuffer&amp;, DB::WriteBuffer&amp;, bool, DB::Context&amp;, std::__1::function&lt;void (std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;)&gt;) executeQuery.cpp:833DB::MySQLHandler::comQuery(DB::ReadBuffer&amp;) MySQLHandler.cpp:307DB::MySQLHandler::run() MySQLHandler.cpp:141 4. Output执行发送1234567891011DB::MySQLOutputFormat::consume(DB::Chunk) MySQLOutputFormat.cpp:53DB::IOutputFormat::work() IOutputFormat.cpp:62DB::executeJob(DB::IProcessor *) PipelineExecutor.cpp:155operator() PipelineExecutor.cpp:172DB::PipelineExecutor::executeStepImpl(unsigned long, unsigned long, std::__1::atomic&lt;bool&gt;*) PipelineExecutor.cpp:630DB::PipelineExecutor::executeSingleThread(unsigned long, unsigned long) PipelineExecutor.cpp:546DB::PipelineExecutor::executeImpl(unsigned long) PipelineExecutor.cpp:812DB::PipelineExecutor::execute(unsigned long) PipelineExecutor.cpp:479DB::executeQuery(DB::ReadBuffer&amp;, DB::WriteBuffer&amp;, bool, DB::Context&amp;, std::__1::function&lt;void (std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;)&gt;) executeQuery.cpp:800DB::MySQLHandler::comQuery(DB::ReadBuffer&amp;) MySQLHandler.cpp:311DB::MySQLHandler::run() MySQLHandler.cpp:141 总结ClickHouse 的模块化比较清晰，像乐高积木一样可以组合拼装，当我们执行: 1SELECT * FROM system.numbers LIMIT 5 首先内核解析 SQL 语句生成 AST，然后根据 AST 获取数据源 Source，pipeline.Add(Source)。其次根据 AST 信息生成 QueryPlan，根据 QueryPlan 再生成相应的 Transform，pipeline.Add(LimitTransform)。然后添加 Output Sink 作为数据发送对象，pipeline.Add(OutputSink)。执行 pipeline, 各个 Transformer 开始工作。 ClickHouse 的 Transformer 调度系统叫做 Processor，也是决定性能的重要模块，详情见 Pipeline 处理器和调度器。ClickHouse 是一辆手动挡的豪华跑车，免费拥有，海啸们！","categories":[{"name":"ClickHouse","slug":"ClickHouse","permalink":"http://dbkernel.github.io/categories/ClickHouse/"}],"tags":[{"name":"ClickHouse和他的朋友们","slug":"ClickHouse和他的朋友们","permalink":"http://dbkernel.github.io/tags/ClickHouse%E5%92%8C%E4%BB%96%E7%9A%84%E6%9C%8B%E5%8F%8B%E4%BB%AC/"},{"name":"ClickHouse","slug":"ClickHouse","permalink":"http://dbkernel.github.io/tags/ClickHouse/"}]},{"title":"ClickHouse和他的朋友们（1）编译、开发、测试","slug":"clickhouse-and-friends-01-development","date":"2020-06-05T11:37:10.000Z","updated":"2021-07-21T07:46:16.766Z","comments":true,"path":"2020/06/05/clickhouse-and-friends-01-development/","link":"","permalink":"http://dbkernel.github.io/2020/06/05/clickhouse-and-friends-01-development/","excerpt":"","text":"《ClickHouse和他的朋友们》系列文章转载自圈内好友 BohuTANG 的博客，原文链接：https://bohutang.me/2020/06/05/clickhouse-and-friends-development/以下为正文。 一次偶然的机会，和ClickHouse团队做了一次线下沟通，Alexey提到ClickHouse的设计哲学: The product must solve actual problem And do it better than others 用工程思维解决商业问题的典范啊！ 对用户来说，他们关心的不是什么天花乱坠、上天入地的高科技，只是需要一个能很好解决自己问题的方案，这在开源社区是非常难得的，靠实力“野蛮式”生长。 于是，我对这个散发着伏特加味道的利器充满了好奇，并参与到ClickHouse的社区中一探究竟，第一感觉是开放、友好、战斗力强(AK47 vs CK16, ClickHouse 2016年开源)。 本文先从编译和测试入手，再到如何为社区贡献Patch，希望对那些想参与CK社区的同学有所帮助。 如何本地编译和测试ClickHouse？源码获取1git clone --recursive https://github.com/ClickHouse/ClickHouse 编译准备1234567sudo apt install build-essentialsudo apt-get install software-properties-commonsudo apt-add-repository ppa:ubuntu-toolchain-r/testsudo apt-get updatesudo apt-get install gcc-9 g++-9 git python ninja-buildsudo snap install cmake 开始编译1234567cd ClickHousemkdir buildcd buildexport CC=gcc-9export CXX=g++-9cmake ..ninja 测试方法ClickHouse的测试在官方development/tests文档里有详细的介绍，这里列举3个常用的测试模式： 1. Functional Tests功能测试，主要用于ClickHouse内部功能测试，方式：输入一个sql文件，输出一个result，类似MySQL里的mtr，测试集合 12cd tests./clickhouse-test -c &quot;../build/programs/clickhouse-client&quot; 00001_select_1 2. Integration Tests集成测试，主要用于涉及第三方服务的测试，比如MySQL/Postgres/MongoDB等，以容器化方式编排调度(pytest)运行，测试集合 由于涉及模块较多，集成测试环境的搭建有一定的难度，建议使用官方的docker镜像。比如要跑test_mysql_protocol下的集成测试集： 123cd tests/integrationdocker pull yandex/clickhouse-integration-tests-runner./runner --binary /your/ClickHouse/build/programs/clickhouse --bridge-binary /your/ClickHouse/build/programs/clickhouse-odbc-bridge --configs-dir /your/ClickHouse/programs/server/ &#x27;test_mysql_protocol/test.py::test_java_client -ss -vv&#x27; 3. Unit Tests单元测试，主要用于代码模块的测试，测试集在各个模块的tests目录，比如: Core/tests 如果大家想了解某个模块是如何工作的，强烈建议去翻翻该模块的tests目录，比如想了解processor的工作机制，跟踪调试 Processors/tests/ 即可。 如何给ClickHouse社区提Patch？1. fork首先在自己的github上fork一份ClickHouse代码，比如 https://github.com/BohuTANG/ClickHouse 2. clone到本地12git clone --recursive https://github.com/BohuTANG/ClickHousegit checkout -B mysql_replica(branch名字) 3. 创建新的分支1git checkout -B mysql_replica(branch名字) 4. 功能开发开发者可以提交一个Draft Pull Request到官方，github会显示这个Pull Request处于Draft状态，官方是无法Merge的 5. can be testd标签等待Upstream打[can be tested]标签，一旦被标记CI狂魔们就强势开跑，跑一轮大概需要几十个小时。协助开发者发现一些代码Style、编译以及测试等错误，这样开发者就可以在自己的分支不停的迭代、修正。 如果只是修改typo，这个标签Upstream通常不会添加。 6. 开发完毕开发完成，测试OK，把Draft提升为正式Pull Request，等待Upstraem Review。 7. Merge到Master如果Upstream通过，你的代码会被Merge到Master，恭喜你成为ClickHouse贡献者 8. 注意事项ClickHouse Upstream迭代非常快，一定要多关注master分支进度，尽量保持自己的分支代码与master同步。否则Upstream Docker更新，自己的test可能就过不了。 建议把doc/development读一遍。","categories":[{"name":"ClickHouse","slug":"ClickHouse","permalink":"http://dbkernel.github.io/categories/ClickHouse/"}],"tags":[{"name":"ClickHouse和他的朋友们","slug":"ClickHouse和他的朋友们","permalink":"http://dbkernel.github.io/tags/ClickHouse%E5%92%8C%E4%BB%96%E7%9A%84%E6%9C%8B%E5%8F%8B%E4%BB%AC/"},{"name":"ClickHouse","slug":"ClickHouse","permalink":"http://dbkernel.github.io/tags/ClickHouse/"}]},{"title":"MySQL select count(*) 、count(1)、count(列) 详解（1）：概念及区别","slug":"MySQL select count(*) 、count(1)、count(列) 详解（1）：概念及区别","date":"2020-05-06T07:55:15.000Z","updated":"2021-07-12T16:10:05.005Z","comments":true,"path":"2020/05/06/MySQL select count(*) 、count(1)、count(列) 详解（1）：概念及区别/","link":"","permalink":"http://dbkernel.github.io/2020/05/06/MySQL%20select%20count(*)%20%E3%80%81count(1)%E3%80%81count(%E5%88%97)%20%E8%AF%A6%E8%A7%A3%EF%BC%881%EF%BC%89%EF%BC%9A%E6%A6%82%E5%BF%B5%E5%8F%8A%E5%8C%BA%E5%88%AB/","excerpt":"","text":"一、前言从接触MySQL开始断断续续的看过一些文章，对count()操作众说纷纭，其中分歧点主要在于count(1)和count(*)哪个效率高，有说count(1)比count(*)快的（这种说法更普遍），有说二者一样快的。个人理解这两种行为可能适用于的是不同的版本，我只关心较新的MySQL版本是什么行为，详见下文。 二、含义首先，先说明一下常见count()操作及含义： count(*)：计算包括NULL值在内的行数，SQL92定义的标准统计行数的语法。 count(1)：计算包括NULL值在内的行数，其中的1是恒真表达式。 count(列名)：计算指定列的行数，但不包含NULL值。 三、具体区别MySQL手册中相关描述如下： For transactional storage engines such as InnoDB, storing an exact row count is problematic. Multiple transactions may be occurring at the same time, each of which may affect the count. InnoDB does not keep an internal count of rows in a table because concurrent transactions might “see” different numbers of rows at the same time. Consequently, SELECT COUNT(*) statements only count rows visible to the current transaction. Prior to MySQL 5.7.18, InnoDB processes SELECT COUNT(*) statements by scanning the clustered index. As of MySQL 5.7.18, InnoDB processes SELECT COUNT(*) statements by traversing the smallest available secondary index unless an index or optimizer hint directs the optimizer to use a different index. If a secondary index is not present, the clustered index is scanned. Processing SELECT COUNT(*) statements takes some time if index records are not entirely in the buffer pool. For a faster count, create a counter table and let your application update it according to the inserts and deletes it does. However, this method may not scale well in situations where thousands of concurrent transactions are initiating updates to the same counter table. If an approximate row count is sufficient, use SHOW TABLE STATUS. InnoDB handles SELECT COUNT(*) and SELECT COUNT(1) operations in the same way. There is no performance difference. For MyISAM tables, COUNT(*) is optimized to return very quickly if the SELECT retrieves from one table, no other columns are retrieved, and there is no WHERE clause. For example: 1&gt;mysql&gt; SELECT COUNT(*) FROM student; This optimization only applies to MyISAM tables, because an exact row count is stored for this storage engine and can be accessed very quickly.COUNT(1) is only subject to the same optimization if the first column is defined as NOT NULL. 官方这段描述要点如下： InnoDB是事务引擎，支持MVCC，并发事务可能同时“看到”不同的行数，所以，InnoDB不保留表中的行数，SELECT COUNT(*)语句只计算当前事务可见的行数。 在MySQL 5.7.18之前，InnoDB通过扫描聚集索引处理SELECT COUNT(*)语句。从MySQL 5.7.18开始，InnoDB通过遍历最小的可用二级索引来处理SELECT COUNT(*)语句，除非索引或优化器明确指示使用不同的索引。如果不存在二级索引，则扫描聚集索引。这样的设计单从 IO 的角度就节省了很多开销。 InnoDB以同样的方式处理SELECT COUNT(*)和SELECT COUNT(1)操作，没有性能差异。 因此，建议使用符合SQL标准的count(*)。 对于MyISAM表，由于MyISAM引擎存储了精确的行数，因此，如果SELECT COUNT(*)语句不包含WHERE子句，则会很快返回。这个很好理解，如果带了where条件，就需要扫表了。 如果索引记录不完全在缓冲池中，则处理SELECT(*)语句需要一些时间。为了更快的计数，您可以创建一个计数器表，并让您的应用程序按插入和删除操作更新它。然而，这种方法在同一计数器表中启动成千上万个并发事务的情况下，可能无法很好地扩展。如果一个近似的行数足够，可以使用SHOW TABLE STATUS查询行数。 到这里我们明白了 count(*) 和 count(1) 本质上面其实是一样的，那么 count(column) 又是怎么回事呢？ count(column) 也是会遍历整张表，但是不同的是它会拿到 column 的值以后判断是否为空，然后再进行累加，那么如果针对主键需要解析内容，如果是二级索引需要再次根据主键获取内容，则要多一次 IO 操作，所以 count(column) 的性能肯定不如前两者，如果按照效率比较的话：*count()=count(1)&gt;count(primary key)&gt;count(非主键column)**。 四、建议基于以上描述，如果要查询innodb存储引擎的表的总行数，有如下建议： 若仅仅是想获取大概的行数，建议使用show table status或查询information_schema.tables：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667mysql&gt; use db6;Reading table information for completion of table and column namesYou can turn off this feature to get a quicker startup with -ADatabase changedmysql&gt; show tables;+---------------+| Tables_in_db6 |+---------------+| t1 |+---------------+1 row in set (0.01 sec)mysql&gt; select count(*) from t1;+----------+| count(*) |+----------+| 2 |+----------+1 row in set (0.00 sec)mysql&gt; show table status\\G*************************** 1. row *************************** Name: t1 Engine: InnoDB Version: 10 Row_format: Dynamic Rows: 2 Avg_row_length: 8192 Data_length: 16384Max_data_length: 0 Index_length: 0 Data_free: 0 Auto_increment: NULL Create_time: 2020-04-21 12:00:44 Update_time: NULL Check_time: NULL Collation: utf8mb4_general_ci Checksum: NULL Create_options: Comment:1 row in set (0.00 sec)mysql&gt; select * from information_schema.tables where table_name = &#x27;t1&#x27;\\G*************************** 1. row *************************** TABLE_CATALOG: def TABLE_SCHEMA: db6 TABLE_NAME: t1 TABLE_TYPE: BASE TABLE ENGINE: InnoDB VERSION: 10 ROW_FORMAT: Dynamic TABLE_ROWS: 2 AVG_ROW_LENGTH: 8192 DATA_LENGTH: 16384MAX_DATA_LENGTH: 0 INDEX_LENGTH: 0 DATA_FREE: 0 AUTO_INCREMENT: NULL CREATE_TIME: 2020-04-21 12:00:44 UPDATE_TIME: NULL CHECK_TIME: NULLTABLE_COLLATION: utf8mb4_general_ci CHECKSUM: NULL CREATE_OPTIONS: TABLE_COMMENT:1 row in set (0.00 sec) 反之，如果必须要获取准确的总行数，建议： 创建一个计数器表，并让您的应用程序按插入和删除操作更新它。 若业务插入和删除相对较少，也可以考虑缓存到 redis。 篇幅有限，深入验证、源码分析将在下一篇文章中介绍。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://dbkernel.github.io/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://dbkernel.github.io/tags/MySQL/"},{"name":"Select","slug":"Select","permalink":"http://dbkernel.github.io/tags/Select/"},{"name":"Count","slug":"Count","permalink":"http://dbkernel.github.io/tags/Count/"}]},{"title":"MySQL-自增列详解（1）：自增列概念及使用","slug":"MySQL-自增列详解（1）：自增列概念及使用","date":"2019-12-09T11:37:10.000Z","updated":"2021-07-14T03:34:33.741Z","comments":true,"path":"2019/12/09/MySQL-自增列详解（1）：自增列概念及使用/","link":"","permalink":"http://dbkernel.github.io/2019/12/09/MySQL-%E8%87%AA%E5%A2%9E%E5%88%97%E8%AF%A6%E8%A7%A3%EF%BC%881%EF%BC%89%EF%BC%9A%E8%87%AA%E5%A2%9E%E5%88%97%E6%A6%82%E5%BF%B5%E5%8F%8A%E4%BD%BF%E7%94%A8/","excerpt":"一直想写一些关于自增列的文章，今天下班比较早，Let’s do this.","text":"一直想写一些关于自增列的文章，今天下班比较早，Let’s do this. 1. 概念自增列，即 AUTO_INCREMENT，可用于为新的记录生成唯一标识。 要求： AUTO_INCREMENT 是数据列的一种属性，只适用于整数类型数据列。 AUTO_INCREMENT 数据列必须具备 NOT NULL 属性。 2. 使用方法2.1. 创建含自增列的表1234567-- 不指定 AUTO_INCREMENT 的值，则从1开始mysql&gt; create table t1(a int auto_increment primary key,b int);Query OK, 0 rows affected (0.01 sec)-- 手动指定 AUTO_INCREMENT 的值mysql&gt; create table t2(a int auto_increment primary key,b int) AUTO_INCREMENT=100;Query OK, 0 rows affected (0.02 sec) 2.2. 插入数据12345678910111213141516-- 不指定自增列mysql&gt; insert into t1(b) values(1),(2);Query OK, 1 row affected (0.00 sec)mysql&gt; select * from t1;+---+------+| a | b |+---+------+| 1 | 1 || 2 | 2 |+---+------+3 rows in set (0.00 sec)-- 指定自增列mysql&gt; insert into t1(a,b) values(3,3);Query OK, 1 row affected (0.00 sec) 2.3. 如何查看表的 AUTO_INCREMENT 涨到了多少？1234567891011mysql&gt; show create table t1;+-------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+| Table | Create Table |+-------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+| t1 | CREATE TABLE `t1` ( `a` int(11) NOT NULL AUTO_INCREMENT, `b` int(11) DEFAULT NULL, PRIMARY KEY (`a`)) ENGINE=InnoDB AUTO_INCREMENT=3 DEFAULT CHARSET=utf8 |+-------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+1 row in set (0.00 sec) 2.4. 插入数据时能否有空洞？可以的，但要注意 AUTO_INCREMENT 的值一定比自增列当前最大的记录值大。 1234567891011121314151617181920212223242526-- 创造空洞mysql&gt; insert into t1(a,b) values(5,5);Query OK, 1 row affected (0.00 sec)mysql&gt; select * from t1;+---+------+| a | b |+---+------+| 1 | 1 || 2 | 2 || 3 | 3 || 5 | 5 |+---+------+5 rows in set (0.00 sec)mysql&gt; show create table t1;+-------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+| Table | Create Table |+-------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+| t1 | CREATE TABLE `t1` ( `a` int(11) NOT NULL AUTO_INCREMENT, `b` int(11) DEFAULT NULL, PRIMARY KEY (`a`)) ENGINE=InnoDB AUTO_INCREMENT=6 DEFAULT CHARSET=utf8 |+-------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+1 row in set (0.00 sec) 2.5. 能否插入重复记录既然自增列是唯一记录，那么肯定不能插入重复记录。 123-- 尝试插入重复记录mysql&gt; insert into t1(a,b) values(5,5);ERROR 1062 (23000): Duplicate entry &#x27;5&#x27; for key &#x27;PRIMARY&#x27; 2.6. 怎么修改 AUTO_INCREMENT 的值？注意：AUTO_INCREMENT 不能小于当前自增列记录的最大值。 12345678910111213141516171819202122232425262728293031323334-- 尝试将 AUTO_INCREMENT 设为10mysql&gt; alter table t1 AUTO_INCREMENT=10;Query OK, 0 rows affected (0.01 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; show create table t1;+-------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+| Table | Create Table |+-------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+| t1 | CREATE TABLE `t1` ( `a` int(11) NOT NULL AUTO_INCREMENT, `b` int(11) DEFAULT NULL, PRIMARY KEY (`a`)) ENGINE=InnoDB AUTO_INCREMENT=10 DEFAULT CHARSET=utf8 |+-------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+1 row in set (0.00 sec)-- 尝试将 AUTO_INCREMENT 设为4mysql&gt; alter table t1 AUTO_INCREMENT=4;Query OK, 0 rows affected (0.00 sec)Records: 0 Duplicates: 0 Warnings: 0-- 由于自增列最大记录值是5，那么 AUTO_INCREMENT 不能小于5，因此该值为6mysql&gt; show create table t1;+-------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+| Table | Create Table |+-------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+| t1 | CREATE TABLE `t1` ( `a` int(11) NOT NULL AUTO_INCREMENT, `b` int(11) DEFAULT NULL, PRIMARY KEY (`a`)) ENGINE=InnoDB AUTO_INCREMENT=6 DEFAULT CHARSET=utf8 |+-------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+1 row in set (0.00 sec) 3. 问题3.1. 自增列是否有上限？由上文可见，自增列会一直增加，那是否有上限呢？ 上文中表 t1 的自增列是 int 类型，由下表（MySQL 5.7）可见取值范围是 -2147483648 到 2147483647（ -231 ~ 231 - 1 ）。 Type Storage (Bytes) Minimum Value Signed Minimum Value Unsigned Maximum Value Signed Maximum Value Unsigned TINYINT 1 -128 0 127 255 SMALLINT 2 -32768 0 32767 65535 MEDIUMINT 3 -8388608 0 8388607 16777215 INT 4 -2147483648 0 2147483647 4294967295 BIGINT 8 -263 0 263-1 264-1 验证如下： 12345678910111213141516171819202122232425262728mysql&gt; show create table t1;+-------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| Table | Create Table |+-------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| t1 | CREATE TABLE `t1` ( `a` int(11) NOT NULL AUTO_INCREMENT, `b` int(11) DEFAULT NULL, PRIMARY KEY (`a`)) ENGINE=InnoDB AUTO_INCREMENT=2147483644 DEFAULT CHARSET=utf8 |+-------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------+1 row in set (0.01 sec)mysql&gt; insert into t1(b) values(0),(0),(0);Query OK, 1 row affected (0.00 sec)mysql&gt; insert into t1(b) values(0);ERROR 1062 (23000): Duplicate entry &#x27;2147483647&#x27; for key &#x27;PRIMARY&#x27;mysql&gt; show create table t1;+-------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| Table | Create Table |+-------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| t1 | CREATE TABLE `t1` ( `a` int(11) NOT NULL AUTO_INCREMENT, `b` int(11) DEFAULT NULL, PRIMARY KEY (`a`)) ENGINE=InnoDB AUTO_INCREMENT=2147483647 DEFAULT CHARSET=utf8 |+-------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------+1 row in set (0.00 sec) 这里需要补充说明下 int(11) 中的数字的含义： MySQL中整数数据类型后面的(N)指定显示宽度。显示宽度不影响查询出来的结果。显示宽度限制了小数点的位置(只要实际数字不超过显示宽度，这种情况下，数字显示为原样)。显示宽度也是一个有用的工具，可以让开发人员知道应该将值填充到哪个长度。 3.2. 如何避免自增列超过最大值？可以采用无符号的 BIGINT 类型（也可根据业务产生自增列的速度采用合适的类型），能极大提升自增列的范围。 1234567891011121314151617181920212223242526272829303132mysql&gt; create table t2(a bigint unsigned primary key auto_increment,b int);Query OK, 0 rows affected (0.00 sec)mysql&gt; alter table t2 auto_increment=18446744073709551613;Query OK, 0 rows affected (0.00 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; show create table t2;+-------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| Table | Create Table |+-------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| t2 | CREATE TABLE `t2` ( `a` bigint(20) unsigned NOT NULL AUTO_INCREMENT, `b` int(11) DEFAULT NULL, PRIMARY KEY (`a`)) ENGINE=InnoDB AUTO_INCREMENT=18446744073709551613 DEFAULT CHARSET=utf8 |+-------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+1 row in set (0.01 sec)mysql&gt; insert into t2(b) values(0);Query OK, 1 row affected (0.00 sec)mysql&gt; insert into t2(b) values(0);ERROR 1467 (HY000): Failed to read auto-increment value from storage enginemysql&gt;mysql&gt; select * from t2;+----------------------+------+| a | b |+----------------------+------+| 18446744073709551613 | 0 |+----------------------+------+1 row in set (0.00 sec) UNSIGNED BIGINT 类型的范围究竟有多大呢？ 假如每秒自增100万次，想要消耗完需要 18446744073709551613/1000000/3600/24/365=584942年。 有的朋友会问如果自增列不是采用BIGINT类型，那么达到最大值后该表就无法写入，此时该怎么办呢？ 一般达到最大值后再次插入数据会报错ERROR 1467 (HY000): Failed to read auto-increment value from storage engine，可以通过alter table 将自增列的类型设为数值范围更大的类型（比如BIGINT）。 4. 总结 AUTO_INCREMENT 列必定唯一，且仅用于整型类型。 AUTO_INCREMENT 列会持续增长，不会因 delete 自增列最大的记录而变小。 当 AUTO_INCREMENT 列达到当前类型的最大值后将无法插入数据，会报错ERROR 1467 (HY000): Failed to read auto-increment value from storage engine，此时将自增列改为 BIGINT 类型可解决问题。 为了避免自增列达到最大值，可将其设为BIGINT类型。 使用 alter table 修改 AUTO_INCREMENT 列时，其值会取自增列当前最大记录值+1与将要设置的值的最大值。 在MySQL 5.7 中，将列设置成 AUTO_INCREMENT 之后，必须将其设置成主键/或者是主键的一部分，否则会报错ERROR 1075 (42000): Incorrect table definition; there can be only one auto column and it must be defined as a key。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://dbkernel.github.io/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://dbkernel.github.io/tags/MySQL/"},{"name":"auto_increment","slug":"auto-increment","permalink":"http://dbkernel.github.io/tags/auto-increment/"}]}],"categories":[{"name":"ClickHouse","slug":"ClickHouse","permalink":"http://dbkernel.github.io/categories/ClickHouse/"},{"name":"MySQL","slug":"MySQL","permalink":"http://dbkernel.github.io/categories/MySQL/"}],"tags":[{"name":"ClickHouse和他的朋友们","slug":"ClickHouse和他的朋友们","permalink":"http://dbkernel.github.io/tags/ClickHouse%E5%92%8C%E4%BB%96%E7%9A%84%E6%9C%8B%E5%8F%8B%E4%BB%AC/"},{"name":"ClickHouse","slug":"ClickHouse","permalink":"http://dbkernel.github.io/tags/ClickHouse/"},{"name":"MySQL","slug":"MySQL","permalink":"http://dbkernel.github.io/tags/MySQL/"},{"name":"Select","slug":"Select","permalink":"http://dbkernel.github.io/tags/Select/"},{"name":"Count","slug":"Count","permalink":"http://dbkernel.github.io/tags/Count/"},{"name":"auto_increment","slug":"auto-increment","permalink":"http://dbkernel.github.io/tags/auto-increment/"}]}