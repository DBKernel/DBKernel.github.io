{"meta":{"title":"DBKernel","subtitle":"","description":"专注于数据库技术分享","author":"DBKernel","url":"http://dbkernel.github.io","root":"/"},"pages":[{"title":"分类","date":"2021-07-10T09:34:18.000Z","updated":"2021-07-10T10:49:25.987Z","comments":false,"path":"categories/index.html","permalink":"http://dbkernel.github.io/categories/index.html","excerpt":"","text":""},{"title":"标签","date":"2017-05-27T05:47:40.000Z","updated":"2021-07-10T13:50:19.870Z","comments":false,"path":"tags/index.html","permalink":"http://dbkernel.github.io/tags/index.html","excerpt":"","text":"-"},{"title":"关于","date":"2021-07-10T05:47:55.000Z","updated":"2021-07-10T13:59:06.317Z","comments":false,"path":"about/index.html","permalink":"http://dbkernel.github.io/about/index.html","excerpt":"","text":"简介卢文双 xxx yyy"},{"title":"友情链接","date":"2021-07-11T13:25:13.262Z","updated":"2021-07-11T13:25:13.213Z","comments":true,"path":"links/index.html","permalink":"http://dbkernel.github.io/links/index.html","excerpt":"","text":"微信公众号：MySQL数据库技术"},{"title":"项目","date":"2021-07-11T13:27:01.021Z","updated":"2021-07-11T13:27:00.986Z","comments":true,"path":"repository/index.html","permalink":"http://dbkernel.github.io/repository/index.html","excerpt":"","text":""}],"posts":[{"title":"技术分享 | 如何为你的代码选择一个合适的开源协议？","slug":"how-to-choose-open-source-licence","date":"2021-08-18T16:37:15.000Z","updated":"2021-08-22T05:58:30.795Z","comments":true,"path":"2021/08/19/how-to-choose-open-source-licence/","link":"","permalink":"http://dbkernel.github.io/2021/08/19/how-to-choose-open-source-licence/","excerpt":"近期公司全面拥抱开源，在选择开源协议方面遇到了一些问题，查阅了很多资料，特此总结~~","text":"近期公司全面拥抱开源，在选择开源协议方面遇到了一些问题，查阅了很多资料，特此总结~~ 前言对于很多刚踏入开源软件这个行业的小伙伴来说，在编码过程中难免会用到其他人的成果，如果你足够细心，很容易注意到即使是一小段代码，优秀的作者都在文件开头附上一段关于版权的声明，比如 Licensed under the MIT license。同时，一些博客也会标明”此文章采用 CC BY 4.0 CN 协议“。 如果我们拷贝了别人的代码或文章却没注意版权问题，在国外法律意识特别强的环境下（国内版权意识也在逐步加强），那么我们的作品会因触犯别人的权益而违法。即使是最开放的开源协议，最低要求也是保留原作者对代码的声明，所以开源不等于免费，也不等于没有约束。 何为 LICENCE？ LICENCE 是软件的授权许可，详细说明了获得代码后拥有的权利，哪些操作是允许的，哪些操作是禁止的。软件的版权许可证可有很多方式，本文仅限于讨论开源软件协议 Open Source License。 对于大多数人来说，没必要花大把时间去写许可协议，选择一种比较流行的开源协议就足够了，省时省力，更便于自己作品的传播，于人于己都有利。 PS： 说句题外话，很多国外开发者在尊重他人劳动成果方面做得很好，如果A的作品是因为B的作品的启发而来，A甚至都没有使用B任何一句代码，但A会在他的作品里面指明是受到了B的启发：Inspired by XXX link: http://www.xxxx.com。 快速选择开源协议如果你不想了解太多，只是想要一个简直直接的答案，下面给出的建议或许适合你。本小节关于协议地址来自于 GitHub choosealicence 。 简单宽松的协议： 如果你只想要一个简单点的协议不想太麻烦的话。 MIT协议相对宽松，此协议允许别人以任何方式使用你的代码同时署名原作者，但原作者不承担代码使用后的风险，当然也没有技术支持的义务。 考虑有专利的情况： 如果你的作品中涉及到专利相关。 Apache协议也是个相对宽松的协议，与MIT类似，但它指明了作者对用户专利上的一些授权（我的理解是软件作品中含有专利，但它授权你可以免费使用）。 促进代码分享： 如果你在乎作品的传播和别人的修改，希望别人也以相同的协议分享出来。 GPL（V2或V3）协议要求代码分发者或者以此代码为基础开发出来的衍生作品需要以同样的协议来发布，也必须开源，因此，该协议具有”传染性“。 乌克兰程序员Paul Bagwell，画了一张分析图，说明应该怎么选择。只用两分钟，你就能搞清楚这六种开源协议之间的最大区别。 国内大神阮一峰的汉化版本： 主流开源许可协议（Open Source License）世界上的开源许可协议（Open Source License）大概有上百种，常用的开源软件协议大致有： GPL LGPL BSD MIT Mozilla Apache 由宽松到严紧排序，常用的开源协议有： MIT BSD Apache LGPL GPL 主要区别： MIT、BSD 开源协议都源自大学，体现了简单、开放和包容的特点。 MIT、BSD、Apache 三者都支持闭源的后续开发。 GPL、LGPL 传染性开源，编译的代码里用了这里的代码，都必须开源。 MIT来源于大学，MIT 开源协议是史上最为简洁、慷慨的开源协议之一。作者只想保留版权，而无任何其他了限制。也就是说，你必须在你的发行版里包含原许可协议的声明，无论你是以二进制发布的还是以源代码发布的。 特点： 用户可以拿你的代码做任何想做的事情。 用户在项目副本中要包含版权声明和许可声明。 你无需承担任何责任。 代表作品： jQuery Rails 等。 BSD BSD-2-Clause BSD-3-Clause BSD可证也来源于大学，与MIT差不多，也非常简单、慷慨。 BSD开源协议是一个给于使用者很大自由的协议。基本上使用者可以”为所欲为”,可以自由的使用、修改源代码，也可以将修改后的代码作为开源或者专有软件再发布。前提是当你发布使用了BSD协议的代码，或者以BSD协议代码为基础开发自己的产品时，需要满足三个条件： 如果再发布的产品中包含源代码，则在源代码中必须带有原代码中的BSD协议。 如果再发布的只是二进制类库/软件，则需要在类库/软件的文档和版权声明中包含原来代码中的BSD协议。 不可以用开源代码的作者/机构名字和原来产品的名字做市场推广。 BSD 开源协议鼓励代码共享，但需要尊重代码作者的著作权。BSD 开源协议允许使用者修改和重新发布代码，也允许使用或在BSD代码上开发商业软件发布、销售，是对商业集成很友好的协议。因此，很多公司在选用开源产品的时候都首选BSD协议。 Apache Licence Apache License, Version 2.0 Apache License, Version 1.1 Apache License, Version 1.0 来自 Apache，类似 MIT 开源协议，但它重视专利权。 Apache Licence 是著名的非盈利开源组织 Apache 采用的协议。该协议和BSD类似，同样鼓励代码共享和尊重原作者的著作权，同样允许修改代码、再发布（作为开源或商业软件）。需要满足的条件也和BSD类似： 需要为使用代码的用户提供一份 Apache Licence 。 如果你修改了代码，需要在被修改的文件中说明。 在延伸的代码中（修改和由源代码衍生的代码中）需要带有原来代码中的协议、商标、专利声明和其他原作者规定需要包含的说明。 如果再发布的产品中包含一个Notice文件，则在Notice文件中需要带有 Apache Licence 。你可以在Notice中增加自己的许可，但不可对 Apache Licence 构成更改。 Apache Licence 也是对商业应用友好的许可，使用者也可以在需要的时候修改代码来满足需要并作为开源或商业产品发布/销售。 代表作品： echarts superset dubbo spark LGPLLGPL（GNU LESSER GENERAL PUBLIC LICENSE）来自于自由软件联盟GNU，可以翻译为更宽松的GPL协议，也属于传染性开源协议。 LGPL是GPL的一个主要为类库使用设计的开源协议。和GPL要求任何使用/修改/衍生之GPL类库的的软件必须采用GPL协议不同，LGPL 允许商业软件通过类库引用(link)方式使用LGPL类库而不需要开源商业软件的代码。这使得采用LGPL协议的开源代码可以被商业软件作为类库引用并发布和销售。 但是如果修改LGPL协议的代码或者衍生，则所有修改的代码，涉及修改部分的额外代码和衍生的代码都必须采用LGPL协议，因此，LGPL协议的开源代码很适合作为第三方类库被商业软件引用，但不适合希望以LGPL协议代码为基础，通过修改和衍生的方式做二次开发的商业软件采用。 GPL/LGPL都保障原作者的知识产权，避免有人利用开源代码复制并开发类似的产品。 GPLGPL（GNU GENERAL PUBLIC LICENSE）来源于自由软件联盟GNU，GPL/LGPL侧重于代码及衍生代码的开源与免费使用。 GPL协议的主要内容是只要在一个软件中使用（”使用”指类库引用，修改后的代码或者衍生代码）GPL 协议的产品，则该软件产品必须也采用GPL协议，既必须也是开源和免费。这就是所谓的”传染性”。 由于GPL严格要求使用了GPL类库的软件产品必须使用GPL协议，对于使用GPL协议的开源代码，商业软件或者对代码有保密要求的部门就不适合集成/采用作为类库和二次开发的基础。 我们很熟悉的Linux就是采用了GPL。GPL协议和BSD, Apache Licence等鼓励代码重用的许可很不一样。GPL的出发点是代码的开源/免费使用/引用/修改和衍生代码的开源/免费使用，但不允许修改后和衍生的代码做为闭源的商业软件发布和销售。 其它细节和BSD/Apache等协议类似。 代表作品： Linux 更多开源协议对比下方表格中出现的用词的解释： 协议和版权信息(License and copyright notice)：在代码中保留作者提供的协议和版权信息。 声明变更(State Changes)：在代码中声明对原来代码的重大修改及变更。 公开源码(Disclose Source)：代码必需公开。 库引用(Library usage)：该库可以用于商业软件中。 责任承担(Hold Liable)：代码的作者承担代码使用后的风险及产生的后果。如果禁止，那么作者将不会承担责任，可以理解为免责条款。 商标使用(Use Trademark)：可以使用作者的姓名，作品的Logo，或商标。 附加协议(Sublicensing)：允许在软件分发传播过程中附加上原来没有的协议条款等。 协议 描述 要求 允许 禁止 Apache 一个比较宽松且简明地指出了专利授权的协议。 1. 协议和版权信息2. 声明变更 1. 商用2. 分发3. 修改4. 专利授权5. 私用6. 附加协议 1. 责任承担（作者免责）2. 商标使用 GPL 应用最广泛的开源协议，拥有较强的版权自由（copyleft）要求。衍生代码的分发需开源并且也要遵守此协议。此协议有许多变种，不同变种的要求略有不同。 1. 公开源码2. 协议和版权信息3. 声明变更 1. 商用2. 分发3. 修改4. 专利授权5. 私用 1. 责任承担2. 附加协议 MIT 此协议宽松简单。在适当标明来源及免责的情况下，它允许你对代码进行任何形式的使用。 1. 协议和版权信息 1. 商用2. 分发3. 修改4. 私用5. 附加协议 1. 责任承担 Artistic Perl社区最钟爱此协议。要求更改后的软件不能影响原软件的使用。 1. 协议和版权信息2. 声明变更 1. 商用2. 分发3. 修改4. 私用5. 附加协议 1. 责任承担2. 商标使用 BSD 较为宽松的协议，有两个变种BSD 2-Clause 和BSD 3-Clause，两者都与MIT协议只存在细微差异。 1. 协议和版权信息 1. 商用2. 分发3. 修改4. 私用5. 附加协议 1. 责任承担 Eclipse 对商用非常友好的协议，可以用于软件的商业授权。包含对专利的优雅授权，也可以对相关代码应用商业协议。 1. 公开源码2. 协议和版权信息 1. 商用2. 分发3. 修改4. 专利授权5. 私用6. 附加协议 1. 责任承担 LGPL 主要用于一些代码库。衍生代码可以以此协议发布（也可以用其他协议），但与此协议相关的代码必需遵循此协议。 1. 公开源码2. 库引用3. 协议和版权信息 1. 商用2. 分发3. 修改4. 专利授权5. 私用6. 附加协议 1. 责任承担 Mozilla Mozilla Public License(MPL 2.0)是由Mozilla基金创建维护的，旨在较为宽松的BSD协议和更加互惠的GPL协议中找一个折衷点。 1. 公开源码2. 协议和版权信息 1. 商用2. 分发3. 修改4. 专利授权5. 私用6. 附加协议 1. 责任承担2. 商标使用 No license 作者保留所有权利，不允许他人分发，复制或者创造衍生物。当你将代码发表在一些网站上时需要遵守该网站的协议，此协议可能包含了一些对你劳动成果的授权许可。比如将代码发布到GitHub，那么就必须同意别人查看和fork。 1. 协议和版权信息 1. 商用2. 私用 1. 分发2. 修改3. 附加协议 Public domain dedication 在许多国家，默认版权归作者自动拥有，所以Unlicense协议提供了一种通用的模板。此协议表明作者放弃版权，将劳动成果无私贡献出来，会丧失作品全部权利，包括在MIT/X11中定义的无担保权利。 1. N/A 1. 商用2. 分发3. 修改4. 私用 1. 责任承担 参考链接 https://github.com/github/choosealicense.com https://opensource.org/licenses https://www.cnblogs.com/Wayou/p/how_to_choose_a_license.html https://zhuanlan.zhihu.com/p/87855729 欢迎关注我的微信公众号【MySQL数据库技术】。 标题 网址 GitHub https://dbkernel.github.io 知乎 https://www.zhihu.com/people/dbkernel/posts 思否（SegmentFault） https://segmentfault.com/u/dbkernel 掘金 https://juejin.im/user/5e9d3ed251882538083fed1f/posts 开源中国（oschina） https://my.oschina.net/dbkernel 博客园（cnblogs） https://www.cnblogs.com/dbkernel","categories":[{"name":"开源","slug":"开源","permalink":"http://dbkernel.github.io/categories/%E5%BC%80%E6%BA%90/"}],"tags":[{"name":"开源协议","slug":"开源协议","permalink":"http://dbkernel.github.io/tags/%E5%BC%80%E6%BA%90%E5%8D%8F%E8%AE%AE/"},{"name":"开源许可证","slug":"开源许可证","permalink":"http://dbkernel.github.io/tags/%E5%BC%80%E6%BA%90%E8%AE%B8%E5%8F%AF%E8%AF%81/"},{"name":"LICENCE","slug":"LICENCE","permalink":"http://dbkernel.github.io/tags/LICENCE/"},{"name":"github","slug":"github","permalink":"http://dbkernel.github.io/tags/github/"}]},{"title":"源码分析 | ClickHouse和他的朋友们（3）MySQL Protocol和Write调用栈","slug":"clickhouse-and-friends-03-mysql-protocol-write-stack","date":"2020-06-08T11:57:10.000Z","updated":"2021-08-22T05:59:19.549Z","comments":true,"path":"2020/06/08/clickhouse-and-friends-03-mysql-protocol-write-stack/","link":"","permalink":"http://dbkernel.github.io/2020/06/08/clickhouse-and-friends-03-mysql-protocol-write-stack/","excerpt":"","text":"《ClickHouse和他的朋友们》系列文章转载自圈内好友 BohuTANG 的博客，原文链接：https://bohutang.me/2020/06/08/clickhouse-and-friends-mysql-protocol-write-stack/以下为正文。 上篇的MySQL Protocol和Read调用里介绍了 ClickHouse 一条查询语句的调用栈，本文继续介绍写的调用栈，开整。 Write请求 建表: 12mysql&gt; CREATE TABLE test(a UInt8, b UInt8, c UInt8) ENGINE=MergeTree() PARTITION BY (a, b) ORDER BY c;Query OK, 0 rows affected (0.03 sec) 写入数据： 1INSERT INTO test VALUES(1,1,1), (2,2,2); 调用栈分析1. 获取存储引擎 OutputStream1234567DB::StorageMergeTree::write(std::__1::shared_ptr&lt;DB::IAST&gt; const&amp;, DB::Context const&amp;) StorageMergeTree.cpp:174DB::PushingToViewsBlockOutputStream::PushingToViewsBlockOutputStream(std::__1::shared_ptr&lt;DB::IStorage&gt; const&amp;, DB::Context const&amp;, std::__1::shared_ptr&lt;DB::IAST&gt; const&amp;, bool) PushingToViewsBlockOutputStream.cpp:110DB::InterpreterInsertQuery::execute() InterpreterInsertQuery.cpp:229DB::executeQueryImpl(const char *, const char *, DB::Context &amp;, bool, DB::QueryProcessingStage::Enum, bool, DB::ReadBuffer *) executeQuery.cpp:364DB::executeQuery(DB::ReadBuffer&amp;, DB::WriteBuffer&amp;, bool, DB::Context&amp;, std::__1::function&lt;void (std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;)&gt;) executeQuery.cpp:696DB::MySQLHandler::comQuery(DB::ReadBuffer&amp;) MySQLHandler.cpp:311DB::MySQLHandler::run() MySQLHandler.cpp:141 2. 从 SQL 组装 InputStream(1,1,1), (2,2,2) 如何组装成 inputstream 结构呢？ 12345DB::InputStreamFromASTInsertQuery::InputStreamFromASTInsertQuery(std::__1::shared_ptr&lt;DB::IAST&gt; const&amp;, DB::ReadBuffer*,DB::InterpreterInsertQuery::execute() InterpreterInsertQuery.cpp:300DB::executeQueryImpl(char const*, char const*, DB::Context&amp;, bool, DB::QueryProcessingStage::Enum, bool, DB::ReadBuffer*) executeQuery.cpp:386DB::MySQLHandler::comQuery(DB::ReadBuffer&amp;) MySQLHandler.cpp:313DB::MySQLHandler::run() MySQLHandler.cpp:150 然后 12res.in = std::make_shared&lt;InputStreamFromASTInsertQuery&gt;(query_ptr, nullptr, query_sample_block, context, nullptr);res.in = std::make_shared&lt;NullAndDoCopyBlockInputStream&gt;(res.in, out_streams.at(0)); 通过 NullAndDoCopyBlockInputStream的 copyData 方法构造出 Block： 12345678910111213141516DB::ValuesBlockInputFormat::readRow(std::__1::vector&lt;COW&lt;DB::IColumn&gt;::mutable_ptr&lt;DB::IColumn&gt;, std::__1::allocator&lt;COW&lt;DB::IColumn&gt;::mutable_ptr&lt;DB::IColumn&gt; &gt; &gt;&amp;, unsigned long) ValuesBlockInputFormat.cpp:93DB::ValuesBlockInputFormat::generate() ValuesBlockInputFormat.cpp:55DB::ISource::work() ISource.cpp:48DB::InputStreamFromInputFormat::readImpl() InputStreamFromInputFormat.h:48DB::IBlockInputStream::read() IBlockInputStream.cpp:57DB::InputStreamFromASTInsertQuery::readImpl() InputStreamFromASTInsertQuery.h:31DB::IBlockInputStream::read() IBlockInputStream.cpp:57void DB::copyDataImpl&lt;DB::copyData(DB::IBlockInputStream&amp;, DB::IBlockOutputStream&amp;, std::__1::atomic&lt;bool&gt;*)::$_0&amp;, void (&amp;)(DB::Block const&amp;)&gt;(DB::IBlockInputStream&amp;, DB::IBlockOutputStream&amp;, DB::copyData(DB::IBlockInputStream&amp;, DB::IBlockOutputStream&amp;, std::__1::atomic&lt;bool&gt;*)::$_0&amp;, void (&amp;)(DB::Block const&amp;)) copyData.cpp:26DB::copyData(DB::IBlockInputStream&amp;, DB::IBlockOutputStream&amp;, std::__1::atomic&lt;bool&gt;*) copyData.cpp:62DB::NullAndDoCopyBlockInputStream::readImpl() NullAndDoCopyBlockInputStream.h:47DB::IBlockInputStream::read() IBlockInputStream.cpp:57void DB::copyDataImpl&lt;std::__1::function&lt;bool ()&gt; const&amp;, std::__1::function&lt;void (DB::Block const&amp;)&gt; const&amp;&gt;(DB::IBlockInputStream&amp;, DB::IBlockOutputStream&amp;, std::__1::function&lt;bool ()&gt; const&amp;, std::__1::function&lt;void (DB::Block const&amp;)&gt; const&amp;) copyData.cpp:26DB::copyData(DB::IBlockInputStream&amp;, DB::IBlockOutputStream&amp;, std::__1::function&lt;bool ()&gt; const&amp;, std::__1::function&lt;void (DB::Block const&amp;)&gt; const&amp;) copyData.cpp:73DB::executeQuery(DB::ReadBuffer&amp;, DB::WriteBuffer&amp;, bool, DB::Context&amp;, std::__1::function&lt;void (std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;)&gt;) executeQuery.cpp:785DB::MySQLHandler::comQuery(DB::ReadBuffer&amp;) MySQLHandler.cpp:313DB::MySQLHandler::run() MySQLHandler.cpp:150 3. 组装 OutputStream12345DB::InterpreterInsertQuery::execute() InterpreterInsertQuery.cpp:107DB::executeQueryImpl(const char *, const char *, DB::Context &amp;, bool, DB::QueryProcessingStage::Enum, bool, DB::ReadBuffer *) executeQuery.cpp:364DB::executeQuery(DB::ReadBuffer&amp;, DB::WriteBuffer&amp;, bool, DB::Context&amp;, std::__1::function&lt;void (std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;)&gt;) executeQuery.cpp:696DB::MySQLHandler::comQuery(DB::ReadBuffer&amp;) MySQLHandler.cpp:311DB::MySQLHandler::run() MySQLHandler.cpp:141 组装顺序: NullAndDoCopyBlockInputStream CountingBlockOutputStream AddingDefaultBlockOutputStream SquashingBlockOutputStream PushingToViewsBlockOutputStream MergeTreeBlockOutputStream 4. 写入OutputStream123456789101112131415DB::MergeTreeBlockOutputStream::write(DB::Block const&amp;) MergeTreeBlockOutputStream.cpp:17DB::PushingToViewsBlockOutputStream::write(DB::Block const&amp;) PushingToViewsBlockOutputStream.cpp:145DB::SquashingBlockOutputStream::finalize() SquashingBlockOutputStream.cpp:30DB::SquashingBlockOutputStream::writeSuffix() SquashingBlockOutputStream.cpp:50DB::AddingDefaultBlockOutputStream::writeSuffix() AddingDefaultBlockOutputStream.cpp:25DB::CountingBlockOutputStream::writeSuffix() CountingBlockOutputStream.h:37DB::copyDataImpl&lt;DB::copyData(DB::IBlockInputStream&amp;, DB::IBlockOutputStream&amp;, std::__1::atomic&lt;bool&gt;*)::&lt;lambda()&gt;&amp;, void (&amp;)(const DB::Block&amp;)&gt;(DB::IBlockInputStream &amp;, DB::IBlockOutputStream &amp;, &lt;lambda()&gt; &amp;, void (&amp;)(const DB::Block &amp;)) copyData.cpp:52DB::copyData(DB::IBlockInputStream&amp;, DB::IBlockOutputStream&amp;, std::__1::atomic&lt;bool&gt;*) copyData.cpp:138DB::NullAndDoCopyBlockInputStream::readImpl() NullAndDoCopyBlockInputStream.h:57DB::IBlockInputStream::read() IBlockInputStream.cpp:60void DB::copyDataImpl&lt;std::__1::function&lt;bool ()&gt; const&amp;, std::__1::function&lt;void (DB::Block const&amp;)&gt; const&amp;&gt;(DB::IBlockInputStream&amp;, DB::IBlockOutputStream&amp;, std::__1::function&lt;bool ()&gt; const&amp;, std::__1::function&lt;void (DB::Block const&amp;)&gt; const&amp;) copyData.cpp:29DB::copyData(DB::IBlockInputStream&amp;, DB::IBlockOutputStream&amp;, std::__1::function&lt;bool ()&gt; const&amp;, std::__1::function&lt;void (DB::Block const&amp;)&gt; const&amp;) copyData.cpp:154DB::executeQuery(DB::ReadBuffer&amp;, DB::WriteBuffer&amp;, bool, DB::Context&amp;, std::__1::function&lt;void (std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;)&gt;) executeQuery.cpp:748DB::MySQLHandler::comQuery(DB::ReadBuffer&amp;) MySQLHandler.cpp:311DB::MySQLHandler::run() MySQLHandler.cpp:141 通过 copyData 方法，让数据在 OutputStream 间层层透传，一直到 MergeTreeBlockOutputStream。 5. 返回 Client123456789DB::MySQLOutputFormat::finalize() MySQLOutputFormat.cpp:62DB::IOutputFormat::doWriteSuffix() IOutputFormat.h:78DB::OutputStreamToOutputFormat::writeSuffix() OutputStreamToOutputFormat.cpp:18DB::MaterializingBlockOutputStream::writeSuffix() MaterializingBlockOutputStream.h:22void DB::copyDataImpl&lt;std::__1::function&lt;bool ()&gt; const&amp;, std::__1::function&lt;void (DB::Block const&amp;)&gt; const&amp;&gt;(DB::IBlockInputStream&amp;, DB::IBlockOutputStream&amp;, std::__1::function&lt;bool ()&gt; const&amp;, std::__1::function&lt;void (DB::Block const&amp;)&gt; const&amp;) copyData.cpp:52DB::copyData(DB::IBlockInputStream&amp;, DB::IBlockOutputStream&amp;, std::__1::function&lt;bool ()&gt; const&amp;, std::__1::function&lt;void (DB::Block const&amp;)&gt; const&amp;) copyData.cpp:154DB::executeQuery(DB::ReadBuffer&amp;, DB::WriteBuffer&amp;, bool, DB::Context&amp;, std::__1::function&lt;void (std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;)&gt;) executeQuery.cpp:748DB::MySQLHandler::comQuery(DB::ReadBuffer&amp;) MySQLHandler.cpp:311DB::MySQLHandler::run() MySQLHandler.cpp:141 总结1INSERT INTO test VALUES(1,1,1), (2,2,2); 首先内核解析 SQL 语句生成 AST，根据 AST 获取 Interpreter：InterpreterInsertQuery。其次 Interpreter 依次添加相应的 OutputStream。然后从 InputStream 读取数据，写入到 OutputStream，stream 会层层渗透，一直写到底层的存储引擎。最后写入到 Socket Output，返回结果。 ClickHouse 的 OutputStream 编排还是比较复杂，缺少类似 Pipeline 的调度和编排，但是由于模式比较固化，目前看还算清晰。 欢迎关注我的微信公众号【MySQL数据库技术】。 标题 网址 GitHub https://dbkernel.github.io 知乎 https://www.zhihu.com/people/dbkernel/posts 思否（SegmentFault） https://segmentfault.com/u/dbkernel 掘金 https://juejin.im/user/5e9d3ed251882538083fed1f/posts 开源中国（oschina） https://my.oschina.net/dbkernel 博客园（cnblogs） https://www.cnblogs.com/dbkernel","categories":[{"name":"ClickHouse","slug":"ClickHouse","permalink":"http://dbkernel.github.io/categories/ClickHouse/"}],"tags":[{"name":"ClickHouse和他的朋友们","slug":"ClickHouse和他的朋友们","permalink":"http://dbkernel.github.io/tags/ClickHouse%E5%92%8C%E4%BB%96%E7%9A%84%E6%9C%8B%E5%8F%8B%E4%BB%AC/"},{"name":"ClickHouse","slug":"ClickHouse","permalink":"http://dbkernel.github.io/tags/ClickHouse/"},{"name":"源码分析","slug":"源码分析","permalink":"http://dbkernel.github.io/tags/%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"}]},{"title":"源码分析 | ClickHouse和他的朋友们（2）MySQL Protocol和Read调用栈","slug":"clickhouse-and-friends-02-mysql-protocol-read-stack","date":"2020-06-07T09:17:10.000Z","updated":"2021-08-22T06:00:12.009Z","comments":true,"path":"2020/06/07/clickhouse-and-friends-02-mysql-protocol-read-stack/","link":"","permalink":"http://dbkernel.github.io/2020/06/07/clickhouse-and-friends-02-mysql-protocol-read-stack/","excerpt":"","text":"《ClickHouse和他的朋友们》系列文章转载自圈内好友 BohuTANG 的博客，原文链接：https://bohutang.me/2020/06/07/clickhouse-and-friends-mysql-protocol-read-stack/以下为正文。 作为一个 OLAP 的 DBMS 来说，有2个端非常重要： 用户如何方便的链进来，这是入口端 ClickHouse 除了自己的 client 外，还提供了 MySQL/PG/GRPC/HTTP 等接入方式 数据如何方便的挂上去，这是数据源端 ClickHouse 除了自己的引擎外，还可以挂载 MySQL/Kafka 等外部数据源 这样内外互通，多条朋友多条路，以实现“数据”级的编排能力。 今天谈的是入口端的 MySQL 协议，也是本系列 ClickHouse 的第一个好朋友，用户可通过 MySQL 客户端或相关 Driver 直接链接到 ClickHouse，进行数据读写等操作。 本文通过 MySQL的 Query 请求，借用调用栈来了解下 ClickHouse 的数据读取全过程。 如何实现？入口文件在:MySQLHandler.cpp 握手协议 MySQLClient 发送 Greeting 数据报文到 MySQLHandler MySQLHandler 回复一个 Greeting-Response 报文 MySQLClient 发送认证报文 MySQLHandler 对认证报文进行鉴权，并返回鉴权结果 MySQL Protocol 实现在: Core/MySQLProtocol.h 最近的代码中调整为了 Core/MySQL/PacketsProtocolText.h Query请求当认证通过后，就可以进行正常的数据交互了。 当 MySQLClient 发送请求: 1mysql&gt; SELECT * FROM system.numbers LIMIT 5; MySQLHandler 的调用栈： 1-&gt;MySQLHandler::comQuery -&gt; executeQuery -&gt; pipeline-&gt;execute -&gt; MySQLOutputFormat::consume MySQLClient 接收到结果 在步骤2里，executeQuery(executeQuery.cpp)非常重要。它是所有前端 Server 和 ClickHouse 内核的接入口，第一个参数是 SQL 文本(‘select 1’)，第二个参数是结果集要发送到哪里去(socket net)。 调用栈分析1SELECT * FROM system.numbers LIMIT 5 1. 获取数据源StorageSystemNumbers 数据源： 123456789101112DB::StorageSystemNumbers::read(std::__1::vector&lt;std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt;, std::__1::allocator&lt;std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; &gt; &gt; const&amp;, std::__1::shared_ptr&lt;DB::StorageInMemoryMetadata const&gt; const&amp;, DB::SelectQueryInfo const&amp;, DB::Context const&amp;, DB::QueryProcessingStage::Enum, unsigned long, unsigned int) StorageSystemNumbers.cpp:135DB::ReadFromStorageStep::ReadFromStorageStep(std::__1::shared_ptr&lt;DB::RWLockImpl::LockHolderImpl&gt;, std::__1::shared_ptr&lt;DB::StorageInMemoryMetadata const&gt;&amp;, DB::SelectQueryOptions,DB::InterpreterSelectQuery::executeFetchColumns(DB::QueryProcessingStage::Enum, DB::QueryPlan&amp;, std::__1::shared_ptr&lt;DB::PrewhereInfo&gt; const&amp;, std::__1::vector&lt;std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt;, std::__1::allocator&lt;std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; &gt; &gt; const&amp;) memory:3028DB::InterpreterSelectQuery::executeFetchColumns(DB::QueryProcessingStage::Enum, DB::QueryPlan&amp;, std::__1::shared_ptr&lt;DB::PrewhereInfo&gt; const&amp;, std::__1::vector&lt;std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt;, std::__1::allocator&lt;std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; &gt; &gt; const&amp;) InterpreterSelectQuery.cpp:1361DB::InterpreterSelectQuery::executeImpl(DB::QueryPlan&amp;, std::__1::shared_ptr&lt;DB::IBlockInputStream&gt; const&amp;, std::__1::optional&lt;DB::Pipe&gt;) InterpreterSelectQuery.cpp:791DB::InterpreterSelectQuery::buildQueryPlan(DB::QueryPlan&amp;) InterpreterSelectQuery.cpp:472DB::InterpreterSelectWithUnionQuery::buildQueryPlan(DB::QueryPlan&amp;) InterpreterSelectWithUnionQuery.cpp:183DB::InterpreterSelectWithUnionQuery::execute() InterpreterSelectWithUnionQuery.cpp:198DB::executeQueryImpl(const char *, const char *, DB::Context &amp;, bool, DB::QueryProcessingStage::Enum, bool, DB::ReadBuffer *) executeQuery.cpp:385DB::executeQuery(DB::ReadBuffer&amp;, DB::WriteBuffer&amp;, bool, DB::Context&amp;, std::__1::function&lt;void (std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;,DB::MySQLHandler::comQuery(DB::ReadBuffer&amp;) MySQLHandler.cpp:307DB::MySQLHandler::run() MySQLHandler.cpp:141 这里最主要的是 ReadFromStorageStep 函数，从不同 storage 里获取数据源 pipe: 1Pipes pipes = storage-&gt;read(required_columns, metadata_snapshot, query_info, *context, processing_stage, max_block_size, max_streams); 2. Pipeline构造12345678910111213DB::LimitTransform::LimitTransform(DB::Block const&amp;, unsigned long, unsigned long, unsigned long, bool, bool, std::__1::vector&lt;DB::SortColumnDescription, std::__1::allocator&lt;DB::SortColumnDescription&gt; &gt;) LimitTransform.cpp:21DB::LimitStep::transformPipeline(DB::QueryPipeline&amp;) memory:2214DB::LimitStep::transformPipeline(DB::QueryPipeline&amp;) memory:2299DB::LimitStep::transformPipeline(DB::QueryPipeline&amp;) memory:3570DB::LimitStep::transformPipeline(DB::QueryPipeline&amp;) memory:4400DB::LimitStep::transformPipeline(DB::QueryPipeline&amp;) LimitStep.cpp:33DB::ITransformingStep::updatePipeline(std::__1::vector&lt;std::__1::unique_ptr&lt;DB::QueryPipeline, std::__1::default_delete&lt;DB::QueryPipeline&gt; &gt;, std::__1::allocator&lt;std::__1::unique_ptr&lt;DB::QueryPipeline, std::__1::default_delete&lt;DB::QueryPipeline&gt; &gt; &gt; &gt;) ITransformingStep.cpp:21DB::QueryPlan::buildQueryPipeline() QueryPlan.cpp:154DB::InterpreterSelectWithUnionQuery::execute() InterpreterSelectWithUnionQuery.cpp:200DB::executeQueryImpl(const char *, const char *, DB::Context &amp;, bool, DB::QueryProcessingStage::Enum, bool, DB::ReadBuffer *) executeQuery.cpp:385DB::executeQuery(DB::ReadBuffer&amp;, DB::WriteBuffer&amp;, bool, DB::Context&amp;, std::__1::function&lt;void (std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;)&gt;) executeQuery.cpp:722DB::MySQLHandler::comQuery(DB::ReadBuffer&amp;) MySQLHandler.cpp:307DB::MySQLHandler::run() MySQLHandler.cpp:141 3. Pipeline执行123456789101112131415161718DB::LimitTransform::prepare(std::__1::vector&lt;unsigned long, std::__1::allocator&lt;unsigned long&gt; &gt; const&amp;, std::__1::vector&lt;unsigned long, std::__1::allocator&lt;unsigned long&gt; &gt; const&amp;) LimitTransform.cpp:67DB::PipelineExecutor::prepareProcessor(unsigned long, unsigned long, std::__1::queue&lt;DB::PipelineExecutor::ExecutionState*, std::__1::deque&lt;DB::PipelineExecutor::ExecutionState*, std::__1::allocator&lt;DB::PipelineExecutor::ExecutionState*&gt; &gt; &gt;&amp;, std::__1::unique_lock&lt;std::__1::mutex&gt;) PipelineExecutor.cpp:291DB::PipelineExecutor::tryAddProcessorToStackIfUpdated(DB::PipelineExecutor::Edge&amp;, std::__1::queue&lt;DB::PipelineExecutor::ExecutionState*, std::__1::deque&lt;DB::PipelineExecutor::ExecutionState*, std::__1::allocator&lt;DB::PipelineExecutor::ExecutionState*&gt; &gt; &gt;&amp;, unsigned long) PipelineExecutor.cpp:264DB::PipelineExecutor::prepareProcessor(unsigned long, unsigned long, std::__1::queue&lt;DB::PipelineExecutor::ExecutionState*, std::__1::deque&lt;DB::PipelineExecutor::ExecutionState*, std::__1::allocator&lt;DB::PipelineExecutor::ExecutionState*&gt; &gt; &gt;&amp;, std::__1::unique_lock&lt;std::__1::mutex&gt;) PipelineExecutor.cpp:373DB::PipelineExecutor::tryAddProcessorToStackIfUpdated(DB::PipelineExecutor::Edge&amp;, std::__1::queue&lt;DB::PipelineExecutor::ExecutionState*, std::__1::deque&lt;DB::PipelineExecutor::ExecutionState*, std::__1::allocator&lt;DB::PipelineExecutor::ExecutionState*&gt; &gt; &gt;&amp;, unsigned long) PipelineExecutor.cpp:264DB::PipelineExecutor::prepareProcessor(unsigned long, unsigned long, std::__1::queue&lt;DB::PipelineExecutor::ExecutionState*, std::__1::deque&lt;DB::PipelineExecutor::ExecutionState*, std::__1::allocator&lt;DB::PipelineExecutor::ExecutionState*&gt; &gt; &gt;&amp;, std::__1::unique_lock&lt;std::__1::mutex&gt;) PipelineExecutor.cpp:373DB::PipelineExecutor::tryAddProcessorToStackIfUpdated(DB::PipelineExecutor::Edge&amp;, std::__1::queue&lt;DB::PipelineExecutor::ExecutionState*, std::__1::deque&lt;DB::PipelineExecutor::ExecutionState*, std::__1::allocator&lt;DB::PipelineExecutor::ExecutionState*&gt; &gt; &gt;&amp;, unsigned long) PipelineExecutor.cpp:264DB::PipelineExecutor::prepareProcessor(unsigned long, unsigned long, std::__1::queue&lt;DB::PipelineExecutor::ExecutionState*, std::__1::deque&lt;DB::PipelineExecutor::ExecutionState*, std::__1::allocator&lt;DB::PipelineExecutor::ExecutionState*&gt; &gt; &gt;&amp;, std::__1::unique_lock&lt;std::__1::mutex&gt;) PipelineExecutor.cpp:373DB::PipelineExecutor::tryAddProcessorToStackIfUpdated(DB::PipelineExecutor::Edge&amp;, std::__1::queue&lt;DB::PipelineExecutor::ExecutionState*, std::__1::deque&lt;DB::PipelineExecutor::ExecutionState*, std::__1::allocator&lt;DB::PipelineExecutor::ExecutionState*&gt; &gt; &gt;&amp;, unsigned long) PipelineExecutor.cpp:264DB::PipelineExecutor::prepareProcessor(unsigned long, unsigned long, std::__1::queue&lt;DB::PipelineExecutor::ExecutionState*, std::__1::deque&lt;DB::PipelineExecutor::ExecutionState*, std::__1::allocator&lt;DB::PipelineExecutor::ExecutionState*&gt; &gt; &gt;&amp;, std::__1::unique_lock&lt;std::__1::mutex&gt;) PipelineExecutor.cpp:373DB::PipelineExecutor::tryAddProcessorToStackIfUpdated(DB::PipelineExecutor::Edge&amp;, std::__1::queue&lt;DB::PipelineExecutor::ExecutionState*, std::__1::deque&lt;DB::PipelineExecutor::ExecutionState*, std::__1::allocator&lt;DB::PipelineExecutor::ExecutionState*&gt; &gt; &gt;&amp;, unsigned long) PipelineExecutor.cpp:264DB::PipelineExecutor::prepareProcessor(unsigned long, unsigned long, std::__1::queue&lt;DB::PipelineExecutor::ExecutionState*, std::__1::deque&lt;DB::PipelineExecutor::ExecutionState*, std::__1::allocator&lt;DB::PipelineExecutor::ExecutionState*&gt; &gt; &gt;&amp;, std::__1::unique_lock&lt;std::__1::mutex&gt;) PipelineExecutor.cpp:373DB::PipelineExecutor::initializeExecution(unsigned long) PipelineExecutor.cpp:747DB::PipelineExecutor::executeImpl(unsigned long) PipelineExecutor.cpp:764DB::PipelineExecutor::execute(unsigned long) PipelineExecutor.cpp:479DB::executeQuery(DB::ReadBuffer&amp;, DB::WriteBuffer&amp;, bool, DB::Context&amp;, std::__1::function&lt;void (std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;)&gt;) executeQuery.cpp:833DB::MySQLHandler::comQuery(DB::ReadBuffer&amp;) MySQLHandler.cpp:307DB::MySQLHandler::run() MySQLHandler.cpp:141 4. Output执行发送1234567891011DB::MySQLOutputFormat::consume(DB::Chunk) MySQLOutputFormat.cpp:53DB::IOutputFormat::work() IOutputFormat.cpp:62DB::executeJob(DB::IProcessor *) PipelineExecutor.cpp:155operator() PipelineExecutor.cpp:172DB::PipelineExecutor::executeStepImpl(unsigned long, unsigned long, std::__1::atomic&lt;bool&gt;*) PipelineExecutor.cpp:630DB::PipelineExecutor::executeSingleThread(unsigned long, unsigned long) PipelineExecutor.cpp:546DB::PipelineExecutor::executeImpl(unsigned long) PipelineExecutor.cpp:812DB::PipelineExecutor::execute(unsigned long) PipelineExecutor.cpp:479DB::executeQuery(DB::ReadBuffer&amp;, DB::WriteBuffer&amp;, bool, DB::Context&amp;, std::__1::function&lt;void (std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;)&gt;) executeQuery.cpp:800DB::MySQLHandler::comQuery(DB::ReadBuffer&amp;) MySQLHandler.cpp:311DB::MySQLHandler::run() MySQLHandler.cpp:141 总结ClickHouse 的模块化比较清晰，像乐高积木一样可以组合拼装，当我们执行: 1SELECT * FROM system.numbers LIMIT 5 首先内核解析 SQL 语句生成 AST，然后根据 AST 获取数据源 Source，pipeline.Add(Source)。其次根据 AST 信息生成 QueryPlan，根据 QueryPlan 再生成相应的 Transform，pipeline.Add(LimitTransform)。然后添加 Output Sink 作为数据发送对象，pipeline.Add(OutputSink)。执行 pipeline, 各个 Transformer 开始工作。 ClickHouse 的 Transformer 调度系统叫做 Processor，也是决定性能的重要模块，详情见 Pipeline 处理器和调度器。ClickHouse 是一辆手动挡的豪华跑车，免费拥有，海啸们！ 欢迎关注我的微信公众号【MySQL数据库技术】。 标题 网址 GitHub https://dbkernel.github.io 知乎 https://www.zhihu.com/people/dbkernel/posts 思否（SegmentFault） https://segmentfault.com/u/dbkernel 掘金 https://juejin.im/user/5e9d3ed251882538083fed1f/posts 开源中国（oschina） https://my.oschina.net/dbkernel 博客园（cnblogs） https://www.cnblogs.com/dbkernel","categories":[{"name":"ClickHouse","slug":"ClickHouse","permalink":"http://dbkernel.github.io/categories/ClickHouse/"}],"tags":[{"name":"ClickHouse和他的朋友们","slug":"ClickHouse和他的朋友们","permalink":"http://dbkernel.github.io/tags/ClickHouse%E5%92%8C%E4%BB%96%E7%9A%84%E6%9C%8B%E5%8F%8B%E4%BB%AC/"},{"name":"ClickHouse","slug":"ClickHouse","permalink":"http://dbkernel.github.io/tags/ClickHouse/"},{"name":"源码分析","slug":"源码分析","permalink":"http://dbkernel.github.io/tags/%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"}]},{"title":"源码分析 | ClickHouse和他的朋友们（1）编译、开发、测试","slug":"clickhouse-and-friends-01-development","date":"2020-06-05T11:37:10.000Z","updated":"2021-08-22T05:58:57.049Z","comments":true,"path":"2020/06/05/clickhouse-and-friends-01-development/","link":"","permalink":"http://dbkernel.github.io/2020/06/05/clickhouse-and-friends-01-development/","excerpt":"","text":"《ClickHouse和他的朋友们》系列文章转载自圈内好友 BohuTANG 的博客，原文链接：https://bohutang.me/2020/06/05/clickhouse-and-friends-development/以下为正文。 一次偶然的机会，和ClickHouse团队做了一次线下沟通，Alexey提到ClickHouse的设计哲学: The product must solve actual problem And do it better than others 用工程思维解决商业问题的典范啊！ 对用户来说，他们关心的不是什么天花乱坠、上天入地的高科技，只是需要一个能很好解决自己问题的方案，这在开源社区是非常难得的，靠实力“野蛮式”生长。 于是，我对这个散发着伏特加味道的利器充满了好奇，并参与到ClickHouse的社区中一探究竟，第一感觉是开放、友好、战斗力强(AK47 vs CK16, ClickHouse 2016年开源)。 本文先从编译和测试入手，再到如何为社区贡献Patch，希望对那些想参与CK社区的同学有所帮助。 如何本地编译和测试ClickHouse？源码获取1git clone --recursive https://github.com/ClickHouse/ClickHouse 编译准备1234567sudo apt install build-essentialsudo apt-get install software-properties-commonsudo apt-add-repository ppa:ubuntu-toolchain-r/testsudo apt-get updatesudo apt-get install gcc-9 g++-9 git python ninja-buildsudo snap install cmake 开始编译1234567cd ClickHousemkdir buildcd buildexport CC=gcc-9export CXX=g++-9cmake ..ninja 测试方法ClickHouse的测试在官方development/tests文档里有详细的介绍，这里列举3个常用的测试模式： 1. Functional Tests功能测试，主要用于ClickHouse内部功能测试，方式：输入一个sql文件，输出一个result，类似MySQL里的mtr，测试集合 12cd tests./clickhouse-test -c &quot;../build/programs/clickhouse-client&quot; 00001_select_1 2. Integration Tests集成测试，主要用于涉及第三方服务的测试，比如MySQL/Postgres/MongoDB等，以容器化方式编排调度(pytest)运行，测试集合 由于涉及模块较多，集成测试环境的搭建有一定的难度，建议使用官方的docker镜像。比如要跑test_mysql_protocol下的集成测试集： 123cd tests/integrationdocker pull yandex/clickhouse-integration-tests-runner./runner --binary /your/ClickHouse/build/programs/clickhouse --bridge-binary /your/ClickHouse/build/programs/clickhouse-odbc-bridge --configs-dir /your/ClickHouse/programs/server/ &#x27;test_mysql_protocol/test.py::test_java_client -ss -vv&#x27; 3. Unit Tests单元测试，主要用于代码模块的测试，测试集在各个模块的tests目录，比如: Core/tests 如果大家想了解某个模块是如何工作的，强烈建议去翻翻该模块的tests目录，比如想了解processor的工作机制，跟踪调试 Processors/tests/ 即可。 如何给ClickHouse社区提Patch？1. fork首先在自己的github上fork一份ClickHouse代码，比如 https://github.com/BohuTANG/ClickHouse 2. clone到本地12git clone --recursive https://github.com/BohuTANG/ClickHousegit checkout -B mysql_replica(branch名字) 3. 创建新的分支1git checkout -B mysql_replica(branch名字) 4. 功能开发开发者可以提交一个Draft Pull Request到官方，github会显示这个Pull Request处于Draft状态，官方是无法Merge的 5. can be testd标签等待Upstream打[can be tested]标签，一旦被标记CI狂魔们就强势开跑，跑一轮大概需要几十个小时。协助开发者发现一些代码Style、编译以及测试等错误，这样开发者就可以在自己的分支不停的迭代、修正。 如果只是修改typo，这个标签Upstream通常不会添加。 6. 开发完毕开发完成，测试OK，把Draft提升为正式Pull Request，等待Upstraem Review。 7. Merge到Master如果Upstream通过，你的代码会被Merge到Master，恭喜你成为ClickHouse贡献者 8. 注意事项ClickHouse Upstream迭代非常快，一定要多关注master分支进度，尽量保持自己的分支代码与master同步。否则Upstream Docker更新，自己的test可能就过不了。 建议把doc/development读一遍。 欢迎关注我的微信公众号【MySQL数据库技术】。 标题 网址 GitHub https://dbkernel.github.io 知乎 https://www.zhihu.com/people/dbkernel/posts 思否（SegmentFault） https://segmentfault.com/u/dbkernel 掘金 https://juejin.im/user/5e9d3ed251882538083fed1f/posts 开源中国（oschina） https://my.oschina.net/dbkernel 博客园（cnblogs） https://www.cnblogs.com/dbkernel","categories":[{"name":"ClickHouse","slug":"ClickHouse","permalink":"http://dbkernel.github.io/categories/ClickHouse/"}],"tags":[{"name":"ClickHouse和他的朋友们","slug":"ClickHouse和他的朋友们","permalink":"http://dbkernel.github.io/tags/ClickHouse%E5%92%8C%E4%BB%96%E7%9A%84%E6%9C%8B%E5%8F%8B%E4%BB%AC/"},{"name":"ClickHouse","slug":"ClickHouse","permalink":"http://dbkernel.github.io/tags/ClickHouse/"},{"name":"源码分析","slug":"源码分析","permalink":"http://dbkernel.github.io/tags/%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"}]},{"title":"引擎特性 | MySQL select count(*) 、count(1)、count(列) 详解（1）：概念及区别","slug":"mysql-select-count-functions-01-concepts-and-differences","date":"2020-05-06T07:55:15.000Z","updated":"2021-08-22T05:59:50.136Z","comments":true,"path":"2020/05/06/mysql-select-count-functions-01-concepts-and-differences/","link":"","permalink":"http://dbkernel.github.io/2020/05/06/mysql-select-count-functions-01-concepts-and-differences/","excerpt":"","text":"一、前言从接触MySQL开始断断续续的看过一些文章，对count()操作众说纷纭，其中分歧点主要在于count(1)和count(*)哪个效率高，有说count(1)比count(*)快的（这种说法更普遍），有说二者一样快的。个人理解这两种行为可能适用于的是不同的版本，我只关心较新的MySQL版本是什么行为，详见下文。 二、含义首先，先说明一下常见count()操作及含义： count(*)：计算包括NULL值在内的行数，SQL92定义的标准统计行数的语法。 count(1)：计算包括NULL值在内的行数，其中的1是恒真表达式。 count(列名)：计算指定列的行数，但不包含NULL值。 三、具体区别MySQL手册中相关描述如下： For transactional storage engines such as InnoDB, storing an exact row count is problematic. Multiple transactions may be occurring at the same time, each of which may affect the count. InnoDB does not keep an internal count of rows in a table because concurrent transactions might “see” different numbers of rows at the same time. Consequently, SELECT COUNT(*) statements only count rows visible to the current transaction. Prior to MySQL 5.7.18, InnoDB processes SELECT COUNT(*) statements by scanning the clustered index. As of MySQL 5.7.18, InnoDB processes SELECT COUNT(*) statements by traversing the smallest available secondary index unless an index or optimizer hint directs the optimizer to use a different index. If a secondary index is not present, the clustered index is scanned. Processing SELECT COUNT(*) statements takes some time if index records are not entirely in the buffer pool. For a faster count, create a counter table and let your application update it according to the inserts and deletes it does. However, this method may not scale well in situations where thousands of concurrent transactions are initiating updates to the same counter table. If an approximate row count is sufficient, use SHOW TABLE STATUS. InnoDB handles SELECT COUNT(*) and SELECT COUNT(1) operations in the same way. There is no performance difference. For MyISAM tables, COUNT(*) is optimized to return very quickly if the SELECT retrieves from one table, no other columns are retrieved, and there is no WHERE clause. For example: 1&gt;mysql&gt; SELECT COUNT(*) FROM student; This optimization only applies to MyISAM tables, because an exact row count is stored for this storage engine and can be accessed very quickly.COUNT(1) is only subject to the same optimization if the first column is defined as NOT NULL. 官方这段描述要点如下： InnoDB是事务引擎，支持MVCC，并发事务可能同时“看到”不同的行数，所以，InnoDB不保留表中的行数，SELECT COUNT(*)语句只计算当前事务可见的行数。 在MySQL 5.7.18之前，InnoDB通过扫描聚集索引处理SELECT COUNT(*)语句。从MySQL 5.7.18开始，InnoDB通过遍历最小的可用二级索引来处理SELECT COUNT(*)语句，除非索引或优化器明确指示使用不同的索引。如果不存在二级索引，则扫描聚集索引。这样的设计单从 IO 的角度就节省了很多开销。 InnoDB以同样的方式处理SELECT COUNT(*)和SELECT COUNT(1)操作，没有性能差异。 因此，建议使用符合SQL标准的count(*)。 对于MyISAM表，由于MyISAM引擎存储了精确的行数，因此，如果SELECT COUNT(*)语句不包含WHERE子句，则会很快返回。这个很好理解，如果带了where条件，就需要扫表了。 如果索引记录不完全在缓冲池中，则处理SELECT(*)语句需要一些时间。为了更快的计数，您可以创建一个计数器表，并让您的应用程序按插入和删除操作更新它。然而，这种方法在同一计数器表中启动成千上万个并发事务的情况下，可能无法很好地扩展。如果一个近似的行数足够，可以使用SHOW TABLE STATUS查询行数。 到这里我们明白了 count(*) 和 count(1) 本质上面其实是一样的，那么 count(column) 又是怎么回事呢？ count(column) 也是会遍历整张表，但是不同的是它会拿到 column 的值以后判断是否为空，然后再进行累加，那么如果针对主键需要解析内容，如果是二级索引需要再次根据主键获取内容，则要多一次 IO 操作，所以 count(column) 的性能肯定不如前两者，如果按照效率比较的话：*count()=count(1)&gt;count(primary key)&gt;count(非主键column)**。 四、建议基于以上描述，如果要查询innodb存储引擎的表的总行数，有如下建议： 若仅仅是想获取大概的行数，建议使用show table status或查询information_schema.tables：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667mysql&gt; use db6;Reading table information for completion of table and column namesYou can turn off this feature to get a quicker startup with -ADatabase changedmysql&gt; show tables;+---------------+| Tables_in_db6 |+---------------+| t1 |+---------------+1 row in set (0.01 sec)mysql&gt; select count(*) from t1;+----------+| count(*) |+----------+| 2 |+----------+1 row in set (0.00 sec)mysql&gt; show table status\\G*************************** 1. row *************************** Name: t1 Engine: InnoDB Version: 10 Row_format: Dynamic Rows: 2 Avg_row_length: 8192 Data_length: 16384Max_data_length: 0 Index_length: 0 Data_free: 0 Auto_increment: NULL Create_time: 2020-04-21 12:00:44 Update_time: NULL Check_time: NULL Collation: utf8mb4_general_ci Checksum: NULL Create_options: Comment:1 row in set (0.00 sec)mysql&gt; select * from information_schema.tables where table_name = &#x27;t1&#x27;\\G*************************** 1. row *************************** TABLE_CATALOG: def TABLE_SCHEMA: db6 TABLE_NAME: t1 TABLE_TYPE: BASE TABLE ENGINE: InnoDB VERSION: 10 ROW_FORMAT: Dynamic TABLE_ROWS: 2 AVG_ROW_LENGTH: 8192 DATA_LENGTH: 16384MAX_DATA_LENGTH: 0 INDEX_LENGTH: 0 DATA_FREE: 0 AUTO_INCREMENT: NULL CREATE_TIME: 2020-04-21 12:00:44 UPDATE_TIME: NULL CHECK_TIME: NULLTABLE_COLLATION: utf8mb4_general_ci CHECKSUM: NULL CREATE_OPTIONS: TABLE_COMMENT:1 row in set (0.00 sec) 反之，如果必须要获取准确的总行数，建议： 创建一个计数器表，并让您的应用程序按插入和删除操作更新它。 若业务插入和删除相对较少，也可以考虑缓存到 redis。 篇幅有限，深入验证、源码分析将在下一篇文章中介绍。 欢迎关注我的微信公众号【MySQL数据库技术】。 标题 网址 GitHub https://dbkernel.github.io 知乎 https://www.zhihu.com/people/dbkernel/posts 思否（SegmentFault） https://segmentfault.com/u/dbkernel 掘金 https://juejin.im/user/5e9d3ed251882538083fed1f/posts 开源中国（oschina） https://my.oschina.net/dbkernel 博客园（cnblogs） https://www.cnblogs.com/dbkernel","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://dbkernel.github.io/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://dbkernel.github.io/tags/MySQL/"},{"name":"Select","slug":"Select","permalink":"http://dbkernel.github.io/tags/Select/"},{"name":"Count","slug":"Count","permalink":"http://dbkernel.github.io/tags/Count/"}]},{"title":"引擎特性 | MySQL-自增列详解（1）：自增列概念及使用","slug":"mysql-auto_increment-details-01-concepts-and-usage","date":"2019-12-09T11:37:10.000Z","updated":"2021-08-22T05:59:32.101Z","comments":true,"path":"2019/12/09/mysql-auto_increment-details-01-concepts-and-usage/","link":"","permalink":"http://dbkernel.github.io/2019/12/09/mysql-auto_increment-details-01-concepts-and-usage/","excerpt":"一直想写一些关于自增列的文章，今天下班比较早，Let’s do this.","text":"一直想写一些关于自增列的文章，今天下班比较早，Let’s do this. 1. 概念自增列，即 AUTO_INCREMENT，可用于为新的记录生成唯一标识。 要求： AUTO_INCREMENT 是数据列的一种属性，只适用于整数类型数据列。 AUTO_INCREMENT 数据列必须具备 NOT NULL 属性。 2. 使用方法2.1. 创建含自增列的表1234567-- 不指定 AUTO_INCREMENT 的值，则从1开始mysql&gt; create table t1(a int auto_increment primary key,b int);Query OK, 0 rows affected (0.01 sec)-- 手动指定 AUTO_INCREMENT 的值mysql&gt; create table t2(a int auto_increment primary key,b int) AUTO_INCREMENT=100;Query OK, 0 rows affected (0.02 sec) 2.2. 插入数据12345678910111213141516-- 不指定自增列mysql&gt; insert into t1(b) values(1),(2);Query OK, 1 row affected (0.00 sec)mysql&gt; select * from t1;+---+------+| a | b |+---+------+| 1 | 1 || 2 | 2 |+---+------+3 rows in set (0.00 sec)-- 指定自增列mysql&gt; insert into t1(a,b) values(3,3);Query OK, 1 row affected (0.00 sec) 2.3. 如何查看表的 AUTO_INCREMENT 涨到了多少？1234567891011mysql&gt; show create table t1;+-------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+| Table | Create Table |+-------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+| t1 | CREATE TABLE `t1` ( `a` int(11) NOT NULL AUTO_INCREMENT, `b` int(11) DEFAULT NULL, PRIMARY KEY (`a`)) ENGINE=InnoDB AUTO_INCREMENT=3 DEFAULT CHARSET=utf8 |+-------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+1 row in set (0.00 sec) 2.4. 插入数据时能否有空洞？可以的，但要注意 AUTO_INCREMENT 的值一定比自增列当前最大的记录值大。 1234567891011121314151617181920212223242526-- 创造空洞mysql&gt; insert into t1(a,b) values(5,5);Query OK, 1 row affected (0.00 sec)mysql&gt; select * from t1;+---+------+| a | b |+---+------+| 1 | 1 || 2 | 2 || 3 | 3 || 5 | 5 |+---+------+5 rows in set (0.00 sec)mysql&gt; show create table t1;+-------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+| Table | Create Table |+-------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+| t1 | CREATE TABLE `t1` ( `a` int(11) NOT NULL AUTO_INCREMENT, `b` int(11) DEFAULT NULL, PRIMARY KEY (`a`)) ENGINE=InnoDB AUTO_INCREMENT=6 DEFAULT CHARSET=utf8 |+-------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+1 row in set (0.00 sec) 2.5. 能否插入重复记录既然自增列是唯一记录，那么肯定不能插入重复记录。 123-- 尝试插入重复记录mysql&gt; insert into t1(a,b) values(5,5);ERROR 1062 (23000): Duplicate entry &#x27;5&#x27; for key &#x27;PRIMARY&#x27; 2.6. 怎么修改 AUTO_INCREMENT 的值？注意：AUTO_INCREMENT 不能小于当前自增列记录的最大值。 12345678910111213141516171819202122232425262728293031323334-- 尝试将 AUTO_INCREMENT 设为10mysql&gt; alter table t1 AUTO_INCREMENT=10;Query OK, 0 rows affected (0.01 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; show create table t1;+-------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+| Table | Create Table |+-------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+| t1 | CREATE TABLE `t1` ( `a` int(11) NOT NULL AUTO_INCREMENT, `b` int(11) DEFAULT NULL, PRIMARY KEY (`a`)) ENGINE=InnoDB AUTO_INCREMENT=10 DEFAULT CHARSET=utf8 |+-------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+1 row in set (0.00 sec)-- 尝试将 AUTO_INCREMENT 设为4mysql&gt; alter table t1 AUTO_INCREMENT=4;Query OK, 0 rows affected (0.00 sec)Records: 0 Duplicates: 0 Warnings: 0-- 由于自增列最大记录值是5，那么 AUTO_INCREMENT 不能小于5，因此该值为6mysql&gt; show create table t1;+-------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+| Table | Create Table |+-------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+| t1 | CREATE TABLE `t1` ( `a` int(11) NOT NULL AUTO_INCREMENT, `b` int(11) DEFAULT NULL, PRIMARY KEY (`a`)) ENGINE=InnoDB AUTO_INCREMENT=6 DEFAULT CHARSET=utf8 |+-------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+1 row in set (0.00 sec) 3. 问题3.1. 自增列是否有上限？由上文可见，自增列会一直增加，那是否有上限呢？ 上文中表 t1 的自增列是 int 类型，由下表（MySQL 5.7）可见取值范围是 -2147483648 到 2147483647（ -231 ~ 231 - 1 ）。 Type Storage (Bytes) Minimum Value Signed Minimum Value Unsigned Maximum Value Signed Maximum Value Unsigned TINYINT 1 -128 0 127 255 SMALLINT 2 -32768 0 32767 65535 MEDIUMINT 3 -8388608 0 8388607 16777215 INT 4 -2147483648 0 2147483647 4294967295 BIGINT 8 -263 0 263-1 264-1 验证如下： 12345678910111213141516171819202122232425262728mysql&gt; show create table t1;+-------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| Table | Create Table |+-------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| t1 | CREATE TABLE `t1` ( `a` int(11) NOT NULL AUTO_INCREMENT, `b` int(11) DEFAULT NULL, PRIMARY KEY (`a`)) ENGINE=InnoDB AUTO_INCREMENT=2147483644 DEFAULT CHARSET=utf8 |+-------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------+1 row in set (0.01 sec)mysql&gt; insert into t1(b) values(0),(0),(0);Query OK, 1 row affected (0.00 sec)mysql&gt; insert into t1(b) values(0);ERROR 1062 (23000): Duplicate entry &#x27;2147483647&#x27; for key &#x27;PRIMARY&#x27;mysql&gt; show create table t1;+-------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| Table | Create Table |+-------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| t1 | CREATE TABLE `t1` ( `a` int(11) NOT NULL AUTO_INCREMENT, `b` int(11) DEFAULT NULL, PRIMARY KEY (`a`)) ENGINE=InnoDB AUTO_INCREMENT=2147483647 DEFAULT CHARSET=utf8 |+-------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------+1 row in set (0.00 sec) 这里需要补充说明下 int(11) 中的数字的含义： MySQL中整数数据类型后面的(N)指定显示宽度。显示宽度不影响查询出来的结果。显示宽度限制了小数点的位置(只要实际数字不超过显示宽度，这种情况下，数字显示为原样)。显示宽度也是一个有用的工具，可以让开发人员知道应该将值填充到哪个长度。 3.2. 如何避免自增列超过最大值？可以采用无符号的 BIGINT 类型（也可根据业务产生自增列的速度采用合适的类型），能极大提升自增列的范围。 1234567891011121314151617181920212223242526272829303132mysql&gt; create table t2(a bigint unsigned primary key auto_increment,b int);Query OK, 0 rows affected (0.00 sec)mysql&gt; alter table t2 auto_increment=18446744073709551613;Query OK, 0 rows affected (0.00 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; show create table t2;+-------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| Table | Create Table |+-------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| t2 | CREATE TABLE `t2` ( `a` bigint(20) unsigned NOT NULL AUTO_INCREMENT, `b` int(11) DEFAULT NULL, PRIMARY KEY (`a`)) ENGINE=InnoDB AUTO_INCREMENT=18446744073709551613 DEFAULT CHARSET=utf8 |+-------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+1 row in set (0.01 sec)mysql&gt; insert into t2(b) values(0);Query OK, 1 row affected (0.00 sec)mysql&gt; insert into t2(b) values(0);ERROR 1467 (HY000): Failed to read auto-increment value from storage enginemysql&gt;mysql&gt; select * from t2;+----------------------+------+| a | b |+----------------------+------+| 18446744073709551613 | 0 |+----------------------+------+1 row in set (0.00 sec) UNSIGNED BIGINT 类型的范围究竟有多大呢？ 假如每秒自增100万次，想要消耗完需要 18446744073709551613/1000000/3600/24/365=584942年。 有的朋友会问如果自增列不是采用BIGINT类型，那么达到最大值后该表就无法写入，此时该怎么办呢？ 一般达到最大值后再次插入数据会报错ERROR 1467 (HY000): Failed to read auto-increment value from storage engine，可以通过alter table 将自增列的类型设为数值范围更大的类型（比如BIGINT）。 4. 总结 AUTO_INCREMENT 列必定唯一，且仅用于整型类型。 AUTO_INCREMENT 列会持续增长，不会因 delete 自增列最大的记录而变小。 当 AUTO_INCREMENT 列达到当前类型的最大值后将无法插入数据，会报错ERROR 1467 (HY000): Failed to read auto-increment value from storage engine，此时将自增列改为 BIGINT 类型可解决问题。 为了避免自增列达到最大值，可将其设为BIGINT类型。 使用 alter table 修改 AUTO_INCREMENT 列时，其值会取自增列当前最大记录值+1与将要设置的值的最大值。 在MySQL 5.7 中，将列设置成 AUTO_INCREMENT 之后，必须将其设置成主键/或者是主键的一部分，否则会报错ERROR 1075 (42000): Incorrect table definition; there can be only one auto column and it must be defined as a key。 欢迎关注我的微信公众号【MySQL数据库技术】。 标题 网址 GitHub https://dbkernel.github.io 知乎 https://www.zhihu.com/people/dbkernel/posts 思否（SegmentFault） https://segmentfault.com/u/dbkernel 掘金 https://juejin.im/user/5e9d3ed251882538083fed1f/posts 开源中国（oschina） https://my.oschina.net/dbkernel 博客园（cnblogs） https://www.cnblogs.com/dbkernel","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://dbkernel.github.io/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://dbkernel.github.io/tags/MySQL/"},{"name":"auto_increment","slug":"auto-increment","permalink":"http://dbkernel.github.io/tags/auto-increment/"}]},{"title":"程序人生 | UNIX环境高级编程技巧之 df 指令实现","slug":"advanced-programming-in-the-unix-environment-df","date":"2014-07-10T01:48:48.000Z","updated":"2021-08-31T15:02:32.737Z","comments":true,"path":"2014/07/10/advanced-programming-in-the-unix-environment-df/","link":"","permalink":"http://dbkernel.github.io/2014/07/10/advanced-programming-in-the-unix-environment-df/","excerpt":"","text":"代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100#include &lt;stdio.h&gt;#include &lt;mntent.h&gt;#include &lt;string.h&gt;#include &lt;sys/vfs.h&gt;static const unsigned long long G = 1024*1024*1024ull;static const unsigned long long M = 1024*1024;static const unsigned long long K = 1024;static char str[20];char* kscale(unsigned long b, unsigned long bs)&#123; unsigned long long size = b * (unsigned long long)bs; if (size &gt; G) &#123; sprintf(str, &quot;%0.2f GB&quot;, size/(G*1.0)); return str; &#125; else if (size &gt; M) &#123; sprintf(str, &quot;%0.2f MB&quot;, size/(1.0*M)); return str; &#125; else if (size &gt; K) &#123; sprintf(str, &quot;%0.2f K&quot;, size/(1.0*K)); return str; &#125; else &#123; sprintf(str, &quot;%0.2f B&quot;, size*1.0); return str; &#125;&#125;int main(int argc, char *argv[])&#123; FILE* mount_table; struct mntent *mount_entry; struct statfs s; unsigned long blocks_used; unsigned blocks_percent_used; const char *disp_units_hdr = NULL; mount_table = NULL; mount_table = setmntent(&quot;/etc/mtab&quot;, &quot;r&quot;); if (!mount_table) &#123; fprintf(stderr, &quot;set mount entry error\\n&quot;); return -1; &#125; disp_units_hdr = &quot; Size&quot;; printf(&quot;Filesystem %-15sUsed Available %s Mounted on\\n&quot;, disp_units_hdr, &quot;Use%&quot;); while (1) &#123; const char *device; const char *mount_point; if (mount_table) &#123; mount_entry = getmntent(mount_table); if (!mount_entry) &#123; endmntent(mount_table); break; &#125; &#125; else continue; device = mount_entry-&gt;mnt_fsname; mount_point = mount_entry-&gt;mnt_dir; //fprintf(stderr, &quot;mount info: device=%s mountpoint=%s\\n&quot;, device, mount_point); if (statfs(mount_point, &amp;s) != 0) &#123; fprintf(stderr, &quot;statfs failed!\\n&quot;); continue; &#125; if ((s.f_blocks &gt; 0) || !mount_table ) &#123; blocks_used = s.f_blocks - s.f_bfree; blocks_percent_used = 0; if (blocks_used + s.f_bavail) &#123; blocks_percent_used = (blocks_used * 100ULL + (blocks_used + s.f_bavail)/2 ) / (blocks_used + s.f_bavail); &#125; /* GNU coreutils 6.10 skips certain mounts, try to be compatible. */ if (strcmp(device, &quot;rootfs&quot;) == 0) continue; if (printf(&quot;\\n%-20s&quot; + 1, device) &gt; 20) printf(&quot;\\n%-20s&quot;, &quot;&quot;); char s1[20]; char s2[20]; char s3[20]; strcpy(s1, kscale(s.f_blocks, s.f_bsize)); strcpy(s2, kscale(s.f_blocks - s.f_bfree, s.f_bsize)); strcpy(s3, kscale(s.f_bavail, s.f_bsize)); printf(&quot; %9s %9s %9s %3u%% %s\\n&quot;, s1, s2, s3, blocks_percent_used, mount_point); &#125; &#125; return 0;&#125; 编译1$ g++ -g -Wall main.cpp -o testdf 运行 testdf执行效果：1234567891011121314151617$ ./testdfFilesystem Size Used Available Use% Mounted onudev 3.87 GB 0.00 B 3.87 GB 0% /devtmpfs 796.17 MB 980.00 K 795.21 MB 0% /run/dev/vda1 96.75 GB 40.54 GB 56.19 GB 42% /tmpfs 3.89 GB 0.00 B 3.89 GB 0% /dev/shmtmpfs 5.00 MB 0.00 B 5.00 MB 0% /run/locktmpfs 3.89 GB 0.00 B 3.89 GB 0% /sys/fs/cgroup/dev/vda15 104.35 MB 3.86 MB 100.50 MB 4% /boot/efi/dev/loop1 55.50 MB 55.50 MB 0.00 B 100% /snap/core18/2074/dev/loop2 70.62 MB 70.62 MB 0.00 B 100% /snap/lxd/16922/dev/loop4 70.38 MB 70.38 MB 0.00 B 100% /snap/lxd/21029/dev/loop5 32.38 MB 32.38 MB 0.00 B 100% /snap/snapd/12704tmpfs 796.17 MB 980.00 K 795.21 MB 0% /run/snapd/nstmpfs 796.17 MB 0.00 B 796.17 MB 0% /run/user/1000/dev/loop6 55.50 MB 55.50 MB 0.00 B 100% /snap/core18/2128/dev/loop0 32.38 MB 32.38 MB 0.00 B 100% /snap/snapd/12883 原生df执行效果：12345678910111213141516$ df -hFilesystem Size Used Avail Use% Mounted onudev 3.9G 0 3.9G 0% /devtmpfs 797M 980K 796M 1% /run/dev/vda1 97G 41G 57G 42% /tmpfs 3.9G 0 3.9G 0% /dev/shmtmpfs 5.0M 0 5.0M 0% /run/locktmpfs 3.9G 0 3.9G 0% /sys/fs/cgroup/dev/vda15 105M 3.9M 101M 4% /boot/efi/dev/loop1 56M 56M 0 100% /snap/core18/2074/dev/loop2 71M 71M 0 100% /snap/lxd/16922/dev/loop4 71M 71M 0 100% /snap/lxd/21029/dev/loop5 33M 33M 0 100% /snap/snapd/12704tmpfs 797M 0 797M 0% /run/user/1000/dev/loop6 56M 56M 0 100% /snap/core18/2128/dev/loop0 33M 33M 0 100% /snap/snapd/12883 欢迎关注我的微信公众号【MySQL数据库技术】。 标题 网址 GitHub https://dbkernel.github.io 知乎 https://www.zhihu.com/people/dbkernel/posts 思否（SegmentFault） https://segmentfault.com/u/dbkernel 掘金 https://juejin.im/user/5e9d3ed251882538083fed1f/posts 开源中国（oschina） https://my.oschina.net/dbkernel 博客园（cnblogs） https://www.cnblogs.com/dbkernel","categories":[{"name":"程序人生","slug":"程序人生","permalink":"http://dbkernel.github.io/categories/%E7%A8%8B%E5%BA%8F%E4%BA%BA%E7%94%9F/"},{"name":"APUE","slug":"程序人生/APUE","permalink":"http://dbkernel.github.io/categories/%E7%A8%8B%E5%BA%8F%E4%BA%BA%E7%94%9F/APUE/"}],"tags":[{"name":"APUE","slug":"APUE","permalink":"http://dbkernel.github.io/tags/APUE/"},{"name":"UNIX","slug":"UNIX","permalink":"http://dbkernel.github.io/tags/UNIX/"},{"name":"df","slug":"df","permalink":"http://dbkernel.github.io/tags/df/"}]}],"categories":[{"name":"开源","slug":"开源","permalink":"http://dbkernel.github.io/categories/%E5%BC%80%E6%BA%90/"},{"name":"ClickHouse","slug":"ClickHouse","permalink":"http://dbkernel.github.io/categories/ClickHouse/"},{"name":"MySQL","slug":"MySQL","permalink":"http://dbkernel.github.io/categories/MySQL/"},{"name":"程序人生","slug":"程序人生","permalink":"http://dbkernel.github.io/categories/%E7%A8%8B%E5%BA%8F%E4%BA%BA%E7%94%9F/"},{"name":"APUE","slug":"程序人生/APUE","permalink":"http://dbkernel.github.io/categories/%E7%A8%8B%E5%BA%8F%E4%BA%BA%E7%94%9F/APUE/"}],"tags":[{"name":"开源协议","slug":"开源协议","permalink":"http://dbkernel.github.io/tags/%E5%BC%80%E6%BA%90%E5%8D%8F%E8%AE%AE/"},{"name":"开源许可证","slug":"开源许可证","permalink":"http://dbkernel.github.io/tags/%E5%BC%80%E6%BA%90%E8%AE%B8%E5%8F%AF%E8%AF%81/"},{"name":"LICENCE","slug":"LICENCE","permalink":"http://dbkernel.github.io/tags/LICENCE/"},{"name":"github","slug":"github","permalink":"http://dbkernel.github.io/tags/github/"},{"name":"ClickHouse和他的朋友们","slug":"ClickHouse和他的朋友们","permalink":"http://dbkernel.github.io/tags/ClickHouse%E5%92%8C%E4%BB%96%E7%9A%84%E6%9C%8B%E5%8F%8B%E4%BB%AC/"},{"name":"ClickHouse","slug":"ClickHouse","permalink":"http://dbkernel.github.io/tags/ClickHouse/"},{"name":"源码分析","slug":"源码分析","permalink":"http://dbkernel.github.io/tags/%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"name":"MySQL","slug":"MySQL","permalink":"http://dbkernel.github.io/tags/MySQL/"},{"name":"Select","slug":"Select","permalink":"http://dbkernel.github.io/tags/Select/"},{"name":"Count","slug":"Count","permalink":"http://dbkernel.github.io/tags/Count/"},{"name":"auto_increment","slug":"auto-increment","permalink":"http://dbkernel.github.io/tags/auto-increment/"},{"name":"APUE","slug":"APUE","permalink":"http://dbkernel.github.io/tags/APUE/"},{"name":"UNIX","slug":"UNIX","permalink":"http://dbkernel.github.io/tags/UNIX/"},{"name":"df","slug":"df","permalink":"http://dbkernel.github.io/tags/df/"}]}